from typing import Dict, Tuple
from requests import Session
import torch
from database import ProductInferenceVectors, UserProfile


def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [Stage 0] ë°ì´í„° ì¤€ë¹„
    DBì˜ ProductInferenceVectors í…Œì´ë¸”ì—ì„œ (ID, Vector)ë¥¼ ë¡œë“œí•˜ì—¬
    ëª¨ë¸ ì´ˆê¸°í™”ìš© Matrixì™€ ID Mappingì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("â³ [DB Loader] Fetching product vectors from DB...")
    
    # 1. DB Query: IDì™€ Servingìš© ë²¡í„°(128d)ë§Œ ê°€ì ¸ì˜´
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_embedding
    ).filter(
        ProductInferenceVectors.vector_embedding.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("âŒ DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤! Item Tower ì¶”ë¡ ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”.")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128  # Item Tower Output Dimension
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    # Shape: (ì „ì²´ìƒí’ˆìˆ˜ + 1, 128)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    
    id_map = {} # Real DB ID -> Model Index (0, 1, 2...)
    
    # 3. ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ [DB Loader] Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listê°€ ë¬¸ìì—´ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜ ì²˜ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ
        # ì—¬ê¸°ì„œëŠ” List[float]ë¼ê³  ê°€ì •
        
        # ID ë§¤í•‘ (DB ID 1050 -> Model Index 1)
        id_map[real_id] = idx 
        
        # í…ì„œ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print(f"âœ… [DB Loader] Matrix Created. Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map

# train_service.py ë‚´ë¶€ì— ì¶”ê°€í•˜ê±°ë‚˜ utilsë¡œ ë¶„ë¦¬

def fetch_training_data_from_db(db: Session, min_interactions: int = 2):
    """
    [Data Extractor]
    DBì˜ UserInteractionì„ ì¡°íšŒí•˜ì—¬ -> í•™ìŠµìš© {history, target, profile} ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    Sliding Window ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤.
    """
    print("ğŸ“Š [Data Fetcher] Loading user logs from DB...")
    
    # UserProfileê³¼ ê·¸ë“¤ì˜ Interactionsë¥¼ í•œ ë²ˆì— ë¡œë”© (Eager Loading ê¶Œì¥)
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ Query ìˆ˜í–‰
    users = db.query(UserProfile).all()
    
    training_samples = []
    
    for user in users:
        # ì´ë ¥ì´ ì—†ëŠ” ìœ ì €ëŠ” ìŠ¤í‚µ
        if not user.interactions:
            continue
            
        # ì‹œê°„ìˆœ ì •ë ¬ (ê³¼ê±° -> ìµœì‹ )
        # DB ëª¨ë¸ì— relationshipì´ 'interactions'ë¡œ ì¡í˜€ìˆë‹¤ê³  ê°€ì •
        sorted_interactions = sorted(user.interactions, key=lambda x: x.timestamp)
        
        # ìƒí’ˆ ID ì‹œí€€ìŠ¤ ì¶”ì¶œ
        product_seq = [i.product_id for i in sorted_interactions]
        
        # ìµœì†Œ ê¸¸ì´ ì²´í¬ (History 1ê°œ + Target 1ê°œ = 2ê°œ ì´ìƒì´ì–´ì•¼ í•™ìŠµ ê°€ëŠ¥)
        if len(product_seq) < min_interactions:
            continue
            
        # --- [Sliding Window Logic] ---
        # ì˜ˆ: [A, B, C] -> ([A], B), ([A,B], C) ë‘ ê°œì˜ ìƒ˜í”Œ ìƒì„±
        for i in range(1, len(product_seq)):
            history_part = product_seq[:i]  # ì…ë ¥: ê³¼ê±° ì´ë ¥
            target_item = product_seq[i]    # ì •ë‹µ: ë‹¤ìŒ ì•„ì´í…œ
            
            # ë„ˆë¬´ ê¸´ historyëŠ” ëª¨ë¸ max_lenì— ë§ì¶° ì˜ë¼ì£¼ëŠ” ê²Œ ì¢‹ìŒ (Datasetì—ì„œë„ í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ì²˜ë¦¬)
            if len(history_part) > 50:
                history_part = history_part[-50:]
            
            training_samples.append({
                "history": history_part,      # List[int]
                "target": target_item,        # int
                "gender": user.gender,        # int
                "age": user.age_level         # int
            })
            
    print(f"âœ… Generated {len(training_samples)} real training samples from DB.")
    return training_samples
