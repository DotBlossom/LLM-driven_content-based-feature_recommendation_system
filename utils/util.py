from typing import Dict, List, Tuple
from requests import Session
import torch
from database import ProductInferenceVectors, UserProfile


def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [Stage 0] ë°ì´í„° ì¤€ë¹„
    DBì˜ ProductInferenceVectors í…Œì´ë¸”ì—ì„œ (ID, Vector)ë¥¼ ë¡œë“œí•˜ì—¬
    ëª¨ë¸ ì´ˆê¸°í™”ìš© Matrixì™€ ID Mappingì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    print("â³ [DB Loader] Fetching product vectors from DB...")
    
    # 1. DB Query: IDì™€ Servingìš© ë²¡í„°(128d)ë§Œ ê°€ì ¸ì˜´
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_embedding
    ).filter(
        ProductInferenceVectors.vector_embedding.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("âŒ DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤! Item Tower ì¶”ë¡ ì„ ë¨¼ì € ìˆ˜í–‰í•˜ì„¸ìš”.")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128  # Item Tower Output Dimension
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    # Shape: (ì „ì²´ìƒí’ˆìˆ˜ + 1, 128)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    
    id_map = {} # Real DB ID -> Model Index (0, 1, 2...)
    
    # 3. ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ [DB Loader] Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listê°€ ë¬¸ìì—´ì´ë‚˜ ë¦¬ìŠ¤íŠ¸ë¡œ ì˜¬ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë³€í™˜ ì²˜ë¦¬ í•„ìš”í•  ìˆ˜ ìˆìŒ
        # ì—¬ê¸°ì„œëŠ” List[float]ë¼ê³  ê°€ì •
        
        # ID ë§¤í•‘ (DB ID 1050 -> Model Index 1)
        id_map[real_id] = idx 
        
        # í…ì„œ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print(f"âœ… [DB Loader] Matrix Created. Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map

# train_service.py ë‚´ë¶€ì— ì¶”ê°€í•˜ê±°ë‚˜ utilsë¡œ ë¶„ë¦¬

















'''
def fetch_training_data_from_db(db: Session, min_interactions: int = 2):
    """
    [Data Extractor]
    DBì˜ UserInteractionì„ ì¡°íšŒí•˜ì—¬ -> í•™ìŠµìš© {history, target, profile} ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    Sliding Window ë°©ì‹ìœ¼ë¡œ ë°ì´í„°ë¥¼ ì¦ê°•í•©ë‹ˆë‹¤.
    """
    print("ğŸ“Š [Data Fetcher] Loading user logs from DB...")
    
    # UserProfileê³¼ ê·¸ë“¤ì˜ Interactionsë¥¼ í•œ ë²ˆì— ë¡œë”© (Eager Loading ê¶Œì¥)
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ Query ìˆ˜í–‰
    users = db.query(UserProfile).all()
    
    training_samples = []
    
    for user in users:
        # ì´ë ¥ì´ ì—†ëŠ” ìœ ì €ëŠ” ìŠ¤í‚µ
        if not user.interactions:
            continue
            
        # ì‹œê°„ìˆœ ì •ë ¬ (ê³¼ê±° -> ìµœì‹ )
        # DB ëª¨ë¸ì— relationshipì´ 'interactions'ë¡œ ì¡í˜€ìˆë‹¤ê³  ê°€ì •
        sorted_interactions = sorted(user.interactions, key=lambda x: x.timestamp)
        
        # ìƒí’ˆ ID ì‹œí€€ìŠ¤ ì¶”ì¶œ
        product_seq = [i.product_id for i in sorted_interactions]
        
        # ìµœì†Œ ê¸¸ì´ ì²´í¬ (History 1ê°œ + Target 1ê°œ = 2ê°œ ì´ìƒì´ì–´ì•¼ í•™ìŠµ ê°€ëŠ¥)
        if len(product_seq) < min_interactions:
            continue
            
        # --- [Sliding Window Logic] ---
        # ì˜ˆ: [A, B, C] -> ([A], B), ([A,B], C) ë‘ ê°œì˜ ìƒ˜í”Œ ìƒì„±
        for i in range(1, len(product_seq)):
            history_part = product_seq[:i]  # ì…ë ¥: ê³¼ê±° ì´ë ¥
            target_item = product_seq[i]    # ì •ë‹µ: ë‹¤ìŒ ì•„ì´í…œ
            
            # ë„ˆë¬´ ê¸´ historyëŠ” ëª¨ë¸ max_lenì— ë§ì¶° ì˜ë¼ì£¼ëŠ” ê²Œ ì¢‹ìŒ (Datasetì—ì„œë„ í•˜ì§€ë§Œ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ì²˜ë¦¬)
            if len(history_part) > 50:
                history_part = history_part[-50:]
            
            training_samples.append({
                "history": history_part,      # List[int]
                "target": target_item,        # int
                "gender": user.gender,        # int
                "age": user.age_level         # int
            })
            
    print(f"âœ… Generated {len(training_samples)} real training samples from DB.")
    return training_samples

## example usage: context vector support
## context -> ranker context feature vector input

import torch
import math
import numpy as np

class ContextFeatureEngineer:
    def __init__(self, output_dim=20):
        self.output_dim = output_dim
        
    def _encode_cyclical_time(self, value, max_val):
        """
        [í•µì‹¬ ê¸°ë²• 1] ì‹œê°„ì˜ ì—°ì†ì„± ë³´ì¡´ (Cyclical Encoding)
        23ì‹œì™€ 0ì‹œëŠ” ìˆ«ìë¡œëŠ” ë©€ì§€ë§Œ(23 ì°¨ì´), ì‹¤ì œë¡œëŠ” 1ì‹œê°„ ì°¨ì´ì…ë‹ˆë‹¤.
        ì´ë¥¼ Sin/Cos ì¢Œí‘œë¡œ ë³€í™˜í•˜ì—¬ ì›í˜• ì‹œê³„ì²˜ëŸ¼ í‘œí˜„í•©ë‹ˆë‹¤.
        """
        sin_val = math.sin(2 * math.pi * value / max_val)
        cos_val = math.cos(2 * math.pi * value / max_val)
        return [sin_val, cos_val]

    def _log_scale(self, value):
        """
        [í•µì‹¬ ê¸°ë²• 2] ê°’ì˜ ìŠ¤ì¼€ì¼ ì••ì¶• (Log Transformation)
        ì¡°íšŒìˆ˜ ê°™ì€ ë°ì´í„°ëŠ” ë¡±í…Œì¼(Long-tail) ë¶„í¬ë¥¼ ê°€ì§‘ë‹ˆë‹¤. (0 ~ 100ë§Œ)
        ë¡œê·¸ë¥¼ ì·¨í•´ ê²©ì°¨ë¥¼ ì¤„ì—¬ì•¼ ëª¨ë¸ì´ í•™ìŠµí•˜ê¸° ì¢‹ìŠµë‹ˆë‹¤.
        log(x + 1) : 0ì¼ ë•Œ ì—ëŸ¬ ë°©ì§€
        """
        return math.log1p(max(0, value))

    def _one_hot(self, value, num_classes):
        """ë²”ì£¼í˜• ë°ì´í„° ë³€í™˜"""
        vec = [0] * num_classes
        if 0 <= value < num_classes:
            vec[value] = 1
        return vec

    def process(self, raw_context: dict) -> torch.Tensor:
        """
        raw_context = {
            'hour': 14,             # 0-23
            'weekday': 0,           # 0(Mon)-6(Sun)
            'view_count_1h': 150,   # ìµœê·¼ 1ì‹œê°„ ì¡°íšŒìˆ˜
            'item_ctr': 0.05,       # ìµœê·¼ CTR
            'last_visit_min': 30,   # ë§ˆì§€ë§‰ ì ‘ì† í›„ íë¥¸ ì‹œê°„(ë¶„)
            'device_type': 0        # 0:Mobile, 1:PC, 2:Tablet
        }
        """
        features = []
        
        # 1. Time (Hour) -> 2 dims
        features.extend(self._encode_cyclical_time(raw_context.get('hour', 0), 24))
        
        # 2. Weekday -> 7 dims
        features.extend(self._one_hot(raw_context.get('weekday', 0), 7))
        
        # 3. Real-time Stats -> 2 dims
        # ì¡°íšŒìˆ˜ëŠ” ë¡œê·¸ ìŠ¤ì¼€ì¼ë§
        features.append(self._log_scale(raw_context.get('view_count_1h', 0)))
        # CTRì€ ì´ë¯¸ 0~1ì´ë¯€ë¡œ ê·¸ëŒ€ë¡œ (í˜¹ì€ ìŠ¤ì¼€ì¼ë§)
        features.append(raw_context.get('item_ctr', 0.0))
        
        # 4. User Freshness -> 1 dim
        # 10ë¶„ ì „ ì ‘ì†ê³¼ 1000ë¶„ ì „ ì ‘ì†ì˜ ì°¨ì´ë¥¼ ë¡œê·¸ë¡œ í‘œí˜„
        features.append(self._log_scale(raw_context.get('last_visit_min', 0)))
        
        # 5. Device -> 3 dims
        features.extend(self._one_hot(raw_context.get('device_type', 0), 3))
        
        # í˜„ì¬ê¹Œì§€ ì°¨ì› ìˆ˜ ê³„ì‚°: 2 + 7 + 1 + 1 + 1 + 3 = 15ì°¨ì›
        
        # 6. Padding (ë‚¨ì€ 5ì°¨ì› 0ìœ¼ë¡œ ì±„ìš°ê¸°)
        current_dim = len(features)
        if current_dim < self.output_dim:
            features.extend([0.0] * (self.output_dim - current_dim))
        
        return torch.tensor(features, dtype=torch.float32)

# --- ì‚¬ìš© ì˜ˆì‹œ ---
engineer = ContextFeatureEngineer(output_dim=20)

# í˜„ì¬ ìƒí™© (ì˜¤í›„ 2ì‹œ, ì›”ìš”ì¼, ëª¨ë°”ì¼ ì ‘ì†, ì¸ê¸°ìˆëŠ” ìƒí’ˆ)
current_ctx = {
    'hour': 14,
    'weekday': 0,
    'view_count_1h': 1205, # ì¡°íšŒìˆ˜ ë†’ìŒ
    'item_ctr': 0.12,
    'last_visit_min': 5,   # ë°©ê¸ˆ ì „ ì ‘ì†
    'device_type': 0       # ëª¨ë°”ì¼
}

context_tensor = engineer.process(current_ctx)

print(f"Context Vector Shape: {context_tensor.shape}")
print(f"Context Vector Data: {context_tensor}")

'''