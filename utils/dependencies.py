# dependencies.py
from typing import Optional

import torch
from database import SessionLocal
#from inference import RecommendationService
from item_tower import HybridItemTower, OptimizedItemTower
from utils.vocab import get_std_vocab_size, get_std_field_keys
from gnn_model.gnn_cl_noise_cp import SimGCL
# 1. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ìž¥í•  ì „ì—­ ë³€ìˆ˜
global_encoder: Optional[HybridItemTower] = None
global_projector: Optional[OptimizedItemTower] = None
#global_gnn_model = Optional[SimGCL] = None
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


global_batch_size: Optional[int] = None
#rec_service: RecommendationService = None

'''
def initialize_rec_service():
    global rec_service
    
    # DB ì„¸ì…˜ ì—´ê¸°: ëª¨ë¸ ë¡œë”©ì— í•„ìš”í•œ ì•„ì´í…œ ë²¡í„°, ID ë§µ ë“±ì„ DBì—ì„œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”
    db = SessionLocal()
    try:
        # RecommendationService ì´ˆê¸°í™”
        # model_pathëŠ” 'models/user_tower_latest.pth'ì™€ ê°™ì´ ìƒëŒ€ ê²½ë¡œë¥¼ ê¶Œìž¥í•©ë‹ˆë‹¤.
        model_path = "models/user_tower_symmetric_final.pth" 
        rec_service = RecommendationService(db_session=db, model_path=model_path)
    except Exception as e:
        print(f"âŒ Recommendation Service ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•± ì‹œìž‘ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜, rec_serviceë¥¼ Noneìœ¼ë¡œ ìœ ì§€í•˜ì—¬ 503 ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì²˜ë¦¬
        rec_service = None
    finally:
        # ëª¨ë¸ ë¡œë”© í›„ DB ì„¸ì…˜ì„ ì¦‰ì‹œ ë‹«ì•„ì¤ë‹ˆë‹¤.
        db.close()
'''     


# 2. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (main.pyì˜ startup ì´ë²¤íŠ¸ì—ì„œ í˜¸ì¶œë¨)
def initialize_global_models():
    """
    ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ìž¥í•©ë‹ˆë‹¤.
    FastAPIì˜ startup ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ í˜¸ì¶œ
    """
    global global_encoder
    global global_projector
    global global_gnn_model
    global std_size 
    global num_std
    global global_batch_size
    std_size = get_std_vocab_size()
    num_std = len(get_std_field_keys())
    

    
    print("ðŸš€ ì•± ì‹œìž‘: CoarseToFineItemTower ë¡œë”© ì¤‘...")
    global_encoder = HybridItemTower(std_size, num_std, embed_dim=128)
    print("âœ… ItemTower ë¡œë“œ ì™„ë£Œ.")

    print("ðŸš€ ì•± ì‹œìž‘: OptimizedItemTower ë¡œë”© ì¤‘...")
    global_projector = OptimizedItemTower(input_dim=128, output_dim=128)
    print("âœ… OptimizedItemTower ë¡œë“œ ì™„ë£Œ.")
    
    
    print("ðŸš€ ì•± ì‹œìž‘: Gnn ë¡œë”© ì¤‘...")
 #   global_gnn_model = SimGCL(in_feats=128, hidden_feats=64, out_feats=128, num_layers=2, dropout=0.3, alpha=0.2)
    print("âœ… Gnn Model params ë¡œë“œ ì™„ë£Œ.")

    global_batch_size = 192
    print(f"âœ… Global Batch Size set to: {global_batch_size}")
    

# 3. ì˜ì¡´ì„± ì£¼ìž…(DI) ì œê³µìž í•¨ìˆ˜
def get_global_encoder() -> HybridItemTower:
    """ì €ìž¥ëœ CoarseToFineItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ìž… í•¨ìˆ˜."""
    if global_encoder is None:
        # ì´ ì˜ˆì™¸ëŠ” startup ì´ë²¤íŠ¸ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ë°œìƒ
        raise Exception("Encoder model has not been loaded yet. Check application startup events.")
    return global_encoder

def get_global_projector() -> OptimizedItemTower:
    """ì €ìž¥ëœ OptimizedItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ìž… í•¨ìˆ˜."""
    if global_projector is None:
        raise Exception("Projector model has not been loaded yet. Check application startup events.")
    return global_projector


def get_global_batch_size() -> int:
    
    if global_batch_size is None:
        raise Exception("global batch size has not been defined")
    return global_batch_size
