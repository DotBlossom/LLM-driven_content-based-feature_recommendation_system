# dependencies.py
from typing import Optional

import torch
from database import SessionLocal
#from inference import RecommendationService
from model import CoarseToFineItemTower, OptimizedItemTower, SimCSEModelWrapper

# 1. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ì¥í•  ì „ì—­ ë³€ìˆ˜
global_encoder: Optional[CoarseToFineItemTower] = None
global_projector: Optional[OptimizedItemTower] = None
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


#rec_service: RecommendationService = None

'''
def initialize_rec_service():
    global rec_service
    
    # DB ì„¸ì…˜ ì—´ê¸°: ëª¨ë¸ ë¡œë”©ì— í•„ìš”í•œ ì•„ì´í…œ ë²¡í„°, ID ë§µ ë“±ì„ DBì—ì„œ ê°€ì ¸ì˜¤ê¸° ìœ„í•´ í•„ìš”
    db = SessionLocal()
    try:
        # RecommendationService ì´ˆê¸°í™”
        # model_pathëŠ” 'models/user_tower_latest.pth'ì™€ ê°™ì´ ìƒëŒ€ ê²½ë¡œë¥¼ ê¶Œì¥í•©ë‹ˆë‹¤.
        model_path = "models/user_tower_symmetric_final.pth" 
        rec_service = RecommendationService(db_session=db, model_path=model_path)
    except Exception as e:
        print(f"âŒ Recommendation Service ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        # ì˜¤ë¥˜ ë°œìƒ ì‹œ ì•± ì‹œì‘ì„ ì¤‘ë‹¨í•˜ê±°ë‚˜, rec_serviceë¥¼ Noneìœ¼ë¡œ ìœ ì§€í•˜ì—¬ 503 ì˜¤ë¥˜ë¥¼ ë°˜í™˜í•˜ë„ë¡ ì²˜ë¦¬
        rec_service = None
    finally:
        # ëª¨ë¸ ë¡œë”© í›„ DB ì„¸ì…˜ì„ ì¦‰ì‹œ ë‹«ì•„ì¤ë‹ˆë‹¤.
        db.close()
'''     


# 2. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (main.pyì˜ startup ì´ë²¤íŠ¸ì—ì„œ í˜¸ì¶œë¨)
def initialize_global_models():
    """
    ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ì¥í•©ë‹ˆë‹¤.
    FastAPIì˜ startup ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ í˜¸ì¶œ
    """
    global global_encoder
    global global_projector
    
    print("ğŸš€ ì•± ì‹œì‘: CoarseToFineItemTower ë¡œë”© ì¤‘...")
    global_encoder = CoarseToFineItemTower(embed_dim=64, output_dim=128)
    print("âœ… CoarseToFineItemTower ë¡œë“œ ì™„ë£Œ.")

    print("ğŸš€ ì•± ì‹œì‘: OptimizedItemTower ë¡œë”© ì¤‘...")
    global_projector = OptimizedItemTower(input_dim=128, output_dim=128)
    print("âœ… OptimizedItemTower ë¡œë“œ ì™„ë£Œ.")

    global global_batch_size
    global_batch_size = 128
    print(f"âœ… Global Batch Size set to: {global_batch_size}")
    

# 3. ì˜ì¡´ì„± ì£¼ì…(DI) ì œê³µì í•¨ìˆ˜
def get_global_encoder() -> CoarseToFineItemTower:
    """ì €ì¥ëœ CoarseToFineItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜."""
    if global_encoder is None:
        # ì´ ì˜ˆì™¸ëŠ” startup ì´ë²¤íŠ¸ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ë°œìƒ
        raise Exception("Encoder model has not been loaded yet. Check application startup events.")
    return global_encoder

def get_global_projector() -> OptimizedItemTower:
    """ì €ì¥ëœ OptimizedItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜."""
    if global_projector is None:
        raise Exception("Projector model has not been loaded yet. Check application startup events.")
    return global_projector

def get_global_batch_size() -> int:
    
    if global_batch_size is None:
        raise Exception("global batch size has not been defined")
    return global_batch_size

'''
def get_global_rec_service() -> RecommendationService:
    """ì €ì¥ëœ RecommendationService ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ì… í•¨ìˆ˜."""
    if rec_service is None:
        raise Exception("Recommendation Service has not been initialized yet. Check application startup events.")
    return rec_service
'''