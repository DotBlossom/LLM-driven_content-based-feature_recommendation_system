# dependencies.py
from typing import Optional

import torch
from model import CoarseToFineItemTower, OptimizedItemTower, SimCSEModelWrapper

# 1. ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ì €ìž¥í•  ì „ì—­ ë³€ìˆ˜ (State)
# Optionalì„ ì‚¬ìš©í•˜ì—¬ ì´ˆê¸°ì—ëŠ” Noneìž„ì„ ëª…ì‹œí•©ë‹ˆë‹¤.
global_encoder: Optional[CoarseToFineItemTower] = None
global_projector: Optional[OptimizedItemTower] = None
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# 2. ëª¨ë¸ ë¡œë”© í•¨ìˆ˜ (main.pyì˜ startup ì´ë²¤íŠ¸ì—ì„œ í˜¸ì¶œë¨)
def initialize_global_models():
    """
    ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë¡œë“œí•˜ê³  ì „ì—­ ë³€ìˆ˜ì— ì €ìž¥í•©ë‹ˆë‹¤.
    (FastAPIì˜ startup ì´ë²¤íŠ¸ í•¸ë“¤ëŸ¬ì—ì„œ í˜¸ì¶œë©ë‹ˆë‹¤.)
    """
    global global_encoder
    global global_projector
    
    print("ðŸš€ ì•± ì‹œìž‘: CoarseToFineItemTower ë¡œë”© ì¤‘...")
    global_encoder = CoarseToFineItemTower(embed_dim=64, output_dim=128)
    print("âœ… CoarseToFineItemTower ë¡œë“œ ì™„ë£Œ.")

    print("ðŸš€ ì•± ì‹œìž‘: OptimizedItemTower ë¡œë”© ì¤‘...")
    global_projector = OptimizedItemTower(input_dim=128, output_dim=128)
    print("âœ… OptimizedItemTower ë¡œë“œ ì™„ë£Œ.")

    global global_batch_size
    global_batch_size = 64
    print(f"âœ… Global Batch Size set to: {global_batch_size}")
    

# 3. ì˜ì¡´ì„± ì£¼ìž…(DI) ì œê³µìž í•¨ìˆ˜
def get_global_encoder() -> CoarseToFineItemTower:
    """ì €ìž¥ëœ CoarseToFineItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ìž… í•¨ìˆ˜."""
    if global_encoder is None:
        # ì´ ì˜ˆì™¸ëŠ” startup ì´ë²¤íŠ¸ê°€ ì‹¤í–‰ë˜ì§€ ì•Šì•˜ì„ ë•Œë§Œ ë°œìƒí•´ì•¼ í•©ë‹ˆë‹¤.
        raise Exception("Encoder model has not been loaded yet. Check application startup events.")
    return global_encoder

def get_global_projector() -> OptimizedItemTower:
    """ì €ìž¥ëœ OptimizedItemTower ì¸ìŠ¤í„´ìŠ¤ë¥¼ ë°˜í™˜í•˜ëŠ” ì˜ì¡´ì„± ì£¼ìž… í•¨ìˆ˜."""
    if global_projector is None:
        raise Exception("Projector model has not been loaded yet. Check application startup events.")
    return global_projector

def get_global_batch_size() -> int:
    
    if global_batch_size is None:
        raise Exception("global batch size has not been defined")
    return global_batch_size