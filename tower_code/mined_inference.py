import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence
from transformers import get_cosine_schedule_with_warmup
import pandas as pd
import numpy as np
import os
import random
import math
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
import gc
import warnings
import logging

warnings.filterwarnings("ignore", message="Support for mismatched src_key_padding_mask and mask is deprecated")

# ==========================================
# âš™ï¸ ì„¤ì • & ê²½ë¡œ
# ==========================================
#TEMPERATURE = 0.2
LAMBDA_LOGQ = 0.1
BATCH_SIZE = 896
EMBED_DIM = 128
MAX_SEQ_LEN = 50
DROPOUT = 0.3
EPOCHS = 10
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

BASE_DIR = r"D:\trainDataset\localprops"
MODEL_DIR = r"C:\Users\candyform\Desktop\inferenceCode\models"
CACHE_DIR = os.path.join(BASE_DIR, "cache")

ITEM_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_item.parquet")
USER_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_user.parquet")
SEQ_DATA_PATH_PQ = os.path.join(BASE_DIR, "features_sequence_cleaned.parquet")
TARGET_VAL_PATH = os.path.join(BASE_DIR, "features_target_val.parquet")
USER_VAL_FEAT_PATH = os.path.join(BASE_DIR, "features_user_val.parquet")
SEQ_VAL_DATA_PATH = os.path.join(BASE_DIR, "features_sequence_val.parquet")

SAVE_PATH_BEST = os.path.join(MODEL_DIR, "user_tower_phase3_best_ft_0.19x.pth")

class SmartLogger:
    def __init__(self, verbosity=1): self.verbosity = verbosity
    def log(self, level, msg):
        if self.verbosity >= level: print(f"[{'â„¹ï¸' if level==1 else 'ğŸ“Š'}] {msg}")

logger = SmartLogger(verbosity=1)

# ==========================================
# 1. Feature Processor & Dataset
# ==========================================
class FeatureProcessor:
    def __init__(self, user_path, item_path, seq_path, scaler=None):
        print(f"ğŸ”„ Loading Data from {user_path}...")
        self.users = pd.read_parquet(user_path)
        self.users = self.users.drop_duplicates(subset=['customer_id']).set_index('customer_id')
        
        self.items = pd.read_parquet(item_path).set_index('article_id')
        self.seqs = pd.read_parquet(seq_path).set_index('customer_id')
        
        # ì¸ë±ìŠ¤ ê°•ì œ ë¬¸ìì—´ ë³€í™˜
        self.users.index = self.users.index.astype(str)
        self.items.index = self.items.index.astype(str)
        self.seqs.index = self.seqs.index.astype(str)

        self.user_ids = self.users.index.tolist()
        self.user2id = {uid: i + 1 for i, uid in enumerate(self.user_ids)} # 1-based
        self.item_ids = self.items.index.tolist()
        self.item2id = {iid: i + 1 for i, iid in enumerate(self.item_ids)} # 1-based
        
        self.u_dense_cols = ['user_avg_price_log', 'total_cnt_log', 'recency_log']
        self.users_scaled = self.users.copy()
        
        if scaler is None: 
            self.user_scaler = StandardScaler()
            scaled_data = self.user_scaler.fit_transform(self.users[self.u_dense_cols])
        else: 
            self.user_scaler = scaler
            scaled_data = self.user_scaler.transform(self.users[self.u_dense_cols])
        
        self.users_scaled[self.u_dense_cols] = np.nan_to_num(scaled_data, nan=0.0)

    def get_user_tensor(self, user_id):
        if user_id not in self.users_scaled.index:
            return torch.zeros(len(self.u_dense_cols)), torch.tensor(0, dtype=torch.long)
            
        row = self.users_scaled.loc[user_id]
        dense = torch.tensor(row[self.u_dense_cols].values.astype(np.float32), dtype=torch.float32)
        # preferred_channelì´ 1~Nì´ë¼ê³  ê°€ì •í•˜ê³  0-basedë¡œ ë³€í™˜ (-1)
        cat = torch.tensor(int(row['preferred_channel']) - 1, dtype=torch.long)
        return dense, cat
    def get_logq_probs(self, device):
        """
        ëª¨ë¸ì˜ Embedding(N+1, D) êµ¬ì¡°ì™€ ì¼ì¹˜í•˜ë„ë¡ ì¸ë±ìŠ¤ ë³´ì •ëœ log_q ìƒì„±
        """
        # 1. raw_probability ì¶”ì¶œ (0-based)
        raw_probs = self.items['raw_probability'].reindex(self.item_ids).values
        
        # 2. Smoothing ë° ì²˜ë¦¬
        eps = 1e-6
        sorted_probs = np.nan_to_num(raw_probs, nan=0.0) + eps
        sorted_probs /= sorted_probs.sum()
        
        # 3. ë¡œê·¸ ê³„ì‚°
        log_q_values = np.log(sorted_probs).astype(np.float32)
        
        # 4. [ì¤‘ìš”] 1-based ì¸ë±ì‹± ëŒ€ì‘ì„ ìœ„í•œ Padding ì¶”ê°€
        # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì•„ì£¼ ì‘ì€ í™•ë¥ (ë˜ëŠ” 0)ì˜ ë¡œê·¸ê°’ìœ¼ë¡œ ì±„ì›€
        full_log_q = np.zeros(len(self.item_ids) + 1, dtype=np.float32)
        full_log_q[1:] = log_q_values  # 1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹¤ì œ ê°’ ì±„ìš°ê¸°
        full_log_q[0] = -20.0          # 0ë²ˆ ì¸ë±ìŠ¤(Padding)ëŠ” ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •
    
        return torch.tensor(full_log_q, dtype=torch.float32).to(device)
class UserTowerDataset(Dataset):
    def __init__(self, processor, max_seq_len=50, is_training=True):
        self.processor = processor
        self.user_ids = processor.user_ids 
        self.max_len = max_seq_len
        self.is_training = is_training
        self.min_cut_len = 3      

    def __len__(self):
        return len(self.user_ids)

    def __getitem__(self, idx):
        u_id_str = self.user_ids[idx]
        u_dense, u_cat = self.processor.get_user_tensor(u_id_str)
        
        processed_tokens = []
        processed_deltas = []
        
        if u_id_str in self.processor.seqs.index:
            seq_row = self.processor.seqs.loc[u_id_str]
            # Seriesì¼ ê²½ìš° ì²˜ë¦¬
            if isinstance(seq_row, pd.DataFrame): seq_row = seq_row.iloc[0]
                
            for i, d in zip(seq_row['sequence_ids'], seq_row['sequence_deltas']):
                 token = self.processor.item2id.get(str(i), 0) # str ë³€í™˜ ì•ˆì „ì¥ì¹˜
                 if token == 0: continue
                 processed_tokens.append(token)
                 processed_deltas.append(d)

        seq_len = len(processed_tokens)
        input_seq = []
        target_seq = [] 

        if seq_len > 0:
            if self.is_training:
                can_sample = seq_len > self.min_cut_len
                if not can_sample or random.random() < 0.8:
                    input_seq = processed_tokens[:-1]
                    target_seq = processed_tokens[1:]
                else:
                    max_cut = seq_len - 1
                    cut_idx = seq_len if max_cut < self.min_cut_len else random.randint(self.min_cut_len, max_cut)
                    full_slice = processed_tokens[:cut_idx+1]
                    input_seq = full_slice[:-1]
                    target_seq = full_slice[1:]
            else:
                input_seq = processed_tokens[:]
                target_seq = [0] * len(input_seq)

        input_ids = input_seq[-self.max_len:]
        target_ids = target_seq[-self.max_len:]
        input_deltas = processed_deltas[:len(input_seq)][-self.max_len:]

        return {
            'user_idx': torch.tensor(idx + 1, dtype=torch.long),
            'user_dense': u_dense, 'user_cat': u_cat,
            'seq_ids': torch.tensor(input_ids, dtype=torch.long),
            'seq_deltas': torch.tensor(input_deltas, dtype=torch.long),
            'target_ids': torch.tensor(target_ids, dtype=torch.long)
        }

def user_tower_collate_fn(batch):
    u_idx = torch.stack([b['user_idx'] for b in batch])
    u_dense = torch.stack([b['user_dense'] for b in batch])
    u_cat = torch.stack([b['user_cat'] for b in batch])
    seq_ids = pad_sequence([b['seq_ids'] for b in batch], batch_first=True, padding_value=0)
    seq_deltas = pad_sequence([b['seq_deltas'] for b in batch], batch_first=True, padding_value=0)
    target_ids = pad_sequence([b['target_ids'] for b in batch], batch_first=True, padding_value=0)
    seq_mask = (seq_ids != 0).long()
    last_target = torch.tensor([b['target_ids'][-1] if len(b['target_ids']) > 0 else 0 for b in batch], dtype=torch.long)
    return u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, last_target

# ==========================================
# 2. Alignment Functions (Alignment)
# ==========================================
def load_and_align_embeddings(model, processor, model_dir, device):
    """ Content Item Embedding Alignment (Pretrained -> model.item_content_emb) """
    print(f"\nğŸ”„ [Content Alignment] Starting Item Embedding Alignment...")
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")

    try:
        pretrained_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(pretrained_emb, dict):
            pretrained_emb = pretrained_emb.get('weight', pretrained_emb.get('item_content_emb.weight'))
        pretrained_ids = torch.load(ids_path, map_location='cpu')
    except Exception as e:
        print(f"âŒ [Error] Failed to load Content files: {e}")
        return model

    pretrained_map = {str(item_id.item()) if isinstance(item_id, torch.Tensor) else str(item_id): pretrained_emb[idx] for idx, item_id in enumerate(pretrained_ids)}
    
    num_embeddings = len(processor.item_ids) + 1 
    new_weight = torch.randn(num_embeddings, pretrained_emb.shape[1]) * 0.01 
    new_weight[0] = 0.0 
    
    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        if current_id_str in pretrained_map:
            new_weight[i + 1] = pretrained_map[current_id_str]
            matched += 1
            
    with torch.no_grad():
        model.item_content_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        
    print(f"âœ… [Content Alignment] Matched: {matched}/{len(processor.item_ids)}")
    return model



def load_and_align_gnn_items2(model, processor, base_dir, device):
    """
    [Fixed] GNN í•™ìŠµ ê²°ê³¼(simgcl_trained.pth) - ID Mapping Only
    """
    print(f"\nğŸ”„ [GNN Alignment] Starting GNN Item Embedding Alignment (ID Only)...")
    
    # ... (ê²½ë¡œ ì„¤ì • ë° íŒŒì¼ ë¡œë“œ ë¶€ë¶„ ë™ì¼) ...
    cache_dir = os.path.join(base_dir, "cache")
    model_path = os.path.join(MODEL_DIR , "simgcl_trained.pth")
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    try:
        maps = torch.load(maps_path, map_location='cpu')
        gnn_item2id = maps['item2id']
        
        gnn_state_dict = torch.load(model_path, map_location='cpu')
        gnn_emb_weight = gnn_state_dict['embedding_item.weight']
        
    except Exception as e:
        print(f"âŒ [Error] Failed to load GNN files: {e}")
        return model

    # ... (ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„± ë° ë§¤í•‘ ë¶€ë¶„ ë™ì¼) ...
    num_embeddings = len(processor.item_ids) + 1 
    emb_dim = gnn_emb_weight.shape[1]
    new_weight = torch.randn(num_embeddings, emb_dim) * 0.01
    new_weight[0] = 0.0

    matched_count = 0
    for i, current_id_str in enumerate(processor.item_ids):
        target_idx = i + 1 
        if current_id_str in gnn_item2id:
            gnn_idx = gnn_item2id[current_id_str]
            new_weight[target_idx] = gnn_emb_weight[gnn_idx]
            matched_count += 1
            
    # 5. ëª¨ë¸ ì£¼ì… (ìˆ˜ì •ë¨!)
    target_layer_name = 'gnn_item_emb'  # âœ… CORRECT: User -> Itemìœ¼ë¡œ ë³€ê²½
    
    with torch.no_grad():
        if hasattr(model, target_layer_name):
            setattr(model, target_layer_name, nn.Embedding.from_pretrained(new_weight.to(device), freeze=False))
            print(f"  âœ… Injected aligned vectors into 'model.{target_layer_name}'")
        else:
            print(f"âŒ [Critical] Could not find '{target_layer_name}' in User Tower.")
            return model

    print(f"âœ… [GNN Alignment] Complete! Matched: {matched_count}/{len(processor.item_ids)}")
    return model





import torch
import torch.nn as nn
import os

class ResidualAdapter(nn.Module):
    def __init__(self, input_dim, output_dim, dropout=0.1):
        super().__init__()
        
        # 1. [Main Path] í•™ìŠµì„ í†µí•´ 'ë³€í˜•'ë  íŠ¹ì§• (Interaction ì •ë³´ ë°˜ì˜)
        self.mlp = nn.Sequential(
            nn.LayerNorm(input_dim),
            nn.Linear(input_dim, input_dim),
            nn.LeakyReLU(0.2),
            nn.Dropout(dropout),
            nn.Linear(input_dim, output_dim)
        )
        
        # 2. [Shortcut Path] ì›ë³¸ ë©”íƒ€ë°ì´í„°ì˜ íŠ¹ì„±ì„ ìœ ì§€í•˜ëŠ” ê²½ë¡œ
        self.shortcut = nn.Linear(input_dim, output_dim, bias=False)
        
        # 3. [Gate Layer] (NEW)
        # ì…ë ¥(x)ì„ ë³´ê³  0~1 ì‚¬ì´ì˜ ì¤‘ìš”ë„(alpha)ë¥¼ ì‚°ì¶œ
        # input_dim -> output_dim í¬ê¸°ì˜ ê²Œì´íŠ¸ë¥¼ ë§Œë“¤ì–´ ì°¨ì›ë³„ë¡œ ì¡°ì ˆ ê°€ëŠ¥í•˜ê²Œ í•¨
        self.gate_layer = nn.Linear(input_dim, output_dim)
        
        # --- Initialization ---
        # A. Shortcut: Identityì— ê°€ê¹ê²Œ ì´ˆê¸°í™” (ì›ë³¸ ë³´ì¡´)
        if input_dim == output_dim:
            nn.init.eye_(self.shortcut.weight)
        else:
            nn.init.xavier_uniform_(self.shortcut.weight)

        # B. MLP: ì´ˆê¸° ì¶œë ¥ì„ ì‘ê²Œ í•˜ì—¬ í•™ìŠµ ì´ˆê¸° ì¶©ê²© ë°©ì§€
        for m in self.mlp:
            if isinstance(m, nn.Linear):
                nn.init.xavier_uniform_(m.weight, gain=0.01)

        # C. Gate: ì´ˆê¸°ì—ëŠ” "ì›ë³¸(Shortcut)"ì„ ë” ì‹ ë¢°í•˜ë„ë¡ ì„¤ì •
        # Biasë¥¼ ì–‘ìˆ˜(2.0)ë¡œ ì„¤ì •í•˜ë©´ Sigmoid í†µê³¼ í›„ ì•½ 0.88ì´ ë¨
        # ì¦‰, í•™ìŠµ ì´ˆê¸°ì—ëŠ” ì›ë³¸ 88%, ë³€í˜• 12% ë¹„ìœ¨ë¡œ ì‹œì‘
        nn.init.xavier_uniform_(self.gate_layer.weight, gain=0.01)
        nn.init.constant_(self.gate_layer.bias, 2.0) 

    def forward(self, x):
        # 1. ë³€í˜•ëœ íŠ¹ì§• (Learned Context)
        transformed = self.mlp(x)
        
        # 2. ì›ë³¸ ë³´ì¡´ íŠ¹ì§• (Original Metadata)
        original = self.shortcut(x)
        
        # 3. Gate ê³„ìˆ˜ ê³„ì‚° (0.0 ~ 1.0)
        # alphaê°€ ë†’ì„ìˆ˜ë¡ 'ì›ë³¸ ë©”íƒ€ë°ì´í„°'ë¥¼ ìœ ì§€í•˜ë ¤ëŠ” ì„±í–¥ì´ ê°•í•¨
        alpha = torch.sigmoid(self.gate_layer(x))
        
        # 4. Gated Mixing (Convex Combination)
        # "ë©”íƒ€ë°ì´í„°ê°€ í™•ì‹¤í•˜ë©´ ì›ë³¸ì„ ì“°ê³ , êµ¬ë§¤ íŒ¨í„´ì´ íŠ¹ì´í•˜ë©´ ë³€í˜•ëœ ê°’ì„ ì¨ë¼"
        return alpha * original + (1 - alpha) * transformed

def load_and_align_gnn_items(model, processor, base_dir, device):
    """ 
    GNN Item Embedding Alignment (Residual Adapter Aware)
    ì €ì¥ëœ Adapter ê°€ì¤‘ì¹˜ë¥¼ ì‚¬ìš©í•´ ìµœì¢… ì„ë² ë”©ì„ ê³„ì‚°í•œ ë’¤ ì •ë ¬í•˜ì—¬ ì£¼ì… 
    """
    print(f"\nğŸ”„ [GNN Item Alignment] Starting (Adapter Mode)...")
    
    # ê²½ë¡œ ì„¤ì •
    # MODEL_DIR ì „ì—­ ë³€ìˆ˜ê°€ ì—†ë‹¤ë©´ base_dir ê¸°ì¤€ìœ¼ë¡œ ì„¤ì •í•˜ê±°ë‚˜ ì¸ìë¡œ ë°›ìœ¼ì„¸ìš”.
    # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ base_dir/models í˜¹ì€ ì§ì ‘ ì§€ì •ëœ ê²½ë¡œ ì‚¬ìš© ê°€ì •
    model_dir = globals().get('MODEL_DIR', os.path.join(base_dir, 'models')) 
    cache_dir = os.path.join(base_dir, "cache")
    
    model_path = os.path.join(model_dir, "model_ver2_ep2_tune.pth") # í˜¹ì€ ìµœì‹  ì—í¬í¬
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    
        # 1. ID Map ë¡œë“œ
    maps = torch.load(maps_path, map_location='cpu')
    gnn_item2id = maps['item2id']
        
        # 2. State Dict ë¡œë“œ
    state_dict = torch.load(model_path, map_location='cpu')
        
        # 3. [í•µì‹¬] Adapter ê°€ì¤‘ì¹˜ì™€ Pretrained Feature ë³µì›
        # ì €ì¥ëœ ëª¨ë¸ì— item_featuresê°€ ì—†ë‹¤ë©´, GNN í•™ìŠµ ì‹œ ì‚¬ìš©í•œ ì›ë³¸ feature íŒŒì¼ì„ ë¡œë“œí•´ì•¼ í•¨
        # í•˜ì§€ë§Œ GNNTrainerì—ì„œ 'item_features'ë¥¼ bufferë‚˜ parameterë¡œ ì €ì¥í–ˆë‹¤ë©´ state_dictì— ìˆìŒ
        
        # (A) Pretrained Input Feature ì°¾ê¸°
    if 'item_features' in state_dict:
        raw_features = state_dict['item_features'] # (N_gnn, 128)
    else:
            # ë§Œì•½ state_dictì— ì—†ë‹¤ë©´ ì™¸ë¶€ íŒŒì¼ì—ì„œ ë¡œë“œ (ì˜ˆì™¸ ì²˜ë¦¬)
            # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ state_dictì— ìˆë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜, ì—†ìœ¼ë©´ ì—ëŸ¬
        raise ValueError("âŒ 'item_features' not found in checkpoint! (Did you save it?)")

        # (B) Adapter & Bias ë¡œë“œ ë° ê³„ì‚°
    input_dim = raw_features.shape[1] # 128
    output_dim = 64 # GNN output dim
        
    adapter = ResidualAdapter(input_dim, output_dim).to('cpu')
        
        # Adapter í‚¤ ë§¤í•‘ (ì ‘ë‘ì‚¬ 'item_adapter.' ì œê±° í•„ìš”í•  ìˆ˜ ìˆìŒ)
    adapter_state = {}
    for k, v in state_dict.items():
        if k.startswith('item_adapter.'):
            adapter_state[k.replace('item_adapter.', '')] = v
        
    adapter.load_state_dict(adapter_state)
        
        # Bias ë¡œë“œ
    bias = state_dict.get('item_bias', torch.zeros(len(gnn_item2id), output_dim))
        
        # (C) ìµœì¢… ì„ë² ë”© ìƒì„± (Forward)
    with torch.no_grad():
        adapter.eval()
            # Feature -> Adapter -> + Bias
        final_gnn_embeddings = adapter(raw_features) + bias
        

    # 4. ì •ë ¬ ë° ì£¼ì… (ê¸°ì¡´ ë¡œì§ê³¼ ë™ì¼)
    num_embeddings = len(processor.item_ids) + 1 
    new_weight = torch.randn(num_embeddings, output_dim) * 0.01
    new_weight[0] = 0.0

    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        if current_id_str in gnn_item2id:
            # GNN í•™ìŠµ ì‹œì˜ IDë¡œ ì„ë² ë”© ì¡°íšŒ
            gnn_idx = gnn_item2id[current_id_str]
            if gnn_idx < len(final_gnn_embeddings):
                new_weight[i + 1] = final_gnn_embeddings[gnn_idx]
                matched += 1
            
    with torch.no_grad():
        model.gnn_item_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        print(f"âœ… Injected into 'model.gnn_item_emb' (Dim: {output_dim})")

    print(f"âœ… [GNN Item Alignment] Matched: {matched}/{len(processor.item_ids)}")
    return model

def load_and_align_gnn_user_embeddings(model, processor, base_dir, device):
    """ GNN User Embedding Alignment (Standard Embedding) """
    print(f"\nğŸ”„ [GNN User Alignment] Starting...")
    
    model_dir = globals().get('MODEL_DIR', os.path.join(base_dir, 'models'))
    cache_dir = os.path.join(base_dir, "cache")
    
    model_path = os.path.join(model_dir, "simgcl_trained.pth")
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    try:
        maps = torch.load(maps_path, map_location='cpu')
        gnn_user2id = maps['user2id']
        state_dict = torch.load(model_path, map_location='cpu')
        
        # ìœ ì € ì„ë² ë”© í‚¤ ì°¾ê¸° ('embedding_user.weight'ê°€ ì¼ë°˜ì )
        user_key = next((k for k in state_dict.keys() if 'embedding_user' in k), None)
        
        if user_key is None:
            raise ValueError(f"User embedding key not found. Keys: {list(state_dict.keys())[:5]}")
            
        gnn_user_weight = state_dict[user_key]

    except Exception as e:
        print(f"âŒ [Error] Failed to load GNN User files: {e}")
        return model

    num_users = len(processor.user_ids) + 1
    embed_dim = gnn_user_weight.shape[1]
    new_weight = torch.randn(num_users, embed_dim) * 0.01
    new_weight[0] = 0.0
    
    matched = 0
    for i, current_id_str in enumerate(processor.user_ids):
        if current_id_str in gnn_user2id:
            gnn_idx = gnn_user2id[current_id_str]
            if gnn_idx < len(gnn_user_weight):
                new_weight[i + 1] = gnn_user_weight[gnn_idx]
                matched += 1
            
    with torch.no_grad():
        model.gnn_user_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        print(f"âœ… Injected into 'model.gnn_user_emb'")

    print(f"âœ… [GNN User Alignment] Matched: {matched}/{len(processor.user_ids)}")
    return model

def verify_gnn_checkpoint_keys(model_path):
    print(f"\nğŸ” [Inspection] Checking keys in: {model_path}")
    
    if not os.path.exists(model_path):
        print("âŒ File not found!")
        return

    try:
        state_dict = torch.load(model_path, map_location='cpu')
        keys = list(state_dict.keys())
        
        print(f"   -> Total Keys: {len(keys)}")
        print("   -> Key Examples:")
        
        # User ê´€ë ¨ í‚¤ í™•ì¸
        user_keys = [k for k in keys if 'user' in k]
        print(f"      ğŸ‘¤ User Keys: {user_keys}")
        
        # Item/Adapter ê´€ë ¨ í‚¤ í™•ì¸
        item_keys = [k for k in keys if 'item' in k or 'adapter' in k]
        print(f"      ğŸ“¦ Item/Adapter Keys: {item_keys}")
        
        # Shape í™•ì¸
        if user_keys:
            print(f"      Shape of {user_keys[0]}: {state_dict[user_keys[0]].shape}")
        
    except Exception as e:
        print(f"âŒ Error reading file: {e}")

def verify_embedding_alignment(model, processor, model_dir):
    # (ìƒëµ: ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼, í•„ìš”ì‹œ ì¶”ê°€)
    pass

# ==========================================
# 3. Model Definition (Fixed)
# ==========================================
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

import torch
import torch.nn as nn
import torch.nn.functional as F

class SequenceCentricFusion(nn.Module):
    """
    [ì„¤ê³„ ì² í•™]
    1. ê²½ìŸ(Softmax)ì„ ì œê±°í•©ë‹ˆë‹¤. SequenceëŠ” ë¬´ì¡°ê±´ 1.0ì˜ ë¹„ì¤‘ì„ ê°€ì§‘ë‹ˆë‹¤.
    2. GNNê³¼ MetaëŠ” Sequence ë²¡í„°ë¥¼ Queryë¡œ ì‚¬ìš©í•˜ì—¬, 
       Sequenceê°€ 'í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•  ë•Œë§Œ' ì •ë³´ê°€ ë”í•´(Add)ì§‘ë‹ˆë‹¤.
    3. ì´ˆê¸°ì—ëŠ” GNN/Meta ë°˜ì˜ë¥ ì„ 0ì— ìˆ˜ë ´í•˜ê²Œ í•˜ì—¬ Sequence í•™ìŠµì„ ê°•ì œí•©ë‹ˆë‹¤.
    """
    def __init__(self, dim=128):
        super().__init__()
        
        # Sequenceê°€ GNN/Metaë¥¼ ì–¼ë§ˆë‚˜ ê°€ì ¸ì˜¬ì§€ ê²°ì •í•˜ëŠ” Gate
        # ì…ë ¥: Sequence (Context)
        # ì¶œë ¥: 2 (GNN gate, Meta gate) -> Softmax ì•„ë‹˜! Sigmoid ì‚¬ìš©
        self.context_gate = nn.Sequential(
            nn.Linear(dim, 64),
            nn.GELU(),
            nn.Linear(64, 2), # [0]: GNN Gate, [1]: Meta Gate
            nn.Sigmoid()      # 0.0 ~ 1.0 ë…ë¦½ì ì¸ í™•ë¥ 
        )
        
        # ì°¨ì› íˆ¬ì˜ (Projector)
        self.gnn_proj = nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.Dropout(0.1)
        )
        
        self.meta_proj = nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.Dropout(0.1)
        )
        
        # ìµœì¢… ì •ë¦¬ëŠ” LayerNormë§Œ (MLP í†µê³¼ X -> ì •ë³´ í¬ì„ ë°©ì§€)
        self.final_ln = nn.LayerNorm(dim)

        # ğŸ”¥ [í•µì‹¬ ì´ˆê¸°í™”]
        # Gateì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ ë°”ì´ì–´ìŠ¤ë¥¼ ìŒìˆ˜ë¡œ ì„¤ì •í•˜ì—¬
        # ì´ˆê¸° Sigmoid ì¶œë ¥ì´ 0ì— ê°€ê¹ê²Œ ë§Œë“¦ (ì˜ˆ: -5 -> sigmoid(-5) â‰ˆ 0.006)
        # ì´ë ‡ê²Œ í•˜ë©´ ì²« Epochì—ëŠ” GNN/Metaê°€ ê±°ì˜ ë°˜ì˜ë˜ì§€ ì•Šê³  Sequenceë§Œ í•™ìŠµë¨.
        nn.init.zeros_(self.context_gate[-2].weight)
        nn.init.constant_(self.context_gate[-2].bias, -5.0) 

    def forward(self, v_gnn, v_seq, v_meta):
        # 1. Gate ê³„ì‚° (Sequenceê°€ ê²°ì •í•¨)
        # gates: (Batch, Seq_Len, 2)
        gates = self.context_gate(v_seq)
        
        g_gnn = gates[..., 0:1]
        g_meta = gates[..., 1:2]
        
        # 2. Residual Addition (ê²½ìŸí•˜ì§€ ì•Šê³  ë”í•˜ê¸°ë§Œ í•¨)
        # v_seq (Main) + (Gate * GNN) + (Gate * Meta)
        # SequenceëŠ” ê³„ìˆ˜ê°€ 1ë¡œ ê³ ì •ì´ë¯€ë¡œ ì ˆëŒ€ ë¬´ì‹œë˜ì§€ ì•ŠìŒ
        fused = v_seq + (g_gnn * self.gnn_proj(v_gnn)) + (g_meta * self.meta_proj(v_meta))
        
        # 3. Norm & Return
        # Gate ê°€ì¤‘ì¹˜ë„ ë¦¬í„´í•˜ì—¬ ë¡œê¹… (í‰ê· ê°’)
        gnn_ratio = g_gnn.mean().item()
        meta_ratio = g_meta.mean().item()
        gate_weights = [gnn_ratio, meta_ratio]

        return self.final_ln(fused), gate_weights

# ==========================================
# ğŸ§© 3. Parallel Adapter (ìœ ì§€)
# ==========================================
class ParallelAdapter(nn.Module):
    def __init__(self, content_dim=128, gnn_dim=64, out_dim=128, dropout=0.2):
        super().__init__()
        self.content_proj = nn.Sequential(
            nn.Linear(content_dim, out_dim),
            nn.LayerNorm(out_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        self.gnn_proj = nn.Sequential(
            nn.Linear(gnn_dim, out_dim),
            nn.LayerNorm(out_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )

    def forward(self, v_content, v_gnn):
        # [ìˆ˜ì •] Content Embeddingì— Residual Connection ì¶”ê°€ (+ v_content)
        # v_content(ì›ë³¸)ê°€ Adapterë¥¼ í†µê³¼í•œ ê²°ê³¼ì™€ ë”í•´ì§ -> ì›ë³¸ ì •ë³´ ë³´ì¡´
        merged = (self.content_proj(v_content) + v_content) + self.gnn_proj(v_gnn)
        return merged

# ==========================================
# ğŸ° Hybrid User Tower (ìˆ˜ì •ë¨)
# ==========================================
class HybridUserTower(nn.Module):
    def __init__(self, num_users, num_items, gnn_user_init, gnn_item_init, item_content_init):
        super().__init__()
        self.embed_dim = 128

        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))
        # 1. Embeddings
        self.gnn_user_emb = nn.Embedding.from_pretrained(gnn_user_init, freeze=False)
        self.gnn_item_emb = nn.Embedding.from_pretrained(gnn_item_init, freeze=False)
        self.item_content_emb = nn.Embedding.from_pretrained(item_content_init, freeze=False)
        
        # 2. Adapters
        self.gnn_projector = nn.Sequential(
            nn.Linear(gnn_user_init.shape[1], 256),
            nn.LayerNorm(256), nn.GELU(), nn.Dropout(DROPOUT),
            nn.Linear(256, 128), nn.LayerNorm(128)
        )
        
        # [ìˆ˜ì •] ParallelAdapter ì‚¬ìš©
        self.seq_adapter = ParallelAdapter(
            content_dim=128, 
            gnn_dim=64, 
            out_dim=128, 
            dropout=DROPOUT
        )
        
        # 3. Sequence Modeling
        self.time_emb = nn.Embedding(1001, 128)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=128, nhead=2, dim_feedforward=512, 
            dropout=DROPOUT, batch_first=True, norm_first=True
        )
        self.seq_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)
        
        # 4. Meta & Fusion
        self.channel_emb = nn.Embedding(2, 32)
        self.meta_mlp = nn.Sequential(
            nn.Linear(35, 128), nn.GELU(),  # Target Layer Monitoring
            nn.Linear(128, 128), nn.LayerNorm(128)
        )
        self.fusion_layer = SequenceCentricFusion(dim=128)
        
        
        
        
    def get_current_temperature(self, clamp_min):
        # ì‚¬ìš©í•  ë•ŒëŠ” expë¥¼ ì·¨í•´ì„œ ì–‘ìˆ˜ë¡œ ë§Œë“¦
        # 1 / exp(scale) = temperature
        # í•˜ì§€ë§Œ ë³´í†µ ê³„ì‚° íš¨ìœ¨ì„ ìœ„í•´ (Cosine Sim * Scale) ë°©ì‹ìœ¼ë¡œ ê³±í•´ë²„ë¦¼
        # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ Loss í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ Temperature ê°’ìœ¼ë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´
        
        # logit_scaleì„ ìµœëŒ€ 100(exp(4.6))ê¹Œì§€ë§Œ ì»¤ì§€ê²Œ ì œí•œ (CLIP ë…¼ë¬¸ í…Œí¬ë‹‰ - ë°œì‚° ë°©ì§€)
        scale = self.logit_scale.exp().clamp(clamp_min, max=100.0)
        
        #clamp(min=14.3)
        # Scale = 1 / Temperature ì´ë¯€ë¡œ,
        # Temperature = 1 / Scale
        return 1.0 / scale
    
    def forward(self, u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat):
        B, L = seq_ids.shape
        
        # 1. GNN User
        v_gnn = self.gnn_projector(self.gnn_user_emb(u_idx))
        v_gnn_seq = F.normalize(v_gnn, p=2, dim=1).unsqueeze(1).expand(-1, L, -1)
        v_gnn_seq = torch.zeros_like(v_gnn_seq)
        if self.training:
            drop_prob = 0.4  # 40% í™•ë¥ ë¡œ GNNì„ ë²„ë¦¼
            keep_prob = 1 - drop_prob
            
            # ë°°ì¹˜ë³„ ë§ˆìŠ¤í¬ ìƒì„± (B, 1, 1)
            mask = torch.bernoulli(torch.full((B, 1, 1), keep_prob, device=v_gnn_seq.device))
            
            # Inverted Dropout: ì‚´ì•„ë‚¨ì€ ì‹ í˜¸ëŠ” keep_probë¡œ ë‚˜ëˆ ì„œ ìŠ¤ì¼€ì¼ ìœ ì§€
            v_gnn_seq = (v_gnn_seq * mask) / keep_prob
        
        # =========================================================
        # [ìˆ˜ì •ëœ ë¶€ë¶„] 2. Dual-View Sequence (Parallel Adapter)
        # =========================================================
        # (1) ì„ë² ë”© êº¼ë‚´ê¸°
        raw_content = self.item_content_emb(seq_ids) # (B, L, 128)
        raw_gnn = self.gnn_item_emb(seq_ids)         # (B, L, 64)
        
        # (2) Adapter í†µê³¼ (ì¸ì 2ê°œ ì „ë‹¬!)
        # ê¸°ì¡´ì—ëŠ” catìœ¼ë¡œ í•©ì³ì„œ ë„£ì—ˆì§€ë§Œ, ì´ì œëŠ” ë”°ë¡œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.
        seq_input = self.seq_adapter(raw_content, raw_gnn) # <--- ì—¬ê¸°ê°€ ìˆ˜ì •ë¨!
        
        # (3) Time Embedding
        seq_input = seq_input  * math.sqrt(self.embed_dim) + self.time_emb(seq_deltas.clamp(max=1000))
        
        # =========================================================
        
        causal_mask = torch.triu(torch.ones(L, L, device=seq_ids.device) * float('-inf'), diagonal=1)
        key_padding_mask = (seq_mask == 0)
        
        seq_out = self.seq_encoder(seq_input, mask=causal_mask, src_key_padding_mask=key_padding_mask)
        v_seq = F.normalize(seq_out, p=2, dim=2)

        cat_vec = self.channel_emb(u_cat)
        v_meta = self.meta_mlp(torch.cat([u_dense, cat_vec], dim=1))
        v_meta_seq = F.normalize(v_meta, p=2, dim=1).unsqueeze(1).expand(-1, L, -1)
        
        output, gate_weights = self.fusion_layer(v_gnn_seq, v_seq, v_meta_seq)
        output = F.normalize(output, p=2, dim=2)
        return output, v_seq, gate_weights
    def get_meta_feature_importance(self):
        """
        Meta MLPì˜ ì²« ë²ˆì§¸ Linear Layer ê°€ì¤‘ì¹˜ë¥¼ ë¶„ì„í•˜ì—¬
        ì–´ë–¤ Featureê°€ ê°€ì¥ ì˜í–¥ë ¥ì´ í°ì§€ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        # ì²« ë²ˆì§¸ Linear Layerì˜ ê°€ì¤‘ì¹˜: (Out_Dim, In_Dim) -> (128, 35)
        weight_matrix = self.meta_mlp[0].weight.abs().detach().cpu()
        
        # Input Dimension Slicing
        # Price: 0~32, Cnt: 32~64, Recency: 64~96, Channel: 96~112
        imp_price = weight_matrix[:, 0:32].mean().item()
        imp_cnt = weight_matrix[:, 32:64].mean().item()
        imp_recency = weight_matrix[:, 64:96].mean().item()
        imp_channel = weight_matrix[:, 96:112].mean().item()
        
        # ì •ê·œí™” (ë¹„ìœ¨ë¡œ ë³´ê¸° ìœ„í•´)
        total = imp_price + imp_cnt + imp_recency + imp_channel + 1e-9
        return {
            "Price": imp_price / total,
            "Count": imp_cnt / total,
            "Recency": imp_recency / total,
            "Channel": imp_channel / total
        }
# ==========================================
# 4. Loss & Eval
# ==========================================
def logq_correction_loss(user_emb, item_emb, pos_item_ids, item_probs, temperature=0.07, lambda_logq=0.0):
    scores = torch.matmul(user_emb, item_emb.T)
    if lambda_logq > 0.0:
        
        log_q = torch.log(item_probs[pos_item_ids] + 1e-4).view(1, -1)
        scores = scores - (lambda_logq * log_q)
    logits = scores / temperature
    is_collision = (pos_item_ids.unsqueeze(1) == pos_item_ids.unsqueeze(0))
    mask = is_collision.fill_diagonal_(False)
    logits = logits.masked_fill(mask, -1e4)
    labels = torch.arange(logits.size(0), device=logits.device)
    return F.cross_entropy(logits, labels)

def efficient_corrected_logq_loss(
    user_emb, 
    item_emb, 
    pos_item_ids, 
    precomputed_log_q, 
    temperature=0.1, 
    lambda_logq=0.1
):
    # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬ (ë””ë²„ê¹…ìš©, ì‹¤ì œ í•™ìŠµì‹œ ì„±ëŠ¥ ì˜í–¥ ë¯¸ë¯¸)
    assert pos_item_ids.max() < precomputed_log_q.size(0), "pos_item_ids contains out-of-bounds index!"
    logits = torch.matmul(user_emb, item_emb.T)
    logits.div_(temperature) # logits /= temperature (In-place)
    
    if lambda_logq > 0.0:
        # 2. LogQ Correction (In-place)
        # precomputed_log_qì—ì„œ í˜„ì¬ ë°°ì¹˜ì˜ ê°’ë§Œ ìŠ¬ë¼ì´ì‹± (View ìƒì„±)
        batch_log_q = precomputed_log_q[pos_item_ids].view(1, -1)
        
        # In-place subtraction: ìƒˆë¡œìš´ í…ì„œ í• ë‹¹ ìµœì†Œí™”
        logits.sub_(batch_log_q * lambda_logq)
        
        # 3. Positive Recovery (RecSys 2025)
        # torch.sum ëŒ€ì‹  einsumì„ ì“°ë©´ ê°€ë” íŠ¹ì • CUDA ë²„ì „ì—ì„œ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.
        pos_logits_raw = torch.einsum('bd,bd->b', user_emb, item_emb).div_(temperature)
        logits.diagonal().copy_(pos_logits_raw)

    # 4. Collision Masking (ë©”ëª¨ë¦¬ ì ˆì•½í˜•)
    with torch.no_grad():
        is_collision = (pos_item_ids.unsqueeze(1) == pos_item_ids.unsqueeze(0))
        mask = is_collision.fill_diagonal_(False)
    
    # FP16 AMP ì‚¬ìš© ì‹œ -3e4ê°€ ì•ˆì „ (Underflow ë°©ì§€)
    mask_value = -30000.0 if logits.dtype == torch.float16 else -1e9
    logits.masked_fill_(mask, mask_value)

    # 5. Labels ìƒì„± (ë§¤ë²ˆ ìƒì„±í•˜ì§€ ì•Šê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ì´ ì •ë„ëŠ” ë¯¸ë¯¸í•¨)
    labels = torch.arange(logits.size(0), device=logits.device)
    
    return F.cross_entropy(logits, labels)







def evaluate_multi_vector_ensemble(
    seq_model, processor, target_df_path, gnn_user_matrix, gnn_item_matrix, 
    device, k_list=[20, 100, 500], batch_size=4096, 
    alpha_step=0.2
):
    """
    Multi-Vector Retrieval Ensemble Evaluation
    
    Logic:
      1. GNNê³¼ Seq Modelì´ ê°ê° ë…ë¦½ì ìœ¼ë¡œ User Vectorì™€ Item Vectorë¥¼ ìƒì„±.
      2. ê°ê° ì „ì²´ ì•„ì´í…œì— ëŒ€í•´ Score ê³„ì‚° í›„ Top-K(Max) ì¶”ì¶œ.
      3. ì§€ì •ëœ ë¹„ìœ¨(Alpha)ì— ë”°ë¼ GNNì˜ ìƒìœ„ Nê°œì™€ Seqì˜ ìƒìœ„ Mê°œë¥¼ í˜¼í•©í•˜ì—¬ ìµœì¢… ì¶”ì²œ ë¦¬ìŠ¤íŠ¸ êµ¬ì„±.
      
    Args:
      alpha: GNNì˜ ë°˜ì˜ ë¹„ìœ¨ (1.0 = GNN Only, 0.0 = Seq Only)
    """
    max_k = max(k_list)
    print(f"\nğŸš€ Starting Multi-Vector Retrieval Ensemble (Max K: {max_k})...")
    
    seq_model.eval()
    
    # ---------------------------------------------------------
    # 1. Target Data Load & Valid Loader
    # ---------------------------------------------------------
    target_df = pd.read_parquet(target_df_path)
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, shuffle=False, collate_fn=user_tower_collate_fn
    )
    
    # ---------------------------------------------------------
    # 2. Pre-computation (Global Item Vectors)
    # ---------------------------------------------------------
    print("âš¡ Pre-computing Item Vectors for both models...")
    with torch.no_grad():
        all_item_ids = torch.arange(1, len(processor.item_ids)+1).to(device)
        
        # [Seq Model] Item Vectors
        seq_item_vecs_list = []
        for i in range(0, len(all_item_ids), 4096):
            chunk = all_item_ids[i:i+4096]
            c_emb = seq_model.item_content_emb(chunk)
            g_emb = seq_model.gnn_item_emb(chunk)
            c_vec = seq_model.seq_adapter(c_emb, g_emb)
            seq_item_vecs_list.append(F.normalize(c_vec, p=2, dim=1))
        all_seq_item_vecs = torch.cat(seq_item_vecs_list, dim=0)

        # [GNN Model] Item Vectors
        # index 0 is padding, so start from 1
        all_gnn_item_vecs = F.normalize(gnn_item_matrix[1:].to(device), p=2, dim=1)

    # ---------------------------------------------------------
    # 3. Setup Evaluation Metrics
    # ---------------------------------------------------------
    # Alpha: 1.0 (GNN 100%) ~ 0.0 (Seq 100%)
    alphas = [round(x, 1) for x in np.arange(1.0, -0.01, -alpha_step)]
    
    # Results Container: {Alpha: {K: Count}}
    results = {a: {k: 0 for k in k_list} for a in alphas}
    total_users = 0
    
    # ---------------------------------------------------------
    # 4. Evaluation Loop
    # ---------------------------------------------------------
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="   -> Multi-Vector Retrieval"):
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, _, _ = [x.to(device) for x in batch]
            
            # ìœ íš¨ ìœ ì € í•„í„°ë§
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            
            if not valid_idx_list: continue
            
            # ìœ íš¨í•œ ì¸ë±ìŠ¤ë§Œ í…ì„œë¡œ ë³€í™˜
            v_idx = torch.tensor(valid_idx_list).to(device)
            current_batch_size = len(v_idx)
            
            # =========================================================
            # [Step A] Independent Inference (Vector Generation)
            # =========================================================
            
            # A-1. GNN User Vectors
            user_gnn_vecs = gnn_user_matrix[u_idx[v_idx]].to(device)
            user_gnn_vecs = F.normalize(user_gnn_vecs, p=2, dim=1)
            
            # A-2. Seq User Vectors
            output = seq_model(
                u_idx[v_idx], seq_ids[v_idx], seq_deltas[v_idx], seq_mask[v_idx], u_dense[v_idx], u_cat[v_idx]
            )
            if isinstance(output, tuple): output = output[0]
            lengths = seq_mask[v_idx].sum(dim=1)
            last_indices = (lengths - 1).clamp(min=0)
            user_seq_vecs = output[torch.arange(current_batch_size), last_indices]
            user_seq_vecs = F.normalize(user_seq_vecs, p=2, dim=1) # Normalize for Cosine Sim
            
            # =========================================================
            # [Step B] Independent Retrieval (Top-K per Model)
            # =========================================================
            
            # B-1. GNN Retrieval (Batch Matmul)
            # (Batch, Dim) @ (Num_Items, Dim).T -> (Batch, Num_Items)
            scores_gnn = torch.matmul(user_gnn_vecs, all_gnn_item_vecs.T)
            # ê°€ì¥ í° Kì— ëŒ€í•´ì„œë§Œ ë¯¸ë¦¬ ì¶”ì¶œ (CPUë¡œ ì˜®ê²¨ì„œ ë³‘í•© ì—°ì‚° ë¶€í•˜ ì¤„ì´ê¸° ìœ„í•¨)
            _, indices_gnn = torch.topk(scores_gnn, k=max_k, dim=1)
            indices_gnn = indices_gnn.cpu().numpy()
            
            # B-2. Seq Retrieval
            scores_seq = torch.matmul(user_seq_vecs, all_seq_item_vecs.T)
            _, indices_seq = torch.topk(scores_seq, k=max_k, dim=1)
            indices_seq = indices_seq.cpu().numpy()
            
            # =========================================================
            # [Step C] Ratio-based Merging & Scoring
            # =========================================================
            
            # íƒ€ê²Ÿ ì •ë‹µì§€ ì¤€ë¹„
            batch_target_sets = []
            for original_idx in valid_idx_list:
                u_id = batch_uids[original_idx]
                # item_id to index (0-based) conversion needed if item_vecs are 0-based
                # Note: indices_gnn/seq returns 0-based index of all_item_ids.
                # all_item_ids[k] corresponds to ItemID k+1.
                # So indices match (ItemID - 1).
                actual_indices = set(processor.item2id[tid] - 1 for tid in target_dict[u_id] if tid in processor.item2id)
                batch_target_sets.append(actual_indices)
            
            # Alpha Loop
            for alpha in alphas:
                # ê° Kì— ëŒ€í•´ í˜¼í•© ë¹„ìœ¨ ì ìš©
                for k in k_list:
                    # ë¹„ìœ¨ ê³„ì‚° (GNN ê°œìˆ˜, Seq ê°œìˆ˜)
                    n_gnn = int(k * alpha)
                    n_seq = k - n_gnn
                    
                    # Batch ë‚´ ê° ìœ ì €ë³„ë¡œ í˜¼í•© ìˆ˜í–‰
                    for u in range(current_batch_size):
                        actual = batch_target_sets[u]
                        if not actual: continue
                        
                        # 1. GNNì—ì„œ ìƒìœ„ n_gnnê°œ ì¶”ì¶œ
                        # 2. Seqì—ì„œ ìƒìœ„ n_seqê°œ ì¶”ì¶œ
                        # 3. í•©ì§‘í•© (ìˆœì„œëŠ” ìƒê´€ì—†ìŒ, Recall ì¸¡ì •ìš© Set)
                        
                        # ìŠ¬ë¼ì´ì‹± ì‹œ n=0ì´ë©´ ë¹ˆ ë°°ì—´ ë°˜í™˜
                        set_gnn = set(indices_gnn[u, :n_gnn]) if n_gnn > 0 else set()
                        set_seq = set(indices_seq[u, :n_seq]) if n_seq > 0 else set()
                        
                        # Multi-Source Merge
                        pred_set = set_gnn | set_seq
                        
                        # Recall Check
                        # (êµì§‘í•©ì´ í•˜ë‚˜ë¼ë„ ìˆìœ¼ë©´ Hit)
                        if not actual.isdisjoint(pred_set):
                            results[alpha][k] += 1

            total_users += len(valid_idx_list)

    # ---------------------------------------------------------
    # 5. Report
    # ---------------------------------------------------------
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Multi-Vector Ensemble Report (Total Users: {total_users})")
    print(f"{'-'*80}")
    
    header = f"{'Alpha(GNN)':<12} | {'GNN:Seq Ratio':<15}"
    for k in k_list:
        header += f" | {f'Recall@{k}':<12}"
    print(header)
    print(f"{'-'*80}")
    
    best_alpha = -1
    best_score = -1
    
    # Sort alphas desc (1.0 -> 0.0)
    for alpha in sorted(results.keys(), reverse=True):
        scores = {}
        for k in k_list:
            scores[k] = results[alpha].get(k, 0) / total_users if total_users > 0 else 0
            
        row_str = f"{alpha:<12.1f} | {f'{int(alpha*10)} : {int((1-alpha)*10)}':<15}"
        for k in k_list:
            row_str += f" | {scores[k]:<12.4f}"
        print(row_str)
        
        # Best Selection (Based on smallest K usually, or largest K)
        # Here we use the first K (Recall@20) as primary metric
        if scores[k_list[0]] > best_score:
            best_score = scores[k_list[0]]
            best_alpha = alpha
            
    print(f"{'='*80}")
    print(f"ğŸ† Best Ensemble Ratio (GNN): {best_alpha}")
    
    return best_alpha

import torch.nn.functional as F
import pandas as pd
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader

def evaluate_weighted_score_ensemble(
    seq_model, processor, target_df_path, gnn_user_matrix, gnn_item_matrix, 
    device, k_list=[20, 100, 500], batch_size=4096, 
    alpha_step=0.1, candidate_pool_size=1000
):
    """
    Weighted Score Fusion Ensemble Evaluation (Late Fusion)
    
    Logic:
      1. ê° ëª¨ë¸ë³„ë¡œ ë„‰ë„‰í•œ í›„ë³´êµ°(candidate_pool_size)ì„ ì¶”ì¶œí•˜ì—¬ í•©ì§‘í•©(Union)ì„ ë§Œë“­ë‹ˆë‹¤.
      2. í•©ì³ì§„ í›„ë³´êµ° ì•„ì´í…œì— ëŒ€í•´ ë‘ ëª¨ë¸ì˜ Scoreë¥¼ ê°ê° ê³„ì‚°í•©ë‹ˆë‹¤.
      3. Min-Max Normalizationì„ ì ìš©í•˜ì—¬ ì ìˆ˜ ìŠ¤ì¼€ì¼ì„ ë§ì¶¥ë‹ˆë‹¤.
      4. Alpha ë¹„ìœ¨ëŒ€ë¡œ ê°€ì¤‘ í•©ì‚°(Weighted Sum)í•˜ì—¬ ìµœì¢… ë­í‚¹ì„ ì‚°ì¶œí•©ë‹ˆë‹¤.
    """
    max_k = max(k_list)
    # í›„ë³´êµ° ì‚¬ì´ì¦ˆëŠ” ëª©í‘œ Kë³´ë‹¤ ì»¤ì•¼ ì•™ìƒë¸” íš¨ê³¼ê°€ ë‚©ë‹ˆë‹¤. (ë³´í†µ 2~5ë°° ì¶”ì²œ)
    pool_k = max(candidate_pool_size, max_k * 2)
    
    print(f"\nğŸš€ Starting Weighted Score Ensemble (Pool K: {pool_k} -> Select Top K)...")
    
    seq_model.eval()
    
    # ---------------------------------------------------------
    # 1. Target Data & Loader
    # ---------------------------------------------------------
    target_df = pd.read_parquet(target_df_path)
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, shuffle=False, collate_fn=user_tower_collate_fn
    )
    
    # ---------------------------------------------------------
    # 2. Pre-computation (Item Vectors)
    # ---------------------------------------------------------
    print("âš¡ Pre-computing Item Vectors...")
    with torch.no_grad():
        all_item_ids = torch.arange(1, len(processor.item_ids)+1).to(device)
        
        # [Seq Model]
        seq_item_vecs_list = []
        for i in range(0, len(all_item_ids), 4096):
            chunk = all_item_ids[i:i+4096]
            c_emb = seq_model.item_content_emb(chunk)
            g_emb = seq_model.gnn_item_emb(chunk)

            c_vec = seq_model.seq_adapter(c_emb, g_emb)
            seq_item_vecs_list.append(F.normalize(c_vec, p=2, dim=1))
        all_seq_item_vecs = torch.cat(seq_item_vecs_list, dim=0)

        # [GNN Model]
        all_gnn_item_vecs = F.normalize(gnn_item_matrix[1:].to(device), p=2, dim=1)

    # ---------------------------------------------------------
    # 3. Evaluation Setup
    # ---------------------------------------------------------
    alphas = [round(x, 1) for x in np.arange(1.0, -0.01, -alpha_step)]
    results = {a: {k: 0 for k in k_list} for a in alphas}
    total_users = 0
    
    
    
    # ---------------------------------------------------------
    # 4. Main Loop
    # ---------------------------------------------------------
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="   -> Weighted Score Fusion"):
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, _, _ = [x.to(device) for x in batch]
            
            # ìœ íš¨ ìœ ì € í•„í„°ë§
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            
            if not valid_idx_list: continue
            v_idx = torch.tensor(valid_idx_list).to(device)
            current_batch_size = len(v_idx)
            
            # =========================================================
            # [Step A] User Vector Generation
            # =========================================================
            # GNN User Vec
            user_gnn_vecs = gnn_user_matrix[u_idx[v_idx]].to(device)
            user_gnn_vecs = F.normalize(user_gnn_vecs, p=2, dim=1)
            
            # Seq User Vec
            output = seq_model(
                u_idx[v_idx], seq_ids[v_idx], seq_deltas[v_idx], seq_mask[v_idx], u_dense[v_idx], u_cat[v_idx]
            )
            if isinstance(output, tuple): output = output[0]
            lengths = seq_mask[v_idx].sum(dim=1)
            last_indices = (lengths - 1).clamp(min=0)
            user_seq_vecs = output[torch.arange(current_batch_size), last_indices]
            # NormalizeëŠ” Cosine Similarity ê³„ì‚°ì„ ìœ„í•´ í•„ìˆ˜ (íŠ¹íˆ Score Fusionì—ì„œ ìŠ¤ì¼€ì¼ ì˜í–¥ ìµœì†Œí™”)
            user_seq_vecs = F.normalize(user_seq_vecs, p=2, dim=1)

            # =========================================================
            # [Step B] Candidate Pool Generation (Union of Top-M)
            # =========================================================
            # ëª¨ë“  ì•„ì´í…œì— ëŒ€í•´ ê³„ì‚°í•˜ë©´ ëŠë¦¬ë¯€ë¡œ, ê° ëª¨ë¸ì˜ Top-Mê°œë¥¼ ë½‘ì•„ í•©ì§‘í•©ì„ ë§Œë“­ë‹ˆë‹¤.
            
            # GNN Global Scores
            scores_gnn_all = torch.matmul(user_gnn_vecs, all_gnn_item_vecs.T)
            _, indices_gnn_top = torch.topk(scores_gnn_all, k=pool_k, dim=1)
            
            # Seq Global Scores
            scores_seq_all = torch.matmul(user_seq_vecs, all_seq_item_vecs.T)
            _, indices_seq_top = torch.topk(scores_seq_all, k=pool_k, dim=1)
            
            # Union Indices (Smart Gathering)
            # ë°°ì¹˜ ë‚´ ê° ìœ ì €ë³„ë¡œ í›„ë³´ ì•„ì´í…œ ì¸ë±ìŠ¤ë¥¼ ëª¨ìë‹ˆë‹¤.
            # íš¨ìœ¨ì ì¸ ë³‘ë ¬ ì²˜ë¦¬ë¥¼ ìœ„í•´ gather ë°©ì‹ì„ ì‚¬ìš©í•©ë‹ˆë‹¤.
            
            # (Batch, 2 * pool_k) í˜•íƒœë¡œ ë³‘í•©
            combined_indices = torch.cat([indices_gnn_top, indices_seq_top], dim=1)
            
            # =========================================================
            # [Step C] Score Calculation on Union Set
            # =========================================================
            # ê° ìœ ì €ë³„ë¡œ ì„ íƒëœ ì•„ì´í…œë“¤ì˜ Vectorë§Œ ê°€ì ¸ì™€ì„œ ë‚´ì  (Efficient)
            
            # 1. Gather Item Vectors based on Combined Indices
            # combined_indices: (Batch, Pool_Size) -> flattened for gathering
            flat_indices = combined_indices.view(-1)
            
            # (Batch * Pool_Size, Dim)
            batch_gnn_items = all_gnn_item_vecs[flat_indices].view(current_batch_size, -1, all_gnn_item_vecs.shape[1])
            batch_seq_items = all_seq_item_vecs[flat_indices].view(current_batch_size, -1, all_seq_item_vecs.shape[1])
            
            # 2. Recalculate Scores (User * Item)
            # (Batch, 1, Dim) * (Batch, Pool_Size, Dim) -> sum -> (Batch, Pool_Size)
            s_gnn = (user_gnn_vecs.unsqueeze(1) * batch_gnn_items).sum(dim=-1)
            s_seq = (user_seq_vecs.unsqueeze(1) * batch_seq_items).sum(dim=-1)
            
            # =========================================================
            # [Step D] Min-Max Normalization (Crucial!)
            # =========================================================
            # ëª¨ë¸ë§ˆë‹¤ ì ìˆ˜ ë¶„í¬(í‰ê· , ë¶„ì‚°)ê°€ ë‹¤ë¥´ë¯€ë¡œ 0~1 ì‚¬ì´ë¡œ ë§ì¶°ì¤ë‹ˆë‹¤.
            def min_max_norm(tensor):
                min_val = tensor.min(dim=1, keepdim=True)[0]
                max_val = tensor.max(dim=1, keepdim=True)[0]
                return (tensor - min_val) / (max_val - min_val + 1e-9)
            
            s_gnn_norm = min_max_norm(s_gnn)
            s_seq_norm = min_max_norm(s_seq)
            
            # íƒ€ê²Ÿ ì •ë‹µì§€ ì¤€ë¹„
            batch_targets = []
            for original_idx in valid_idx_list:
                u_id = batch_uids[original_idx]
                actual_indices = set(processor.item2id[tid] - 1 for tid in target_dict[u_id] if tid in processor.item2id)
                batch_targets.append(actual_indices)
                
            # combined_indices (Local Index -> Global Index ë§¤í•‘ìš©)
            combined_indices_cpu = combined_indices.cpu().numpy()
            
            # =========================================================
            # [Step E] Alpha Sweep & Metric
            # =========================================================
            for alpha in alphas:
                # Weighted Sum
                final_scores = alpha * s_gnn_norm + (1.0 - alpha) * s_seq_norm
                
                # Top-K Selection (Local Index)
                # ì—¬ê¸°ì„œ ì¤‘ë³µëœ ì•„ì´í…œì´ ìˆì„ ìˆ˜ ìˆìŒ (Union ê³¼ì •ì—ì„œ) -> í•˜ì§€ë§Œ ì ìˆ˜ëŠ” ë™ì¼í•˜ë¯€ë¡œ ë¬¸ì œ ì—†ìŒ
                # ë‹¤ë§Œ ì™„ë²½ì„ ìœ„í•´ TopK í›„ Global IDë¡œ ë³€í™˜í•˜ì—¬ ì¤‘ë³µ ì œê±° í•„ìš”í•  ìˆ˜ ìˆìœ¼ë‚˜,
                # topkê°€ ì¶©ë¶„íˆ í¬ì§€ ì•Šìœ¼ë©´ í° ì˜í–¥ ì—†ìŒ. ì •ì„ëŒ€ë¡œë¼ë©´ unique ì²˜ë¦¬ê°€ í•„ìš”.
                # ì—¬ê¸°ì„œëŠ” ì†ë„ë¥¼ ìœ„í•´ ë°”ë¡œ TopK í›„ ê²€ì¦ ë‹¨ê³„ì—ì„œ Setìœ¼ë¡œ ì²˜ë¦¬.
                
                _, local_topk_indices = torch.topk(final_scores, k=max_k + 20, dim=1) # ë„‰ë„‰íˆ ì¶”ì¶œ (ì¤‘ë³µ ëŒ€ë¹„)
                local_topk_indices = local_topk_indices.cpu().numpy()
                
                for i, actual_indices in enumerate(batch_targets):
                    if not actual_indices: continue
                    
                    # Local Index -> Global Item ID ë³µì›
                    # combined_indices[i] : í•´ë‹¹ ìœ ì €ì˜ í›„ë³´êµ° ê¸€ë¡œë²Œ IDë“¤
                    # local_topk_indices[i] : ê·¸ í›„ë³´êµ° ì•ˆì—ì„œì˜ ë“±ìˆ˜
                    pred_global_ids = combined_indices_cpu[i][local_topk_indices[i]]
                    
                    # ì¤‘ë³µ ì œê±°í•˜ë©´ì„œ Top-K ìœ ì§€ (unique_preserve_order)
                    _, unique_idx = np.unique(pred_global_ids, return_index=True)
                    pred_unique = pred_global_ids[np.sort(unique_idx)]
                    
                    for k in k_list:
                        # ìƒìœ„ Kê°œë§Œ ì˜ë¼ì„œ ì •ë‹µ í™•ì¸
                        top_k_items = pred_unique[:k]
                        if not actual_indices.isdisjoint(top_k_items):
                            results[alpha][k] += 1
                            
            total_users += len(valid_idx_list)

    # ---------------------------------------------------------
    # 5. Report
    # ---------------------------------------------------------
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Weighted Score Fusion Report (Pool: {pool_k})")
    print(f"{'-'*80}")
    
    header = f"{'Alpha(GNN)':<12} | {'GNN:Seq Ratio':<15}"
    for k in k_list:
        header += f" | {f'Recall@{k}':<12}"
    print(header)
    print(f"{'-'*80}")
    
    best_alpha = -1
    best_score = -1
    
    for alpha in sorted(results.keys(), reverse=True):
        scores = {}
        for k in k_list:
            scores[k] = results[alpha].get(k, 0) / total_users if total_users > 0 else 0
            
        row_str = f"{alpha:<12.1f} | {f'{int(alpha*10)} : {int((1-alpha)*10)}':<15}"
        for k in k_list:
            row_str += f" | {scores[k]:<12.4f}"
        print(row_str)
        
        # Best Metric Update (Recall@20 ê¸°ì¤€)
        if scores[k_list[0]] > best_score:
            best_score = scores[k_list[0]]
            best_alpha = alpha
            
    print(f"{'='*80}")
    print(f"ğŸ† Best Weighted Alpha: {best_alpha}")
    
    return best_alpha
# ==========================================
# 6. Main Execution Flow
# ==========================================
import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader

def evaluate_rrf_ensemble(
    seq_model, processor, target_df_path, gnn_user_matrix, gnn_item_matrix, 
    device, k_list=[20, 100, 500], batch_size=4096, 
    alpha_step=0.1, candidate_pool_size=1000, k_rrf=200
):
    """
    Weighted RRF (Reciprocal Rank Fusion) Ensemble Evaluation
    
    Logic:
      1. GNNê³¼ Seq ëª¨ë¸ì´ ê°ê° Top-N í›„ë³´ë¥¼ ë½‘ì•„ í•©ì§‘í•©(Union)ì„ ë§Œë“­ë‹ˆë‹¤.
      2. í•©ì³ì§„ í›„ë³´êµ°ì— ëŒ€í•´ ë‘ ëª¨ë¸ì˜ ì ìˆ˜ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•©ë‹ˆë‹¤.
      3. ì ìˆ˜ ëŒ€ì‹  **ë“±ìˆ˜(Rank)**ë¥¼ ì‚°ì¶œí•©ë‹ˆë‹¤.
      4. RRF ê³µì‹: Score = alpha * (1 / (k_rrf + rank1)) + (1-alpha) * (1 / (k_rrf + rank2))
      
    Args:
      k_rrf: RRF ìƒìˆ˜ë¡œ, ë³´í†µ 60ì„ ë§ì´ ì‚¬ìš©í•©ë‹ˆë‹¤. (ë­í‚¹ì´ ë‚®ì•„ë„ ì ìˆ˜ê°€ ë„ˆë¬´ 0ì´ ë˜ì§€ ì•Šê²Œ ì™„í™”)
    """
    max_k = max(k_list)
    pool_k = max(candidate_pool_size, max_k * 2)
    
    print(f"\nğŸš€ Starting Weighted RRF Ensemble (Pool K: {pool_k}, RRF Constant: {k_rrf})...")
    
    seq_model.eval()
    
    # ---------------------------------------------------------
    # 1. Target Data & Loader (ê¸°ì¡´ê³¼ ë™ì¼)
    # ---------------------------------------------------------
    target_df = pd.read_parquet(target_df_path)
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, shuffle=False, collate_fn=user_tower_collate_fn
    )
    
    # ---------------------------------------------------------
    # 2. Pre-computation (Item Vectors) (ê¸°ì¡´ê³¼ ë™ì¼)
    # ---------------------------------------------------------
    print("âš¡ Pre-computing Item Vectors...")
    with torch.no_grad():
        all_item_ids = torch.arange(1, len(processor.item_ids)+1).to(device)
        
        # [Seq Model]
        seq_item_vecs_list = []
        for i in range(0, len(all_item_ids), 4096):
            chunk = all_item_ids[i:i+4096]
            c_emb = seq_model.item_content_emb(chunk)
            g_emb = seq_model.gnn_item_emb(chunk)
            c_vec = seq_model.seq_adapter(c_emb, g_emb)
            seq_item_vecs_list.append(F.normalize(c_vec, p=2, dim=1))
        all_seq_item_vecs = torch.cat(seq_item_vecs_list, dim=0)

        # [GNN Model]
        all_gnn_item_vecs = F.normalize(gnn_item_matrix[1:].to(device), p=2, dim=1)

    # ---------------------------------------------------------
    # 3. Evaluation Setup
    # ---------------------------------------------------------
    alphas = [round(x, 1) for x in np.arange(1.0, -0.01, -alpha_step)]
    results = {a: {k: 0 for k in k_list} for a in alphas}
    total_users = 0
    
    # RRF ë­í‚¹ ê³„ì‚°ì„ ìœ„í•œ í—¬í¼ í…ì„œ (ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•¨)
    # ë¯¸ë¦¬ ë§Œë“¤ì§€ ì•Šê³  ë°°ì¹˜ ë£¨í”„ ì•ˆì—ì„œ ìƒì„±
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="   -> Weighted RRF Ranking"):
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, _, _ = [x.to(device) for x in batch]
            
            # ìœ íš¨ ìœ ì € í•„í„°ë§
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            
            if not valid_idx_list: continue
            v_idx = torch.tensor(valid_idx_list).to(device)
            current_batch_size = len(v_idx)
            
            # =========================================================
            # [Step A] User Vector Generation
            # =========================================================
            user_gnn_vecs = F.normalize(gnn_user_matrix[u_idx[v_idx]].to(device), p=2, dim=1)
            
            output = seq_model(u_idx[v_idx], seq_ids[v_idx], seq_deltas[v_idx], seq_mask[v_idx], u_dense[v_idx], u_cat[v_idx])
            if isinstance(output, tuple): output = output[0]
            lengths = seq_mask[v_idx].sum(dim=1)
            last_indices = (lengths - 1).clamp(min=0)
            user_seq_vecs = F.normalize(output[torch.arange(current_batch_size), last_indices], p=2, dim=1)

            # =========================================================
            # [Step B] Candidate Pool Generation (Union)
            # =========================================================
            # ê° ëª¨ë¸ë³„ Top-K ì¶”ì¶œ (ì†ë„ë¥¼ ìœ„í•´)
            scores_gnn_all = torch.matmul(user_gnn_vecs, all_gnn_item_vecs.T)
            _, indices_gnn_top = torch.topk(scores_gnn_all, k=pool_k, dim=1)
            
            scores_seq_all = torch.matmul(user_seq_vecs, all_seq_item_vecs.T)
            _, indices_seq_top = torch.topk(scores_seq_all, k=pool_k, dim=1)
            
            # Union Indices (Batch, 2 * pool_k)
            combined_indices = torch.cat([indices_gnn_top, indices_seq_top], dim=1)
            
            # =========================================================
            # [Step C] Score Recalculation (For Ranking)
            # =========================================================
            flat_indices = combined_indices.view(-1)
            batch_gnn_items = all_gnn_item_vecs[flat_indices].view(current_batch_size, -1, all_gnn_item_vecs.shape[1])
            batch_seq_items = all_seq_item_vecs[flat_indices].view(current_batch_size, -1, all_seq_item_vecs.shape[1])
            
            # (Batch, Pool_Size) - ì ìˆ˜ ê³„ì‚°
            raw_scores_gnn = (user_gnn_vecs.unsqueeze(1) * batch_gnn_items).sum(dim=-1)
            raw_scores_seq = (user_seq_vecs.unsqueeze(1) * batch_seq_items).sum(dim=-1)
            
            # =========================================================
            # [Step D] Convert Scores to Ranks (í•µì‹¬ ë³€ê²½ ë¶€ë¶„)
            # =========================================================
            # RRFë¥¼ ìœ„í•´ì„œëŠ” ì ìˆ˜ê°€ ì•„ë‹ˆë¼ 'ìˆœìœ„(Rank)'ê°€ í•„ìš”í•©ë‹ˆë‹¤.
            # torch.argsort(descending=True)ë¥¼ ë‘ ë²ˆ ì“°ë©´ ë­í¬ë¥¼ ì–»ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
            # ì˜ˆ: scores=[0.1, 0.9, 0.5] -> argsort1=[1, 2, 0] (ì¸ë±ìŠ¤) -> argsort2=[2, 0, 1] (ë­í¬: 0.9ê°€ 0ë“±)
            
            # 1. Sortí•˜ì—¬ ì¸ë±ìŠ¤ í™•ë³´
            _, sorted_idx_gnn = torch.sort(raw_scores_gnn, dim=1, descending=True)
            _, sorted_idx_seq = torch.sort(raw_scores_seq, dim=1, descending=True)
            
            # 2. ì›ë˜ ìœ„ì¹˜ì— ë­í¬(ë“±ìˆ˜) í• ë‹¹ (Scatter)
            # 0ë“±ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ +1ì€ ë‚˜ì¤‘ì— RRF ê³µì‹ì—ì„œ ì²˜ë¦¬í•˜ê±°ë‚˜ ì—¬ê¸°ì„œ ë¯¸ë¦¬ ì²˜ë¦¬
            rank_gnn = torch.zeros_like(raw_scores_gnn)
            rank_seq = torch.zeros_like(raw_scores_seq)
            
            # arangeë¥¼ ë°°ì¹˜ í¬ê¸°ë§Œí¼ í™•ì¥ (0, 1, ..., Pool_Size-1)
            ranks_range = torch.arange(combined_indices.size(1)).to(device).expand(current_batch_size, -1)
            
            # sorted_idx ìœ„ì¹˜ì— 0, 1, 2... ìˆœì„œëŒ€ë¡œ ê°’ì„ ë¿Œë ¤ì¤Œ
            rank_gnn.scatter_(1, sorted_idx_gnn, ranks_range.float())
            rank_seq.scatter_(1, sorted_idx_seq, ranks_range.float())
            
            # =========================================================
            # [Step E] RRF & Alpha Sweep
            # =========================================================
            # RRF Formula: 1 / (k + rank + 1)  (RankëŠ” 0-basedë¼ ê°€ì •ì‹œ +1 í•„ìš”, í˜¹ì€ kì— í¬í•¨)
            # ì—¬ê¸°ì„œëŠ” Rankê°€ 0ë¶€í„° ì‹œì‘í•˜ë¯€ë¡œ (k_rrf + rank + 1)ë¡œ ê³„ì‚°
            
            rrf_score_gnn = 1.0 / (k_rrf + rank_gnn + 1.0)
            rrf_score_seq = 1.0 / (k_rrf + rank_seq + 1.0)
            
            combined_indices_cpu = combined_indices.cpu().numpy()
            
            # íƒ€ê²Ÿ ì¤€ë¹„
            batch_targets = []
            for original_idx in valid_idx_list:
                u_id = batch_uids[original_idx]
                actual_indices = set(processor.item2id[tid] - 1 for tid in target_dict[u_id] if tid in processor.item2id)
                batch_targets.append(actual_indices)

            for alpha in alphas:
                # Weighted RRF
                final_rrf_scores = (alpha * rrf_score_gnn) + ((1.0 - alpha) * rrf_score_seq)
                
                # Top-K Selection
                _, local_topk_indices = torch.topk(final_rrf_scores, k=max_k + 20, dim=1)
                local_topk_indices = local_topk_indices.cpu().numpy()
                
                for i, actual_indices in enumerate(batch_targets):
                    if not actual_indices: continue
                    
                    # Local Index -> Global Item ID
                    pred_global_ids = combined_indices_cpu[i][local_topk_indices[i]]
                    
                    # ì¤‘ë³µ ì œê±° (Unique)
                    _, unique_idx = np.unique(pred_global_ids, return_index=True)
                    pred_unique = pred_global_ids[np.sort(unique_idx)]
                    
                    for k in k_list:
                        if not actual_indices.isdisjoint(pred_unique[:k]):
                            results[alpha][k] += 1
                            
            total_users += len(valid_idx_list)

    # ---------------------------------------------------------
    # 4. Report
    # ---------------------------------------------------------
    print(f"\n{'='*80}")
    print(f"ğŸ“Š Weighted RRF Ensemble Report (k_rrf: {k_rrf})")
    print(f"{'-'*80}")
    
    header = f"{'Alpha(GNN)':<12} | {'GNN:Seq Ratio':<15}"
    for k in k_list:
        header += f" | {f'Recall@{k}':<12}"
    print(header)
    print(f"{'-'*80}")
    
    best_alpha = -1
    best_score = -1
    
    for alpha in sorted(results.keys(), reverse=True):
        scores = {}
        for k in k_list:
            scores[k] = results[alpha].get(k, 0) / total_users if total_users > 0 else 0
            
        row_str = f"{alpha:<12.1f} | {f'{int(alpha*10)} : {int((1-alpha)*10)}':<15}"
        for k in k_list:
            row_str += f" | {scores[k]:<12.4f}"
        print(row_str)
        
        if scores[k_list[0]] > best_score:
            best_score = scores[k_list[0]]
            best_alpha = alpha
            
    print(f"{'='*80}")
    print(f"ğŸ† Best RRF Alpha: {best_alpha}")
    
    return best_alpha

import torch
import torch.nn.functional as F
import pandas as pd
import numpy as np
from tqdm import tqdm
from torch.utils.data import DataLoader

def evaluate_gnn_standalone(
    model, processor, target_df_path, device, 
    k_list=[20, 100, 500], batch_size=4096
):
    """
    Pure GNN Retrieval Evaluation
    
    Logic:
      1. ëª¨ë¸ ë‚´ ì£¼ì…ëœ GNN User Embeddingê³¼ GNN Item Embeddingì„ ì¶”ì¶œí•©ë‹ˆë‹¤.
      2. User Vectorì™€ ì „ì²´ Item Vector ê°„ì˜ Cosine Similarityë¥¼ ê³„ì‚°í•©ë‹ˆë‹¤.
      3. Top-Kë¥¼ ì¶”ì¶œí•˜ì—¬ ì •ë‹µ(Target)ê³¼ ë¹„êµí•©ë‹ˆë‹¤.
      (Sequence Modelì˜ Logitì´ë‚˜ ScoreëŠ” ì „í˜€ ì‚¬ìš©í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.)
    """
    max_k = max(k_list)
    print(f"\nğŸš€ Starting Standalone GNN Evaluation (Max K: {max_k})...")
    
    model.eval()
    
    # ---------------------------------------------------------
    # 1. Target Data Load
    # ---------------------------------------------------------
    target_df = pd.read_parquet(target_df_path)
    # customer_id -> [target_item_id1, target_item_id2, ...]
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    # ---------------------------------------------------------
    # 2. Valid Loader Setup
    # ---------------------------------------------------------
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, shuffle=False, collate_fn=user_tower_collate_fn
    )
    
    # ---------------------------------------------------------
    # 3. Pre-computation (GNN Item Matrix)
    # ---------------------------------------------------------
    print("âš¡ Extracting & Normalizing GNN Item Vectors...")
    with torch.no_grad():
        # ëª¨ë¸ì— ì €ì¥ëœ GNN ì•„ì´í…œ ì„ë² ë”© ì „ì²´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        # Index 0ì€ Paddingì´ë¯€ë¡œ ì œì™¸í•˜ê±°ë‚˜ í¬í•¨í•´ë„ 0ë²¡í„°ë¼ ì˜í–¥ ì—†ìŒ (ì—¬ê¸°ì„  1ë¶€í„° ì‚¬ìš©)
        # í•˜ì§€ë§Œ Indexing í¸ì˜ë¥¼ ìœ„í•´ ì „ì²´ë¥¼ ê°€ì ¸ì˜¤ê³  0ë²ˆì€ ë¬´ì‹œí•˜ëŠ” ì „ëµ ì‚¬ìš©
        all_gnn_items = model.gnn_item_emb.weight.data.clone().detach().to(device)
        
        # Cosine Similarityë¥¼ ìœ„í•œ L2 Normalization
        # (Batch Matmul ì‹œ Dot Productë§Œ í•˜ë©´ ë¨)
        all_gnn_items_norm = F.normalize(all_gnn_items, p=2, dim=1)

    # ---------------------------------------------------------
    # 4. Evaluation Loop
    # ---------------------------------------------------------
    results = {k: 0 for k in k_list}
    total_users = 0
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="   -> GNN Retrieval"):
            u_idx, _, _, _, _, _, _, _ = [x.to(device) for x in batch]
            
            # ìœ íš¨ ìœ ì € í•„í„°ë§ (Targetì´ ìˆëŠ” ìœ ì €ë§Œ)
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            
            if not valid_idx_list: continue
            
            v_idx = torch.tensor(valid_idx_list).to(device)
            valid_u_idx = u_idx[v_idx]
            current_batch_size = len(v_idx)
            
            # =========================================================
            # [Step A] User Vector Extraction
            # =========================================================
            # ëª¨ë¸ì˜ GNN User Embeddingì—ì„œ ì¡°íšŒ
            batch_gnn_user = model.gnn_user_emb(valid_u_idx)
            batch_gnn_user_norm = F.normalize(batch_gnn_user, p=2, dim=1)
            
            # =========================================================
            # [Step B] Retrieval (Dot Product)
            # =========================================================
            # (Batch, Dim) @ (Num_Items, Dim).T -> (Batch, Num_Items)
            # all_gnn_items_normì€ (N+1, Dim) í˜•íƒœ (0ë²ˆì€ íŒ¨ë”©)
            scores = torch.matmul(batch_gnn_user_norm, all_gnn_items_norm.T)
            
            # 0ë²ˆ ì¸ë±ìŠ¤(Padding)ê°€ ê²€ìƒ‰ë˜ì§€ ì•Šë„ë¡ ë§ˆìŠ¤í‚¹ (ì„ íƒì‚¬í•­, ì•ˆì „ì¥ì¹˜)
            scores[:, 0] = -float('inf')
            
            # Top-K ì¶”ì¶œ
            _, topk_indices = torch.topk(scores, k=max_k, dim=1)
            topk_indices = topk_indices.cpu().numpy()
            
            # =========================================================
            # [Step C] Metric Calculation
            # =========================================================
            for i, original_idx in enumerate(valid_idx_list):
                u_id = batch_uids[original_idx]
                
                # ì •ë‹µ ID -> Index ë³€í™˜
                # processor.item2idëŠ” String ID -> 1-based Index ë§¤í•‘
                actual_indices = set(
                    processor.item2id[tid] 
                    for tid in target_dict[u_id] 
                    if tid in processor.item2id
                )
                
                if not actual_indices: continue
                
                # Recall Check
                pred_items = topk_indices[i] # ì´ë¯¸ 1-based index (Embedding Indexì™€ ë™ì¼)
                
                for k in k_list:
                    # ìƒìœ„ kê°œ ì¤‘ì— ì •ë‹µì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ê°€?
                    if not actual_indices.isdisjoint(pred_items[:k]):
                        results[k] += 1
            
            total_users += len(valid_idx_list)

    # ---------------------------------------------------------
    # 5. Report
    # ---------------------------------------------------------
    print(f"\n{'='*60}")
    print(f"ğŸ“Š GNN Standalone Performance Report")
    print(f"   (Total Users: {total_users})")
    print(f"{'-'*60}")
    
    header = f"{'Metric':<15} | {'Value':<10}"
    print(header)
    print(f"{'-'*60}")
    
    for k in sorted(k_list):
        recall = results[k] / total_users if total_users > 0 else 0
        print(f"{f'Recall@{k}':<15} | {recall:.4f}")
            
    print(f"{'='*60}\n")

# ì‚¬ìš© ì˜ˆì‹œ
# evaluate_gnn_standalone(model, valid_proc, TARGET_VAL_PATH, DEVICE)
def main():
    # 1. ì´ˆê¸°í™”: Feature Processor ë¡œë“œ
    # (Train Processorë¥¼ ë¡œë“œí•˜ì—¬ ID ë§¤í•‘ ê¸°ì¤€ì„ ì¡ìŒ)
    print("1ï¸âƒ£ Initializing Processors...")
    train_proc = FeatureProcessor(USER_FEAT_PATH_PQ, ITEM_FEAT_PATH_PQ, SEQ_DATA_PATH_PQ)
    valid_proc = FeatureProcessor(
        USER_VAL_FEAT_PATH,  # ê²€ì¦ ìœ ì € í”¼ì²˜
        ITEM_FEAT_PATH_PQ,   # ì•„ì´í…œ í”¼ì²˜ (ê³µìœ )
        SEQ_VAL_DATA_PATH,   # â­ í•µì‹¬: ê²€ì¦ìš© ì‹œí€€ìŠ¤ (Target ì œì™¸)
        scaler=train_proc.user_scaler # Scaler ê³µìœ 
    )
    
    # [ì¤‘ìš”] ID ë§¤í•‘ì„ Trainê³¼ ë™ì¼í•˜ê²Œ ê°•ì œ ì¼ì¹˜
    # (ìƒˆë¡œìš´ ì•„ì´í…œ/ìœ ì €ê°€ ìˆìœ¼ë©´ ë¬´ì‹œí•˜ê±°ë‚˜ ì²˜ë¦¬í•˜ê¸° ìœ„í•´)
    valid_proc.user2id = train_proc.user2id
    valid_proc.item2id = train_proc.item2id
    valid_proc.user_ids = train_proc.user_ids 
    valid_proc.item_ids = train_proc.item_ids
    num_users = len(train_proc.user_ids) + 1
    num_items = len(train_proc.item_ids) + 1
    
    # 2. ëª¨ë¸ ì´ˆê¸°í™” (Dummy Init)
    print("2ï¸âƒ£ Initializing Model...")
    # ì‹¤ì œë¡œëŠ” Pretrained Tensorë¥¼ ë¡œë“œí•´ì„œ ë„£ì–´ì•¼ í•¨
    dummy_gnn_u = torch.randn(num_users, 64)
    dummy_gnn_i = torch.randn(num_items, 64)
    dummy_content = torch.randn(num_items, 128)
    
    model = HybridUserTower(
        num_users=num_users,
        num_items=num_items,
        gnn_user_init=dummy_gnn_u,
        gnn_item_init=dummy_gnn_i,
        item_content_init=dummy_content
    ).to(DEVICE)
    
    # 3. ì„ë² ë”© ì •ë ¬ & ë¡œë“œ
    model = load_and_align_embeddings(model, train_proc, MODEL_DIR, DEVICE)

    model = load_and_align_gnn_items(model, train_proc, BASE_DIR, DEVICE)
    # 4. í•™ìŠµëœ ê°€ì¤‘ì¹˜ ë¡œë“œ
    if os.path.exists(SAVE_PATH_BEST):
        print(f"3ï¸âƒ£ Loading Trained Weights form {SAVE_PATH_BEST}...")
        # strict=False: ì„ë² ë”© ì‚¬ì´ì¦ˆ ë“±ì´ ë¯¸ì„¸í•˜ê²Œ ë‹¤ë¥¼ ê²½ìš° ìœ ì—°í•˜ê²Œ ë¡œë“œ
        model.load_state_dict(torch.load(SAVE_PATH_BEST), strict=False)
        model = load_and_align_gnn_items(model, train_proc, BASE_DIR, DEVICE)
        gnn_item_matrix = model.gnn_item_emb.weight.data.clone().detach()
    else:
        print("âš ï¸ Trained weights not found. Using random init.")
    
    model = load_and_align_gnn_user_embeddings(model, train_proc, BASE_DIR, DEVICE)
    # 5. GNN ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ (ì•™ìƒë¸”ìš©)
    # ëª¨ë¸ ë‚´ë¶€ì— ì •ë ¬ë˜ì–´ ì €ì¥ëœ GNN ì„ë² ë”©ì„ êº¼ë‚´ì„œ ì‚¬ìš©
    print("4ï¸âƒ£ Extracting GNN Matrices...")
    gnn_user_matrix = model.gnn_user_emb.weight.data.clone().detach()


    # 6. ì•™ìƒë¸” í‰ê°€ ìˆ˜í–‰
    # valid_proc ëŒ€ì‹  train_procì„ ì‚¬ìš© (ë°ì´í„° ê²½ë¡œë§Œ Validationìš©ìœ¼ë¡œ ì§€ì •í•˜ë©´ ë¨)
    # ì‹¤ì œë¡œëŠ” Valid Setì— ëŒ€í•œ Processorë¥¼ ë”°ë¡œ ë§Œë“œëŠ” ê²ƒì´ ì •ì„ì´ì§€ë§Œ, 
    # ì—¬ê¸°ì„œëŠ” í¸ì˜ìƒ ID ë§¤í•‘ì´ ë™ì¼í•œ train_proc ì‚¬ìš© + Valid Target Path ì£¼ì…
    '''
    evaluate_ensemble_sweep(
        seq_model=model,
        processor=valid_proc, 
        target_df_path=TARGET_VAL_PATH, 
        gnn_user_matrix=gnn_user_matrix, 
        gnn_item_matrix=gnn_item_matrix,
        device=DEVICE
    )
    
    evaluate_rrf_ensemble_sweep(        seq_model=model,
        processor=valid_proc, 
        target_df_path=TARGET_VAL_PATH, 
        gnn_user_matrix=gnn_user_matrix, 
        gnn_item_matrix=gnn_item_matrix,
        device=DEVICE)
        '''
    evaluate_weighted_score_ensemble(
        seq_model=model,
        processor=valid_proc, 
        target_df_path=TARGET_VAL_PATH, 
        gnn_user_matrix=gnn_user_matrix, 
        gnn_item_matrix=gnn_item_matrix,
        device=DEVICE,
        k_list=[20, 100, 500], # í‰ê°€í•  K ì‚¬ì´ì¦ˆ
        alpha_step=0.2         # ë¹„ìœ¨ ë³€ê²½ ë‹¨ìœ„
    )


    
if __name__ == "__main__":
    main()





