import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from torch.nn.utils.rnn import pad_sequence
from transformers import get_cosine_schedule_with_warmup
import pandas as pd
import numpy as np
import os
import random
import math
from tqdm import tqdm
from sklearn.preprocessing import StandardScaler
from tqdm import tqdm
import gc
import warnings
import logging

warnings.filterwarnings("ignore", message="Support for mismatched src_key_padding_mask and mask is deprecated")

# ==========================================
# âš™ï¸ ì„¤ì • & ê²½ë¡œ
# ==========================================
#TEMPERATURE = 0.2
LAMBDA_LOGQ = 0.1
BATCH_SIZE = 896
EMBED_DIM = 128
MAX_SEQ_LEN = 50
DROPOUT = 0.3
EPOCHS = 10
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"

BASE_DIR = r"D:\trainDataset\localprops"
MODEL_DIR = r"C:\Users\candyform\Desktop\inferenceCode\models"
CACHE_DIR = os.path.join(BASE_DIR, "cache")

ITEM_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_item.parquet")
USER_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_user.parquet")
SEQ_DATA_PATH_PQ = os.path.join(BASE_DIR, "features_sequence_cleaned.parquet")
TARGET_VAL_PATH = os.path.join(BASE_DIR, "features_target_val.parquet")
USER_VAL_FEAT_PATH = os.path.join(BASE_DIR, "features_user_val.parquet")
SEQ_VAL_DATA_PATH = os.path.join(BASE_DIR, "features_sequence_val.parquet")

SAVE_PATH_BEST = os.path.join(MODEL_DIR, "user_tower_phase3_best_ft_0.19x.pth")

class SmartLogger:
    def __init__(self, verbosity=1): self.verbosity = verbosity
    def log(self, level, msg):
        if self.verbosity >= level: print(f"[{'â„¹ï¸' if level==1 else 'ğŸ“Š'}] {msg}")

logger = SmartLogger(verbosity=1)

# ==========================================
# 1. Feature Processor & Dataset
# ==========================================
class FeatureProcessor:
    def __init__(self, user_path, item_path, seq_path, scaler=None):
        self.users = pd.read_parquet(user_path)
        # ì¤‘ë³µ ì œê±° ë° ì¸ë±ìŠ¤ ì„¤ì •
        self.users = self.users.drop_duplicates(subset=['customer_id']).set_index('customer_id')
        self.items = pd.read_parquet(item_path).set_index('article_id')
        self.seqs = pd.read_parquet(seq_path).set_index('customer_id')
        
        # ì¸ë±ìŠ¤ íƒ€ì… ê°•ì œ (String)
        self.users.index = self.users.index.astype(str)
        self.items.index = self.items.index.astype(str)
        self.seqs.index = self.seqs.index.astype(str)

        self.user_ids = self.users.index.tolist()
        self.user2id = {uid: i + 1 for i, uid in enumerate(self.user_ids)}
        self.item_ids = self.items.index.tolist()
        self.item2id = {iid: i + 1 for i, iid in enumerate(self.item_ids)}
        
        self.u_dense_cols = ['user_avg_price_log', 'total_cnt_log', 'recency_log']
        self.users_scaled = self.users.copy()
        self.user_scaler = StandardScaler()
        
        

        if scaler is None: 
            scaled_data = self.user_scaler.fit_transform(self.users[self.u_dense_cols])
        else: 
            self.user_scaler = scaler
            scaled_data = self.user_scaler.transform(self.users[self.u_dense_cols])
        
        # NaN ë°©ì–´
        self.users_scaled[self.u_dense_cols] = np.nan_to_num(scaled_data, nan=0.0)

    def get_user_tensor(self, user_id):
        dense = torch.tensor(self.users_scaled.loc[user_id, self.u_dense_cols].values, dtype=torch.float32)
        cat = torch.tensor(int(self.users_scaled.loc[user_id, 'preferred_channel']) - 1, dtype=torch.long)
        return dense, cat
    def get_logq_probs(self, device):
        """
        ëª¨ë¸ì˜ Embedding(N+1, D) êµ¬ì¡°ì™€ ì¼ì¹˜í•˜ë„ë¡ ì¸ë±ìŠ¤ ë³´ì •ëœ log_q ìƒì„±
        """
        # 1. raw_probability ì¶”ì¶œ (0-based)
        raw_probs = self.items['raw_probability'].reindex(self.item_ids).values
        
        # 2. Smoothing ë° ì²˜ë¦¬
        eps = 1e-6
        sorted_probs = np.nan_to_num(raw_probs, nan=0.0) + eps
        sorted_probs /= sorted_probs.sum()
        
        # 3. ë¡œê·¸ ê³„ì‚°
        log_q_values = np.log(sorted_probs).astype(np.float32)
        
        # 4. [ì¤‘ìš”] 1-based ì¸ë±ì‹± ëŒ€ì‘ì„ ìœ„í•œ Padding ì¶”ê°€
        # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” ì‚¬ìš©í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ì•„ì£¼ ì‘ì€ í™•ë¥ (ë˜ëŠ” 0)ì˜ ë¡œê·¸ê°’ìœ¼ë¡œ ì±„ì›€
        full_log_q = np.zeros(len(self.item_ids) + 1, dtype=np.float32)
        full_log_q[1:] = log_q_values  # 1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹¤ì œ ê°’ ì±„ìš°ê¸°
        full_log_q[0] = -20.0          # 0ë²ˆ ì¸ë±ìŠ¤(Padding)ëŠ” ë‚®ì€ ê°’ìœ¼ë¡œ ì„¤ì •
    
        return torch.tensor(full_log_q, dtype=torch.float32).to(device)
class UserTowerDataset(Dataset):
    def __init__(self, processor, max_seq_len=50, is_training=True):
        self.processor = processor
        self.user_ids = processor.user_ids 
        self.max_len = max_seq_len
        self.is_training = is_training
        self.min_cut_len = 3      

    def __len__(self):
        return len(self.user_ids)

    def __getitem__(self, idx):
        u_id_str = self.user_ids[idx]
        u_dense, u_cat = self.processor.get_user_tensor(u_id_str)
        
        processed_tokens = []
        processed_deltas = []
        
        if u_id_str in self.processor.seqs.index:
            seq_row = self.processor.seqs.loc[u_id_str]
            # Seriesì¼ ê²½ìš° ì²˜ë¦¬
            if isinstance(seq_row, pd.DataFrame): seq_row = seq_row.iloc[0]
                
            for i, d in zip(seq_row['sequence_ids'], seq_row['sequence_deltas']):
                 token = self.processor.item2id.get(str(i), 0) # str ë³€í™˜ ì•ˆì „ì¥ì¹˜
                 if token == 0: continue
                 processed_tokens.append(token)
                 processed_deltas.append(d)

        seq_len = len(processed_tokens)
        input_seq = []
        target_seq = [] 

        if seq_len > 0:
            if self.is_training:
                can_sample = seq_len > self.min_cut_len
                if not can_sample or random.random() < 0.8:
                    input_seq = processed_tokens[:-1]
                    target_seq = processed_tokens[1:]
                else:
                    max_cut = seq_len - 1
                    cut_idx = seq_len if max_cut < self.min_cut_len else random.randint(self.min_cut_len, max_cut)
                    full_slice = processed_tokens[:cut_idx+1]
                    input_seq = full_slice[:-1]
                    target_seq = full_slice[1:]
            else:
                input_seq = processed_tokens[:]
                target_seq = [0] * len(input_seq)

        input_ids = input_seq[-self.max_len:]
        target_ids = target_seq[-self.max_len:]
        input_deltas = processed_deltas[:len(input_seq)][-self.max_len:]

        return {
            'user_idx': torch.tensor(idx + 1, dtype=torch.long),
            'user_dense': u_dense, 'user_cat': u_cat,
            'seq_ids': torch.tensor(input_ids, dtype=torch.long),
            'seq_deltas': torch.tensor(input_deltas, dtype=torch.long),
            'target_ids': torch.tensor(target_ids, dtype=torch.long)
        }

def user_tower_collate_fn(batch):
    u_idx = torch.stack([b['user_idx'] for b in batch])
    u_dense = torch.stack([b['user_dense'] for b in batch])
    u_cat = torch.stack([b['user_cat'] for b in batch])
    seq_ids = pad_sequence([b['seq_ids'] for b in batch], batch_first=True, padding_value=0)
    seq_deltas = pad_sequence([b['seq_deltas'] for b in batch], batch_first=True, padding_value=0)
    target_ids = pad_sequence([b['target_ids'] for b in batch], batch_first=True, padding_value=0)
    seq_mask = (seq_ids != 0).long()
    last_target = torch.tensor([b['target_ids'][-1] if len(b['target_ids']) > 0 else 0 for b in batch], dtype=torch.long)
    return u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, last_target

# ==========================================
# 2. Alignment Functions (Alignment)
# ==========================================
def load_and_align_embeddings(model, processor, model_dir, device):
    """ Content Item Embedding Alignment (Pretrained -> model.item_content_emb) """
    print(f"\nğŸ”„ [Content Alignment] Starting Item Embedding Alignment...")
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")

    try:
        pretrained_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(pretrained_emb, dict):
            pretrained_emb = pretrained_emb.get('weight', pretrained_emb.get('item_content_emb.weight'))
        pretrained_ids = torch.load(ids_path, map_location='cpu')
    except Exception as e:
        print(f"âŒ [Error] Failed to load Content files: {e}")
        return model

    pretrained_map = {str(item_id.item()) if isinstance(item_id, torch.Tensor) else str(item_id): pretrained_emb[idx] for idx, item_id in enumerate(pretrained_ids)}
    
    num_embeddings = len(processor.item_ids) + 1 
    new_weight = torch.randn(num_embeddings, pretrained_emb.shape[1]) * 0.01 
    new_weight[0] = 0.0 
    
    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        if current_id_str in pretrained_map:
            new_weight[i + 1] = pretrained_map[current_id_str]
            matched += 1
            
    with torch.no_grad():
        model.item_content_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        
    print(f"âœ… [Content Alignment] Matched: {matched}/{len(processor.item_ids)}")
    return model

def load_and_align_gnn_items(model, processor, base_dir, device):
    """ GNN Item Embedding Alignment (GNN -> model.gnn_item_emb) """
    print(f"\nğŸ”„ [GNN Item Alignment] Starting...")
    cache_dir = os.path.join(base_dir, "cache")
    model_path = os.path.join(MODEL_DIR , "simgcl_trained.pth")
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    try:
        maps = torch.load(maps_path, map_location='cpu')
        gnn_item2id = maps['item2id']
        gnn_state_dict = torch.load(model_path, map_location='cpu')
        gnn_emb_weight = gnn_state_dict['embedding_item.weight']
    except Exception as e:
        print(f"âŒ [Error] Failed to load GNN Item files: {e}")
        return model

    num_embeddings = len(processor.item_ids) + 1 
    new_weight = torch.randn(num_embeddings, gnn_emb_weight.shape[1]) * 0.01
    new_weight[0] = 0.0

    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        if current_id_str in gnn_item2id:
            new_weight[i + 1] = gnn_emb_weight[gnn_item2id[current_id_str]]
            matched += 1
            
    with torch.no_grad():
        # [ì¤‘ìš”] ë°˜ë“œì‹œ gnn_item_emb ì— ë„£ì–´ì•¼ í•¨!
        model.gnn_item_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        print(f"âœ… Injected into 'model.gnn_item_emb'")

    print(f"âœ… [GNN Item Alignment] Matched: {matched}/{len(processor.item_ids)}")
    return model

def load_and_align_gnn_user_embeddings(model, processor, base_dir, device):
    """ GNN User Embedding Alignment (GNN -> model.gnn_user_emb) """
    print(f"\nğŸ”„ [GNN User Alignment] Starting...")
    cache_dir = os.path.join(base_dir, "cache")
    model_path = os.path.join(MODEL_DIR , "simgcl_trained.pth")
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    try:
        maps = torch.load(maps_path, map_location='cpu')
        gnn_user2id = maps['user2id']
        gnn_state_dict = torch.load(model_path, map_location='cpu')
        
        # ìœ ì € ê°€ì¤‘ì¹˜ ì°¾ê¸°
        gnn_user_weight = None
        for key, tensor in gnn_state_dict.items():
            if 'embedding_user' in key:
                gnn_user_weight = tensor
                break
        if gnn_user_weight is None: raise Exception("User embedding not found in state dict")

    except Exception as e:
        print(f"âŒ [Error] Failed to load GNN User files: {e}")
        return model

    num_users = len(processor.user_ids) + 1
    new_weight = torch.randn(num_users, gnn_user_weight.shape[1]) * 0.01
    new_weight[0] = 0.0
    
    matched = 0
    for i, current_id_str in enumerate(processor.user_ids):
        if current_id_str in gnn_user2id:
            new_weight[i + 1] = gnn_user_weight[gnn_user2id[current_id_str]]
            matched += 1
            
    with torch.no_grad():
        # [ì¤‘ìš”] ë°˜ë“œì‹œ gnn_user_emb ì— ë„£ì–´ì•¼ í•¨! (í¬ê¸° 96ë§Œ)
        model.gnn_user_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        print(f"âœ… Injected into 'model.gnn_user_emb'")

    print(f"âœ… [GNN User Alignment] Matched: {matched}/{len(processor.user_ids)}")
    return model

def verify_embedding_alignment(model, processor, model_dir):
    # (ìƒëµ: ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼, í•„ìš”ì‹œ ì¶”ê°€)
    pass

# ==========================================
# 3. Model Definition (Fixed)
# ==========================================
import torch
import torch.nn as nn
import torch.nn.functional as F
import math

import torch
import torch.nn as nn
import torch.nn.functional as F

class SequenceCentricFusion(nn.Module):
    """
    [ì„¤ê³„ ì² í•™]
    1. ê²½ìŸ(Softmax)ì„ ì œê±°í•©ë‹ˆë‹¤. SequenceëŠ” ë¬´ì¡°ê±´ 1.0ì˜ ë¹„ì¤‘ì„ ê°€ì§‘ë‹ˆë‹¤.
    2. GNNê³¼ MetaëŠ” Sequence ë²¡í„°ë¥¼ Queryë¡œ ì‚¬ìš©í•˜ì—¬, 
       Sequenceê°€ 'í•„ìš”í•˜ë‹¤ê³  íŒë‹¨í•  ë•Œë§Œ' ì •ë³´ê°€ ë”í•´(Add)ì§‘ë‹ˆë‹¤.
    3. ì´ˆê¸°ì—ëŠ” GNN/Meta ë°˜ì˜ë¥ ì„ 0ì— ìˆ˜ë ´í•˜ê²Œ í•˜ì—¬ Sequence í•™ìŠµì„ ê°•ì œí•©ë‹ˆë‹¤.
    """
    def __init__(self, dim=128):
        super().__init__()
        
        # Sequenceê°€ GNN/Metaë¥¼ ì–¼ë§ˆë‚˜ ê°€ì ¸ì˜¬ì§€ ê²°ì •í•˜ëŠ” Gate
        # ì…ë ¥: Sequence (Context)
        # ì¶œë ¥: 2 (GNN gate, Meta gate) -> Softmax ì•„ë‹˜! Sigmoid ì‚¬ìš©
        self.context_gate = nn.Sequential(
            nn.Linear(dim, 64),
            nn.GELU(),
            nn.Linear(64, 2), # [0]: GNN Gate, [1]: Meta Gate
            nn.Sigmoid()      # 0.0 ~ 1.0 ë…ë¦½ì ì¸ í™•ë¥ 
        )
        
        # ì°¨ì› íˆ¬ì˜ (Projector)
        self.gnn_proj = nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.Dropout(0.1)
        )
        
        self.meta_proj = nn.Sequential(
            nn.Linear(dim, dim),
            nn.LayerNorm(dim),
            nn.Dropout(0.1)
        )
        
        # ìµœì¢… ì •ë¦¬ëŠ” LayerNormë§Œ (MLP í†µê³¼ X -> ì •ë³´ í¬ì„ ë°©ì§€)
        self.final_ln = nn.LayerNorm(dim)

        # ğŸ”¥ [í•µì‹¬ ì´ˆê¸°í™”]
        # Gateì˜ ë§ˆì§€ë§‰ ë ˆì´ì–´ ë°”ì´ì–´ìŠ¤ë¥¼ ìŒìˆ˜ë¡œ ì„¤ì •í•˜ì—¬
        # ì´ˆê¸° Sigmoid ì¶œë ¥ì´ 0ì— ê°€ê¹ê²Œ ë§Œë“¦ (ì˜ˆ: -5 -> sigmoid(-5) â‰ˆ 0.006)
        # ì´ë ‡ê²Œ í•˜ë©´ ì²« Epochì—ëŠ” GNN/Metaê°€ ê±°ì˜ ë°˜ì˜ë˜ì§€ ì•Šê³  Sequenceë§Œ í•™ìŠµë¨.
        nn.init.zeros_(self.context_gate[-2].weight)
        nn.init.constant_(self.context_gate[-2].bias, -5.0) 

    def forward(self, v_gnn, v_seq, v_meta):
        # 1. Gate ê³„ì‚° (Sequenceê°€ ê²°ì •í•¨)
        # gates: (Batch, Seq_Len, 2)
        gates = self.context_gate(v_seq)
        
        g_gnn = gates[..., 0:1]
        g_meta = gates[..., 1:2]
        
        # 2. Residual Addition (ê²½ìŸí•˜ì§€ ì•Šê³  ë”í•˜ê¸°ë§Œ í•¨)
        # v_seq (Main) + (Gate * GNN) + (Gate * Meta)
        # SequenceëŠ” ê³„ìˆ˜ê°€ 1ë¡œ ê³ ì •ì´ë¯€ë¡œ ì ˆëŒ€ ë¬´ì‹œë˜ì§€ ì•ŠìŒ
        fused = v_seq + (g_gnn * self.gnn_proj(v_gnn)) + (g_meta * self.meta_proj(v_meta))
        
        # 3. Norm & Return
        # Gate ê°€ì¤‘ì¹˜ë„ ë¦¬í„´í•˜ì—¬ ë¡œê¹… (í‰ê· ê°’)
        gnn_ratio = g_gnn.mean().item()
        meta_ratio = g_meta.mean().item()
        gate_weights = [gnn_ratio, meta_ratio]

        return self.final_ln(fused), gate_weights

# ==========================================
# ğŸ§© 3. Parallel Adapter (ìœ ì§€)
# ==========================================
class ParallelAdapter(nn.Module):
    def __init__(self, content_dim=128, gnn_dim=64, out_dim=128, dropout=0.2):
        super().__init__()
        self.content_proj = nn.Sequential(
            nn.Linear(content_dim, out_dim),
            nn.LayerNorm(out_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )
        self.gnn_proj = nn.Sequential(
            nn.Linear(gnn_dim, out_dim),
            nn.LayerNorm(out_dim),
            nn.GELU(),
            nn.Dropout(dropout)
        )

    def forward(self, v_content, v_gnn):
        # [ìˆ˜ì •] Content Embeddingì— Residual Connection ì¶”ê°€ (+ v_content)
        # v_content(ì›ë³¸)ê°€ Adapterë¥¼ í†µê³¼í•œ ê²°ê³¼ì™€ ë”í•´ì§ -> ì›ë³¸ ì •ë³´ ë³´ì¡´
        merged = (self.content_proj(v_content) + v_content) + self.gnn_proj(v_gnn)
        return merged

# ==========================================
# ğŸ° Hybrid User Tower (ìˆ˜ì •ë¨)
# ==========================================
class HybridUserTower(nn.Module):
    def __init__(self, num_users, num_items, gnn_user_init, gnn_item_init, item_content_init):
        super().__init__()
        self.embed_dim = 128

        self.logit_scale = nn.Parameter(torch.ones([]) * np.log(1 / 0.07))
        # 1. Embeddings
        self.gnn_user_emb = nn.Embedding.from_pretrained(gnn_user_init, freeze=False)
        self.gnn_item_emb = nn.Embedding.from_pretrained(gnn_item_init, freeze=False)
        self.item_content_emb = nn.Embedding.from_pretrained(item_content_init, freeze=False)
        
        # 2. Adapters
        self.gnn_projector = nn.Sequential(
            nn.Linear(gnn_user_init.shape[1], 256),
            nn.LayerNorm(256), nn.GELU(), nn.Dropout(DROPOUT),
            nn.Linear(256, 128), nn.LayerNorm(128)
        )
        
        # [ìˆ˜ì •] ParallelAdapter ì‚¬ìš©
        self.seq_adapter = ParallelAdapter(
            content_dim=128, 
            gnn_dim=64, 
            out_dim=128, 
            dropout=DROPOUT
        )
        
        # 3. Sequence Modeling
        self.time_emb = nn.Embedding(1001, 128)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=128, nhead=2, dim_feedforward=512, 
            dropout=DROPOUT, batch_first=True, norm_first=True
        )
        self.seq_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)
        
        # 4. Meta & Fusion
        self.channel_emb = nn.Embedding(2, 32)
        self.meta_mlp = nn.Sequential(
            nn.Linear(35, 128), nn.GELU(),  # Target Layer Monitoring
            nn.Linear(128, 128), nn.LayerNorm(128)
        )
        self.fusion_layer = SequenceCentricFusion(dim=128)
        
        
        
        
    def get_current_temperature(self, clamp_min):
        # ì‚¬ìš©í•  ë•ŒëŠ” expë¥¼ ì·¨í•´ì„œ ì–‘ìˆ˜ë¡œ ë§Œë“¦
        # 1 / exp(scale) = temperature
        # í•˜ì§€ë§Œ ë³´í†µ ê³„ì‚° íš¨ìœ¨ì„ ìœ„í•´ (Cosine Sim * Scale) ë°©ì‹ìœ¼ë¡œ ê³±í•´ë²„ë¦¼
        # ì—¬ê¸°ì„œëŠ” ê¸°ì¡´ Loss í•¨ìˆ˜ì™€ì˜ í˜¸í™˜ì„±ì„ ìœ„í•´ Temperature ê°’ìœ¼ë¡œ ë³€í™˜í•´ì„œ ë¦¬í„´
        
        # logit_scaleì„ ìµœëŒ€ 100(exp(4.6))ê¹Œì§€ë§Œ ì»¤ì§€ê²Œ ì œí•œ (CLIP ë…¼ë¬¸ í…Œí¬ë‹‰ - ë°œì‚° ë°©ì§€)
        scale = self.logit_scale.exp().clamp(clamp_min, max=100.0)
        
        #clamp(min=14.3)
        # Scale = 1 / Temperature ì´ë¯€ë¡œ,
        # Temperature = 1 / Scale
        return 1.0 / scale
    
    def forward(self, u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat):
        B, L = seq_ids.shape
        
        # 1. GNN User
        v_gnn = self.gnn_projector(self.gnn_user_emb(u_idx))
        v_gnn_seq = F.normalize(v_gnn, p=2, dim=1).unsqueeze(1).expand(-1, L, -1)
        v_gnn_seq = torch.zeros_like(v_gnn_seq)
        if self.training:
            drop_prob = 0.4  # 40% í™•ë¥ ë¡œ GNNì„ ë²„ë¦¼
            keep_prob = 1 - drop_prob
            
            # ë°°ì¹˜ë³„ ë§ˆìŠ¤í¬ ìƒì„± (B, 1, 1)
            mask = torch.bernoulli(torch.full((B, 1, 1), keep_prob, device=v_gnn_seq.device))
            
            # Inverted Dropout: ì‚´ì•„ë‚¨ì€ ì‹ í˜¸ëŠ” keep_probë¡œ ë‚˜ëˆ ì„œ ìŠ¤ì¼€ì¼ ìœ ì§€
            v_gnn_seq = (v_gnn_seq * mask) / keep_prob
        
        # =========================================================
        # [ìˆ˜ì •ëœ ë¶€ë¶„] 2. Dual-View Sequence (Parallel Adapter)
        # =========================================================
        # (1) ì„ë² ë”© êº¼ë‚´ê¸°
        raw_content = self.item_content_emb(seq_ids) # (B, L, 128)
        raw_gnn = self.gnn_item_emb(seq_ids)         # (B, L, 64)
        
        # (2) Adapter í†µê³¼ (ì¸ì 2ê°œ ì „ë‹¬!)
        # ê¸°ì¡´ì—ëŠ” catìœ¼ë¡œ í•©ì³ì„œ ë„£ì—ˆì§€ë§Œ, ì´ì œëŠ” ë”°ë¡œ ë„£ì–´ì•¼ í•©ë‹ˆë‹¤.
        seq_input = self.seq_adapter(raw_content, raw_gnn) # <--- ì—¬ê¸°ê°€ ìˆ˜ì •ë¨!
        
        # (3) Time Embedding
        seq_input = seq_input  * math.sqrt(self.embed_dim) + self.time_emb(seq_deltas.clamp(max=1000))
        
        # =========================================================
        
        causal_mask = torch.triu(torch.ones(L, L, device=seq_ids.device) * float('-inf'), diagonal=1)
        key_padding_mask = (seq_mask == 0)
        
        seq_out = self.seq_encoder(seq_input, mask=causal_mask, src_key_padding_mask=key_padding_mask)
        v_seq = F.normalize(seq_out, p=2, dim=2)

        cat_vec = self.channel_emb(u_cat)
        v_meta = self.meta_mlp(torch.cat([u_dense, cat_vec], dim=1))
        v_meta_seq = F.normalize(v_meta, p=2, dim=1).unsqueeze(1).expand(-1, L, -1)
        
        output, gate_weights = self.fusion_layer(v_gnn_seq, v_seq, v_meta_seq)
        output = F.normalize(output, p=2, dim=2)
        return output, v_seq, gate_weights
    def get_meta_feature_importance(self):
        """
        Meta MLPì˜ ì²« ë²ˆì§¸ Linear Layer ê°€ì¤‘ì¹˜ë¥¼ ë¶„ì„í•˜ì—¬
        ì–´ë–¤ Featureê°€ ê°€ì¥ ì˜í–¥ë ¥ì´ í°ì§€ ê³„ì‚°í•©ë‹ˆë‹¤.
        """
        # ì²« ë²ˆì§¸ Linear Layerì˜ ê°€ì¤‘ì¹˜: (Out_Dim, In_Dim) -> (128, 35)
        weight_matrix = self.meta_mlp[0].weight.abs().detach().cpu()
        
        # Input Dimension Slicing
        # Price: 0~32, Cnt: 32~64, Recency: 64~96, Channel: 96~112
        imp_price = weight_matrix[:, 0:32].mean().item()
        imp_cnt = weight_matrix[:, 32:64].mean().item()
        imp_recency = weight_matrix[:, 64:96].mean().item()
        imp_channel = weight_matrix[:, 96:112].mean().item()
        
        # ì •ê·œí™” (ë¹„ìœ¨ë¡œ ë³´ê¸° ìœ„í•´)
        total = imp_price + imp_cnt + imp_recency + imp_channel + 1e-9
        return {
            "Price": imp_price / total,
            "Count": imp_cnt / total,
            "Recency": imp_recency / total,
            "Channel": imp_channel / total
        }
# ==========================================
# 4. Loss & Eval
# ==========================================
def logq_correction_loss(user_emb, item_emb, pos_item_ids, item_probs, temperature=0.07, lambda_logq=0.0):
    scores = torch.matmul(user_emb, item_emb.T)
    if lambda_logq > 0.0:
        
        log_q = torch.log(item_probs[pos_item_ids] + 1e-4).view(1, -1)
        scores = scores - (lambda_logq * log_q)
    logits = scores / temperature
    is_collision = (pos_item_ids.unsqueeze(1) == pos_item_ids.unsqueeze(0))
    mask = is_collision.fill_diagonal_(False)
    logits = logits.masked_fill(mask, -1e4)
    labels = torch.arange(logits.size(0), device=logits.device)
    return F.cross_entropy(logits, labels)

def efficient_corrected_logq_loss(
    user_emb, 
    item_emb, 
    pos_item_ids, 
    precomputed_log_q, 
    temperature=0.1, 
    lambda_logq=0.1
):
    # ì¸ë±ìŠ¤ ë²”ìœ„ ì²´í¬ (ë””ë²„ê¹…ìš©, ì‹¤ì œ í•™ìŠµì‹œ ì„±ëŠ¥ ì˜í–¥ ë¯¸ë¯¸)
    assert pos_item_ids.max() < precomputed_log_q.size(0), "pos_item_ids contains out-of-bounds index!"
    logits = torch.matmul(user_emb, item_emb.T)
    logits.div_(temperature) # logits /= temperature (In-place)
    
    if lambda_logq > 0.0:
        # 2. LogQ Correction (In-place)
        # precomputed_log_qì—ì„œ í˜„ì¬ ë°°ì¹˜ì˜ ê°’ë§Œ ìŠ¬ë¼ì´ì‹± (View ìƒì„±)
        batch_log_q = precomputed_log_q[pos_item_ids].view(1, -1)
        
        # In-place subtraction: ìƒˆë¡œìš´ í…ì„œ í• ë‹¹ ìµœì†Œí™”
        logits.sub_(batch_log_q * lambda_logq)
        
        # 3. Positive Recovery (RecSys 2025)
        # torch.sum ëŒ€ì‹  einsumì„ ì“°ë©´ ê°€ë” íŠ¹ì • CUDA ë²„ì „ì—ì„œ ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.
        pos_logits_raw = torch.einsum('bd,bd->b', user_emb, item_emb).div_(temperature)
        logits.diagonal().copy_(pos_logits_raw)

    # 4. Collision Masking (ë©”ëª¨ë¦¬ ì ˆì•½í˜•)
    with torch.no_grad():
        is_collision = (pos_item_ids.unsqueeze(1) == pos_item_ids.unsqueeze(0))
        mask = is_collision.fill_diagonal_(False)
    
    # FP16 AMP ì‚¬ìš© ì‹œ -3e4ê°€ ì•ˆì „ (Underflow ë°©ì§€)
    mask_value = -30000.0 if logits.dtype == torch.float16 else -1e9
    logits.masked_fill_(mask, mask_value)

    # 5. Labels ìƒì„± (ë§¤ë²ˆ ìƒì„±í•˜ì§€ ì•Šê³  ì¬ì‚¬ìš© ê°€ëŠ¥í•˜ì§€ë§Œ, ì´ ì •ë„ëŠ” ë¯¸ë¯¸í•¨)
    labels = torch.arange(logits.size(0), device=logits.device)
    
    return F.cross_entropy(logits, labels)



class EnsembleGate(nn.Module):
    def __init__(self, input_dim=4):
        super().__init__()
        # ì•„ì£¼ ê°€ë²¼ìš´ 2ì¸µ MLP
        self.mlp = nn.Sequential(
            nn.Linear(input_dim, 32),
            nn.BatchNorm1d(32),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(32, 16),
            nn.ReLU(),
            nn.Linear(16, 1),
            nn.Sigmoid() # ê²°ê³¼ëŠ” ë¬´ì¡°ê±´ 0~1 ì‚¬ì´ (Alpha)
        )
        
    def forward(self, seq_len, u_dense):
        # seq_len ì •ê·œí™” (ëŒ€ëµ 100ìœ¼ë¡œ ë‚˜ëˆ”)
        len_feat = seq_len.unsqueeze(1).float() / 100.0
        
        # ì…ë ¥ ë²¡í„° ê²°í•©: [ê¸¸ì´, ìœ ì €ì •ë³´1, ìœ ì €ì •ë³´2, ...]
        # u_denseëŠ” ì´ë¯¸ log/scale ë˜ì–´ ìˆë‹¤ê³  ê°€ì •
        features = torch.cat([len_feat, u_dense], dim=1) 
        
        # Alpha ì˜ˆì¸¡
        alpha = self.mlp(features)
        return alpha

def save_gate_model(gate_model, save_dir, filename="gate_model_best.pth"):
    if not os.path.exists(save_dir):
        os.makedirs(save_dir)
    save_path = os.path.join(save_dir, filename)
    torch.save(gate_model.state_dict(), save_path)
    print(f"ğŸ’¾ Gate Model Saved: {save_path}")

def load_gate_model(save_dir, device, filename="gate_model_best.pth"):
    save_path = os.path.join(save_dir, filename)
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    gate_model = EnsembleGate().to(device)
    
    if os.path.exists(save_path):
        gate_model.load_state_dict(torch.load(save_path, map_location=device))
        gate_model.eval() # í‰ê°€ëŠ” ë¬´ì¡°ê±´ eval ëª¨ë“œ
        print(f"ğŸ“‚ Gate Model Loaded from: {save_path}")
        return gate_model
    else:
        print(f"âš ï¸ Warning: No Gate model found at {save_path}. Initializing Randomly.")
        return gate_model





def train_gate_only(
    gate_model, 
    seq_model, 
    processor, 
    gnn_user_matrix, 
    gnn_item_matrix,
    train_loader, # í•™ìŠµ ë°ì´í„° ë¡œë”
    epochs=3
):
    print("\nğŸš€ Training Ensemble Gate (Freezing Base Models)...")
    
    # 1. ê¸°ì¡´ ëª¨ë¸ Freeze (ì ˆëŒ€ ê±´ë“œë¦¬ì§€ ì•ŠìŒ)
    seq_model.eval()
    for param in seq_model.parameters():
        param.requires_grad = False
        
    # 2. Gate ëª¨ë¸ë§Œ í•™ìŠµ
    gate_model.train()
    optimizer = torch.optim.Adam(gate_model.parameters(), lr=0.001)
    criterion = nn.CrossEntropyLoss() # í˜¹ì€ Contrastive Loss
    
    # GNN/Seq Item Vector ë¯¸ë¦¬ ê³„ì‚° (ê³ ì •ê°’)
    with torch.no_grad():
        all_item_ids = torch.arange(1, len(processor.item_ids)+1).to(DEVICE)
        
        # (Seq Item Vec)
        seq_item_vecs = []
        for i in range(0, len(all_item_ids), 4096):
            chunk = all_item_ids[i:i+4096]
            c_vec = seq_model.seq_adapter(
                seq_model.item_content_emb(chunk), 
                seq_model.gnn_item_emb(chunk)
            )
            seq_item_vecs.append(F.normalize(c_vec, p=2, dim=1))
        all_seq_vecs = torch.cat(seq_item_vecs, dim=0)
        
        # (GNN Item Vec)
        all_gnn_vecs = F.normalize(gnn_item_matrix[1:].to(DEVICE), p=2, dim=1)

    # 3. í•™ìŠµ ë£¨í”„
    for epoch in range(epochs):
        total_loss = 0
        pbar = tqdm(train_loader, desc=f"Gate Epoch {epoch+1}")
        
        for batch in pbar:
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, _ = [x.to(DEVICE) for x in batch]
            
            with torch.no_grad():
                # (A) Seq Score ê³„ì‚°
                # Seq Only ëª¨ë“œì´ë¯€ë¡œ outputë§Œ ë°›ìŒ
                output = seq_model(u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat)
                if isinstance(output, tuple): output = output[0]
                
                lengths = seq_mask.sum(dim=1)
                last_indices = (lengths - 1).clamp(min=0)
                seq_user = output[torch.arange(len(u_idx)), last_indices]
                
                # ì •ë‹µ ì•„ì´í…œ(Pos)ì— ëŒ€í•œ ì ìˆ˜ë§Œ ê³„ì‚° (íš¨ìœ¨ì„± ìœ„í•´)
                # ì‹¤ì œ í•™ìŠµ ë• Negative Sampling í•„ìš”í•˜ì§€ë§Œ ì—¬ê¸°ì„  ê°„ëµí™”
                # ì „ì²´ ì•„ì´í…œê³¼ì˜ ë‚´ì  (Batch, Num_Items)
                scores_seq = torch.matmul(seq_user, all_seq_vecs.T)
                
                # (B) GNN Score ê³„ì‚°
                gnn_user = F.normalize(gnn_user_matrix[u_idx], p=2, dim=1)
                scores_gnn = torch.matmul(gnn_user, all_gnn_vecs.T)
            
            # --- ì—¬ê¸°ë¶€í„° Gradient íë¦„ ---
            
            # (C) Gateê°€ Alpha ê²°ì •
            # u_dense: (Batch, 3) ê°€ì • -> input_dim = 1 + 3 = 4
            alpha = gate_model(lengths, u_dense) # (Batch, 1)
            
            # (D) ì ìˆ˜ í•©ì„±
            final_scores = alpha * scores_seq + (1 - alpha) * scores_gnn
            
            # (E) Loss ê³„ì‚° (Cross Entropy)
            # target_idsì˜ ë§ˆì§€ë§‰ ì•„ì´í…œ(Next Item)ì„ ë§ì¶”ë„ë¡ ìœ ë„
            # target_ids: (Batch, Seq_Len) -> last item extraction needed
            # í¸ì˜ìƒ loaderê°€ last_targetì„ ì¤€ë‹¤ê³  ê°€ì •
            last_target = target_ids[:, -1] - 1 # 0-base index
            
            loss = criterion(final_scores / 0.1, last_target) # Temp=0.1
            
            optimizer.zero_grad()
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            pbar.set_postfix({'loss': total_loss / (pbar.n + 1), 'avg_alpha': alpha.mean().item()})
            save_gate_model(gate_model, MODEL_DIR, "gate_model_best.pth")
    return gate_model







def main_evaluation_flow():
    # 1. ëª¨ë¸ ì´ˆê¸°í™” (Dummyë¡œ ì‹œì‘)
    train_proc = FeatureProcessor(USER_FEAT_PATH_PQ, ITEM_FEAT_PATH_PQ, SEQ_DATA_PATH_PQ, scaler=None)
    valid_proc = FeatureProcessor(USER_VAL_FEAT_PATH, ITEM_FEAT_PATH_PQ, SEQ_VAL_DATA_PATH, scaler=train_proc.user_scaler)
    valid_proc.item2id, valid_proc.item_ids = train_proc.item2id, train_proc.item_ids

    num_users = len(train_proc.user_ids) + 1
    num_items = len(train_proc.item_ids) + 1
    
    # Dummy Init

    model = HybridUserTower(
        num_users=len(train_proc.user_ids)+1,
        num_items=len(train_proc.item_ids)+1,
        gnn_user_init=torch.zeros((len(train_proc.user_ids)+1, 64)),
        gnn_item_init=torch.zeros((len(train_proc.item_ids)+1, 64)),
        item_content_init=torch.zeros((len(train_proc.item_ids)+1, 128))
    ).to(DEVICE)

    # 2. ì„ë² ë”© ë¡œë“œ ë° ì •ë ¬ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©) âœ…
    # ì´ ê³¼ì •ì—ì„œ Pretrained ID -> Current ID ë§¤í•‘ì´ ì™„ë£Œë¨
    model = load_and_align_embeddings(model, train_proc, MODEL_DIR, DEVICE)     # Content
    model = load_and_align_gnn_items(model, train_proc, BASE_DIR, DEVICE)       # GNN Item
    model = load_and_align_gnn_user_embeddings(model, train_proc, BASE_DIR, DEVICE) # GNN User

    # 3. ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (Sequence í•™ìŠµëœ ëª¨ë¸)
    # GNN/Content ì„ë² ë”©ì€ ìœ„ì—ì„œ ë¡œë“œí–ˆìœ¼ë¯€ë¡œ, í•™ìŠµëœ Tower Weightë§Œ ë®ì–´ì”Œì›€ (strict=False ê¶Œì¥)
    # ë§Œì•½ ì €ì¥ëœ pthì— ì„ë² ë”©ê¹Œì§€ ë‹¤ ë“¤ì–´ìˆë‹¤ë©´ load_state_dict í•œë°©ì´ë©´ ë¨
    if os.path.exists(SAVE_PATH_BEST):
        model.load_state_dict(torch.load(SAVE_PATH_BEST), strict=False)
        print("âœ… Trained Model Weights Loaded.")

    # 4. GNN ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ (ì•™ìƒë¸”ìš©) â­
    # ëª¨ë¸ ì•ˆì— Align ë˜ì–´ ë“¤ì–´ìˆëŠ” ê°€ì¤‘ì¹˜ë¥¼ ë³µì‚¬í•´ì„œ êº¼ëƒ„
    # .data.clone()ì„ í•´ì•¼ ì•ˆì „í•¨
    gnn_user_matrix = model.gnn_user_emb.weight.data.clone().detach()
    gnn_item_matrix = model.gnn_item_emb.weight.data.clone().detach()

    # 5. ì•™ìƒë¸” í‰ê°€ ì‹¤í–‰
    print("\nğŸ§ª Starting Hybrid Ensemble Evaluation...")
    
    # Alpha ê°’ì„ ì¡°ì •í•´ê°€ë©° ìµœì ì  ì°¾ê¸°
# ê¸°ì¡´ for loopê°€ ëë‚œ ë’¤ í˜¸ì¶œ

# ì‹¤í–‰
# main_evaluation_flow()




def evaluate_hybrid_with_trained_gate(
    seq_model,       # í•™ìŠµëœ Sequence Model
    gate_model,      # í•™ìŠµëœ Gate Model (Load ëœ ê²ƒ)
    processor, 
    target_df_path, 
    gnn_user_matrix, 
    gnn_item_matrix, 
    k_list=[20, 100, 500], 
    batch_size=256
):
    print("\nğŸ¤– Starting AI-Gated Ensemble Evaluation...")
    seq_model.eval()
    gate_model.eval() # Gate ëª¨ë¸ë„ í‰ê°€ ëª¨ë“œ í•„ìˆ˜!
    
    target_df = pd.read_parquet(target_df_path)
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, shuffle=False, collate_fn=user_tower_collate_fn
    )
    
    # [Pre-computation: Item Vectors] ------------------------------
    with torch.no_grad():
        all_item_ids = torch.arange(1, len(processor.item_ids)+1).to(DEVICE)
        
        # 1. Seq Item Vecs
        seq_item_vecs_list = []
        for i in range(0, len(all_item_ids), 4096):
            chunk = all_item_ids[i:i+4096]
            c_vec = seq_model.seq_adapter(
                seq_model.item_content_emb(chunk), seq_model.gnn_item_emb(chunk)
            )
            seq_item_vecs_list.append(F.normalize(c_vec, p=2, dim=1))
        all_seq_item_vecs = torch.cat(seq_item_vecs_list, dim=0)

        # 2. GNN Item Vecs
        all_gnn_item_vecs = F.normalize(gnn_item_matrix[1:].to(DEVICE), p=2, dim=1) 
    # --------------------------------------------------------------

    hit_counts = {k: 0 for k in k_list}
    total_users = 0
    total_alpha_sum = 0
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="ğŸ¤– AI Gating..."):
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, _, _ = [x.to(DEVICE) for x in batch]
            
            # ìœ íš¨ ìœ ì € í•„í„°ë§
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            if not valid_idx_list: continue
            v_idx = torch.tensor(valid_idx_list).to(DEVICE)

            # ------------------------------------------------------
            # [A] Calculate Scores
            # ------------------------------------------------------
            # 1. Seq Score
            output = seq_model(
                u_idx[v_idx], seq_ids[v_idx], seq_deltas[v_idx], seq_mask[v_idx], u_dense[v_idx], u_cat[v_idx]
            )
            if isinstance(output, tuple): output = output[0]
            
            lengths = seq_mask[v_idx].sum(dim=1)
            last_indices = (lengths - 1).clamp(min=0)
            user_seq_vecs = output[torch.arange(len(v_idx)), last_indices]
            scores_seq = torch.matmul(user_seq_vecs, all_seq_item_vecs.T)

            # 2. GNN Score
            user_gnn_vecs = F.normalize(gnn_user_matrix[u_idx[v_idx]].to(DEVICE), p=2, dim=1)
            scores_gnn = torch.matmul(user_gnn_vecs, all_gnn_item_vecs.T)

            # ------------------------------------------------------
            # [B] Apply Trained Gate Model â­
            # ------------------------------------------------------
            # ì…ë ¥: (ì‹œí€€ìŠ¤ ê¸¸ì´, ìœ ì € ë´ìŠ¤ í”¼ì²˜) -> ì¶œë ¥: Alpha (Batch, 1)
            # Gateê°€ "ì´ ìœ ì €ëŠ” 0.7ë§Œí¼ Seqë¥¼ ë¯¿ì–´ë¼"ë¼ê³  íŒë‹¨í•¨
            alpha_tensor = gate_model(lengths, u_dense[v_idx]) 
            
            total_alpha_sum += alpha_tensor.mean().item() * len(v_idx)

            # ------------------------------------------------------
            # [C] Weighted Fusion
            # ------------------------------------------------------
            # alpha_tensorëŠ” ì´ë¯¸ (Batch, 1) ëª¨ì–‘ì´ë¯€ë¡œ ë°”ë¡œ ë¸Œë¡œë“œìºìŠ¤íŒ… ê³±ì…ˆ ê°€ëŠ¥
            final_scores = (alpha_tensor * scores_seq) + ((1.0 - alpha_tensor) * scores_gnn)
            
            # Top-K Counting
            _, topk_indices = torch.topk(final_scores, k=max(k_list), dim=1)
            pred_ids = (topk_indices + 1).cpu().numpy()
            
            for i, original_idx in enumerate(valid_idx_list):
                u_id = batch_uids[original_idx]
                actual_indices = set(processor.item2id[tid] for tid in target_dict[u_id] if tid in processor.item2id)
                if not actual_indices: continue
                for k in k_list:
                    if not actual_indices.isdisjoint(pred_ids[i, :k]): hit_counts[k] += 1
                total_users += 1

    avg_alpha = total_alpha_sum / total_users if total_users > 0 else 0
    metrics = {f"R@{k}": (hit_counts[k] / total_users if total_users > 0 else 0.0) for k in k_list}
    
    print(f"\nğŸ“Š [AI-Gated Result]")
    print(f"   - Avg Alpha Predicted: {avg_alpha:.4f}")
    print(f"   - Metrics: {metrics}")
    return metrics



def main_with_trained_gate():
    # 1. ê¸°ë³¸ ëª¨ë¸ & ë°ì´í„° ë¡œë“œ (ê¸°ì¡´ê³¼ ë™ì¼)
    # ... (seq_model, gnn_matrix ë“± ë¡œë“œ ì™„ë£Œ ê°€ì •) ...
    
    # [ê°€ì •] ì´ë¯¸ gate_model í•™ìŠµì„ ì™„ë£Œí•˜ê³  ì €ì¥í–ˆë‹¤ê³  ê°€ì •
    # ì˜ˆ: train_gate_only(...) -> save_gate_model(...) ì‹¤í–‰ ì™„ë£Œ
    
    train_proc = FeatureProcessor(USER_FEAT_PATH_PQ, ITEM_FEAT_PATH_PQ, SEQ_DATA_PATH_PQ, scaler=None)
    valid_proc = FeatureProcessor(USER_VAL_FEAT_PATH, ITEM_FEAT_PATH_PQ, SEQ_VAL_DATA_PATH, scaler=train_proc.user_scaler)
    valid_proc.item2id, valid_proc.item_ids = train_proc.item2id, train_proc.item_ids

    num_users = len(train_proc.user_ids) + 1
    num_items = len(train_proc.item_ids) + 1
    
    # Dummy Init

    model = HybridUserTower(
        num_users=len(train_proc.user_ids)+1,
        num_items=len(train_proc.item_ids)+1,
        gnn_user_init=torch.zeros((len(train_proc.user_ids)+1, 64)),
        gnn_item_init=torch.zeros((len(train_proc.item_ids)+1, 64)),
        item_content_init=torch.zeros((len(train_proc.item_ids)+1, 128))
    ).to(DEVICE)

    # 2. ì„ë² ë”© ë¡œë“œ ë° ì •ë ¬ (ê¸°ì¡´ í•¨ìˆ˜ ì¬ì‚¬ìš©) âœ…
    # ì´ ê³¼ì •ì—ì„œ Pretrained ID -> Current ID ë§¤í•‘ì´ ì™„ë£Œë¨
    model = load_and_align_embeddings(model, train_proc, MODEL_DIR, DEVICE)     # Content
    model = load_and_align_gnn_items(model, train_proc, BASE_DIR, DEVICE)       # GNN Item
    model = load_and_align_gnn_user_embeddings(model, train_proc, BASE_DIR, DEVICE) # GNN User

    # 3. ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ (Sequence í•™ìŠµëœ ëª¨ë¸)
    # GNN/Content ì„ë² ë”©ì€ ìœ„ì—ì„œ ë¡œë“œí–ˆìœ¼ë¯€ë¡œ, í•™ìŠµëœ Tower Weightë§Œ ë®ì–´ì”Œì›€ (strict=False ê¶Œì¥)
    # ë§Œì•½ ì €ì¥ëœ pthì— ì„ë² ë”©ê¹Œì§€ ë‹¤ ë“¤ì–´ìˆë‹¤ë©´ load_state_dict í•œë°©ì´ë©´ ë¨
    if os.path.exists(SAVE_PATH_BEST):
        model.load_state_dict(torch.load(SAVE_PATH_BEST), strict=False)
        print("âœ… Trained Model Weights Loaded.")

    # 4. GNN ë§¤íŠ¸ë¦­ìŠ¤ ì¶”ì¶œ (ì•™ìƒë¸”ìš©) â­
    # ëª¨ë¸ ì•ˆì— Align ë˜ì–´ ë“¤ì–´ìˆëŠ” ê°€ì¤‘ì¹˜ë¥¼ ë³µì‚¬í•´ì„œ êº¼ëƒ„
    # .data.clone()ì„ í•´ì•¼ ì•ˆì „í•¨
    gnn_user_matrix = model.gnn_user_emb.weight.data.clone().detach()
    gnn_item_matrix = model.gnn_item_emb.weight.data.clone().detach()

    # 5. ì•™ìƒë¸” í‰ê°€ ì‹¤í–‰
    print("\nğŸ§ª Starting Hybrid Ensemble Evaluation...")
       
    
    
    
    
    
    
    # 2. Gate ëª¨ë¸ ë¶ˆëŸ¬ì˜¤ê¸° â­
    # ì €ì¥ëœ ê²½ë¡œì—ì„œ í•™ìŠµëœ ê°€ì¤‘ì¹˜ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.
    trained_gate = load_gate_model(
        save_dir=MODEL_DIR, 
        device=DEVICE, 
        filename="gate_model_best.pth"
    )
    
    # 3. í‰ê°€ ì‹¤í–‰
    evaluate_hybrid_with_trained_gate(
        seq_model=model,        # Freezeëœ Seq ëª¨ë¸
        gate_model=trained_gate,# Loadëœ Gate ëª¨ë¸
        processor=valid_proc,
        target_df_path=TARGET_VAL_PATH,
        gnn_user_matrix=gnn_user_matrix,
        gnn_item_matrix=gnn_item_matrix
    )





if __name__ == "__main__":
   main_with_trained_gate()