import os
import random
import math  # [í•„ìˆ˜] sqrt ì‚¬ìš©ì„ ìœ„í•´ ì¶”ê°€
import pandas as pd
import numpy as np
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader
from torch.nn.utils.rnn import pad_sequence
from sklearn.preprocessing import StandardScaler
from transformers import get_cosine_schedule_with_warmup
from tqdm import tqdm
import warnings
warnings.filterwarnings("ignore", message="Support for mismatched src_key_padding_mask and mask is deprecated")
# -------------------------------------------------------------------------
# 0. Global Configuration & Logger
# -------------------------------------------------------------------------
# [ìˆ˜ì •] Temperatureë¥¼ ë‚®ì¶°ì•¼ ì •ê·œí™”ëœ ë²¡í„°ë¼ë¦¬ êµ¬ë¶„ì´ ê°€ëŠ¥í•´ì§
TEMPERATURE = 0.15
# [ìˆ˜ì •] ì´ˆê¸° í•™ìŠµ ì•ˆì •ì„±ì„ ìœ„í•´ LogQ ê°€ì¤‘ì¹˜ë¥¼ ì•½ê°„ ë‚®ì¶¤ (ë‚˜ì¤‘ì— ì˜¬ë ¤ë„ ë¨)
LAMBDA_LOGQ = 0.0
BATCH_SIZE = 768
EMBED_DIM = 128
MAX_SEQ_LEN = 50
DROPOUT = 0.2
EPOCHS = 10
DEVICE = "cuda" if torch.cuda.is_available() else "cpu"


# ê²½ë¡œ ì„¤ì • (ì‚¬ìš©ì í™˜ê²½ì— ë§ê²Œ ìœ ì§€)
BASE_DIR = r"D:\trainDataset\localprops"
MODEL_DIR = r"C:\Users\candyform\Desktop\inferenceCode\models"
ITEM_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_item.parquet")
USER_FEAT_PATH_PQ = os.path.join(BASE_DIR, "features_user.parquet")
SEQ_DATA_PATH_PQ = os.path.join(BASE_DIR, "features_sequence_cleaned.parquet")
GNN_PATH = os.path.join(MODEL_DIR, "simgcl_trained.pth")
GNN_MAP_PATH = os.path.join(BASE_DIR, "cache", "id_maps_train.pt")
ITEM_MATRIX_PATH = os.path.join(MODEL_DIR, "pretrained_item_matrix.pt")
ITEM_ID_PATH = os.path.join(MODEL_DIR, "item_ids.pt")
TARGET_VAL_PATH = os.path.join(BASE_DIR, "features_target_val.parquet")
PHASE2_WEIGHTS = os.path.join(MODEL_DIR, "user_tower_phase2.pth")
SAVE_PATH_BEST_PREV = os.path.join(MODEL_DIR, "user_tower_phase2.5_best.pth")
USER_VAL_FEAT_PATH = os.path.join(BASE_DIR, "features_user_val.parquet")
SEQ_VAL_DATA_PATH = os.path.join(BASE_DIR, "features_sequence_val.parquet")
SAVE_PATH_BEST = os.path.join(MODEL_DIR, "user_tower_phase2.5_best_ft.pth")

class SmartLogger:
    def __init__(self, verbosity=1): self.verbosity = verbosity
    def log(self, level, msg):
        if self.verbosity >= level: print(f"[{'â„¹ï¸' if level==1 else 'ğŸ“Š'}] {msg}")

logger = SmartLogger(verbosity=1)
import torch
import torch.nn.functional as F
import pandas as pd

# ==========================================
# ğŸ› ï¸ ì„¤ì • (ê²½ë¡œ í™•ì¸ í•„ìˆ˜)
# ==========================================
ITEM_MATRIX_PATH = r"C:\Users\candyform\Desktop\inferenceCode\models\pretrained_item_matrix.pt"
ITEM_META_PATH = r"D:\trainDataset\localprops\features_item.parquet" # ì•„ì´í…œ ì´ë¦„ í™•ì¸í•  ë©”íƒ€ë°ì´í„°
import torch
import torch.nn as nn
import os
def verify_gnn_alignment(model, processor, base_dir):
    print(f"\nğŸ•µï¸â€â™‚ï¸ [GNN Verification] Checking GNN Alignment Integrity...")
    
    cache_dir = os.path.join(base_dir, "cache")
    model_path = os.path.join(MODEL_DIR, "simgcl_trained.pth")
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")
    
    try:
        # 1. ì›ë³¸ ì†ŒìŠ¤ ë¡œë“œ (ë¹„êµ ê¸°ì¤€)
        maps = torch.load(maps_path, map_location='cpu')
        gnn_item2id = maps['item2id'] # {'item_str': gnn_idx}
        
        gnn_state_dict = torch.load(model_path, map_location='cpu')
        gnn_source_weight = gnn_state_dict['embedding_item.weight'] # ì›ë³¸ ë²¡í„° ë­‰ì¹˜
        
    except Exception as e:
        print(f"âš ï¸ ì›ë³¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ë¡œ ê²€ì¦ ê±´ë„ˆëœ€: {e}")
        return

    # 2. í˜„ì¬ ëª¨ë¸ì˜ GNN ë ˆì´ì–´ ê°€ì ¸ì˜¤ê¸°
    # ì•„ê¹Œ ë³€ìˆ˜ëª…ì´ 'gnn_user_emb'ë¼ê³  í•˜ì…¨ìœ¼ë¯€ë¡œ ê·¸ê±¸ ê°€ì ¸ì˜µë‹ˆë‹¤.
    if hasattr(model, 'gnn_user_emb'):
        current_weight = model.gnn_user_emb.weight.detach().cpu()
    elif hasattr(model, 'item_gnn_emb'):
        current_weight = model.item_gnn_emb.weight.detach().cpu()
    else:
        print("âŒ [Error] ëª¨ë¸ì—ì„œ GNN ë ˆì´ì–´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    # 3. ìƒ˜í”Œë§ ê²€ì‚¬
    check_cnt = 0
    success_cnt = 0
    
    print(f"   -------------------------------------------------------------")
    print(f"   {'Status':<10} | {'Item ID':<15} | {'Vector Match?':<15} | {'Diff Sum'}")
    print(f"   -------------------------------------------------------------")

    for item_id_str in processor.item_ids:
        # 5ê°œë§Œ í™•ì¸
        if check_cnt >= 5: break
        
        # (1) í˜„ì¬ ëª¨ë¸ì—ì„œì˜ ìœ„ì¹˜ì™€ ê°’
        if item_id_str not in processor.item2id: continue
        target_idx = processor.item2id[item_id_str]
        model_vec = current_weight[target_idx]
        
        # (2) GNN ì›ë³¸ì—ì„œì˜ ìœ„ì¹˜ì™€ ê°’
        if item_id_str in gnn_item2id:
            gnn_idx = gnn_item2id[item_id_str]
            original_vec = gnn_source_weight[gnn_idx]
            
            # (3) ë¹„êµ
            is_same = torch.allclose(model_vec, original_vec, atol=1e-5)
            diff = (model_vec - original_vec).abs().sum().item()
            
            status = "âœ… Matched" if is_same else "âŒ Broken"
            print(f"   {status:<10} | {item_id_str:<15} | {str(is_same):<15} | {diff:.6f}")
            
            if is_same: success_cnt += 1
            check_cnt += 1
            
    print(f"   -------------------------------------------------------------")
    
    if success_cnt == check_cnt:
        print(f"ğŸ‰ [Success] GNN Vectors are perfectly aligned!")
    else:
        print(f"ğŸ”¥ [Fail] Some GNN vectors do not match. Check Alignment Logic!")
def load_and_align_gnn_items(model, processor, base_dir, device):
    """
    GNN í•™ìŠµ ê²°ê³¼(simgcl_trained.pth)ì™€ IDë§µ(id_maps_train.pt)ì„ ë¡œë“œí•˜ì—¬
    í˜„ì¬ User Towerì˜ ì•„ì´í…œ ìˆœì„œì— ë§ê²Œ ì¬ì •ë ¬ í›„ ì£¼ì…í•©ë‹ˆë‹¤.
    """
    print(f"\nğŸ”„ [GNN Alignment] Starting GNN Item Embedding Alignment...")
    
    # GNN í•™ìŠµ ì½”ë“œì— ì„¤ì •ëœ ê²½ë¡œ ê¸°ì¤€
    cache_dir = os.path.join(base_dir, "cache")
    
    # 1. íŒŒì¼ ê²½ë¡œ ì„¤ì •
    # GNN ëª¨ë¸ ê°€ì¤‘ì¹˜ (simgcl_trained.pth)
    model_path = os.path.join(MODEL_DIR , "simgcl_trained.pth")
    # GNN ID ë§¤í•‘ íŒŒì¼ (id_maps_train.pt)
    maps_path = os.path.join(cache_dir, "id_maps_train.pt")

    # 2. íŒŒì¼ ë¡œë“œ
    try:
        # (A) ID ë§¤í•‘ ë¡œë“œ
        maps = torch.load(maps_path, map_location='cpu')
        gnn_item2id = maps['item2id'] # {'item_str': index} í˜•íƒœ
        
        # (B) GNN ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        gnn_state_dict = torch.load(model_path, map_location='cpu')
        # GNN ì½”ë“œìƒ ë³€ìˆ˜ëª…: embedding_item.weight
        gnn_emb_weight = gnn_state_dict['embedding_item.weight']
        
        print(f"   - GNN Source: {gnn_emb_weight.shape} vectors")
        print(f"   - GNN Map Size: {len(gnn_item2id)} items")
        
    except Exception as e:
        print(f"âŒ [Error] Failed to load GNN files: {e}")
        print("   ğŸ‘‰ ê²½ë¡œê°€ ë§ëŠ”ì§€, GNN í•™ìŠµì´ ì™„ë£Œë˜ì—ˆëŠ”ì§€ í™•ì¸í•˜ì„¸ìš”.")
        return model

    # 3. íƒ€ê²Ÿ(User Tower)ì— ë§ëŠ” ìƒˆë¡œìš´ ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    # User Tower ì•„ì´í…œ ê°œìˆ˜ + 1 (Padding)
    num_embeddings = len(processor.item_ids) + 1 
    emb_dim = gnn_emb_weight.shape[1]
    
    # ì´ˆê¸°í™”: ë§¤ì¹­ ì•ˆ ë˜ëŠ” ê±´ ëœë¤ (ë˜ëŠ” 0)
    new_weight = torch.randn(num_embeddings, emb_dim) * 0.01
    new_weight[0] = 0.0 # Padding

    # 4. ë§¤í•‘ ìˆ˜í–‰ (Alignment)
    matched_count = 0
    missing_count = 0
    
    # processor.item_ids: User Towerê°€ ì‚¬ìš©í•˜ëŠ” ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ (ìˆœì„œ ì¤‘ìš”!)
    for i, current_id_str in enumerate(processor.item_ids):
        # User Towerì˜ ì¸ë±ìŠ¤ (1ë¶€í„° ì‹œì‘)
        target_idx = i + 1 
        
        # GNN ì¡±ë³´(gnn_item2id)ì— ì´ ì•„ì´í…œì´ ìˆëŠ”ê°€?
        if current_id_str in gnn_item2id:
            # GNNì—ì„œì˜ ì¸ë±ìŠ¤ ì°¾ê¸°
            gnn_idx = gnn_item2id[current_id_str]
            
            # ë²¡í„° ë³µì‚¬: GNN[gnn_idx] -> UserTower[target_idx]
            new_weight[target_idx] = gnn_emb_weight[gnn_idx]
            matched_count += 1
        else:
            missing_count += 1
            
    # 5. ëª¨ë¸ ì£¼ì…
    # HybridUserTower ë‚´ë¶€ì˜ GNN ì„ë² ë”© ë ˆì´ì–´ ë³€ìˆ˜ëª… í™•ì¸ í•„ìš”!
    # (ì—¬ê¸°ì„œëŠ” 'item_gnn_emb'ë¼ê³  ê°€ì •í•©ë‹ˆë‹¤. ë‹¤ë¥´ë©´ ìˆ˜ì •í•˜ì„¸ìš”!)
    target_layer_name = 'gnn_user_emb' 
    
    with torch.no_grad():
        if hasattr(model, target_layer_name):
            # [ì¤‘ìš”] freeze=False (ë¯¸ì„¸ì¡°ì • í—ˆìš©)
            setattr(model, target_layer_name, nn.Embedding.from_pretrained(new_weight.to(device), freeze=False))
            print(f"   âœ… Injected aligned vectors into 'model.{target_layer_name}'")
        else:
            # í˜¹ì‹œ ë³€ìˆ˜ëª…ì´ gnn_item_emb ì¼ ìˆ˜ë„ ìˆìŒ
            fallback_name = 'gnn_item_emb'
            if hasattr(model, fallback_name):
                setattr(model, fallback_name, nn.Embedding.from_pretrained(new_weight.to(device), freeze=False))
                print(f"   âœ… Injected aligned vectors into 'model.{fallback_name}'")
            else:
                print(f"âŒ [Critical] Could not find GNN layer in User Tower. Check variable names!")
                return model

    print(f"âœ… [GNN Alignment] Complete!")
    print(f"   - Matched: {matched_count}")
    print(f"   - Missing: {missing_count}")
    
    return model
def verify_embedding_alignment(model, processor, model_dir):
    print(f"\nğŸ•µï¸â€â™‚ï¸ [Verification] Checking Alignment Integrity...")
    
    # 1. ë¹„êµë¥¼ ìœ„í•´ ì›ë³¸(Source) ë‹¤ì‹œ ë¡œë“œ (ë©”ëª¨ë¦¬ ë¶€ë‹´ë˜ë©´ ìƒëµ ê°€ëŠ¥í•˜ì§€ë§Œ, í™•ì‹¤í•œ ê²€ì¦ì„ ìœ„í•´ ê¶Œì¥)
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")
    
    try:
        source_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(source_emb, dict):
            source_emb = source_emb.get('weight', source_emb.get('item_content_emb.weight'))
        source_ids = torch.load(ids_path, map_location='cpu')
    except:
        print("âš ï¸ ì›ë³¸ íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨ë¡œ ê²€ì¦ ê±´ë„ˆëœ€")
        return

    # ì›ë³¸ ë§µ ìƒì„±
    source_map = {}
    for idx, item_id in enumerate(source_ids):
        key = str(item_id.item()) if isinstance(item_id, torch.Tensor) else str(item_id)
        source_map[key] = source_emb[idx]

    # 2. ìƒ˜í”Œë§ ê²€ì‚¬ (ë§¤ì¹­ëœ ê²ƒ 5ê°œ, ì—†ëŠ” ê²ƒ 1ê°œ í™•ì¸)
    check_cnt = 0
    success_cnt = 0
    
    model_weight = model.item_content_emb.weight.detach().cpu()
    
    print(f"   -------------------------------------------------------------")
    print(f"   {'Status':<10} | {'Item ID':<15} | {'Vector Match?':<15} | {'Diff Sum'}")
    print(f"   -------------------------------------------------------------")

    for item_id_str in processor.item_ids:
        # 5ê°œë§Œ í™•ì¸í•˜ê³  ì¢…ë£Œ
        if check_cnt >= 5: break
        
        # ëª¨ë¸ ë‚´ ì¸ë±ìŠ¤ ì°¾ê¸°
        if item_id_str not in processor.item2id: continue
        target_idx = processor.item2id[item_id_str]
        
        # ëª¨ë¸ì— ìˆëŠ” ë²¡í„°
        current_vec = model_weight[target_idx]
        
        if item_id_str in source_map:
            # Case 1: ë§¤ì¹­ëœ ì•„ì´í…œ (Pretrainedì™€ ê°’ì´ ê°™ì•„ì•¼ í•¨)
            original_vec = source_map[item_id_str]
            
            # ê°’ì´ ê°™ì€ì§€ í™•ì¸ (ì˜¤ì°¨ 1e-5 ì´ë‚´)
            is_same = torch.allclose(current_vec, original_vec, atol=1e-5)
            diff = (current_vec - original_vec).abs().sum().item()
            
            status = "âœ… Matched" if is_same else "âŒ Broken"
            print(f"   {status:<10} | {item_id_str:<15} | {str(is_same):<15} | {diff:.6f}")
            if is_same: success_cnt += 1
            check_cnt += 1
            
        else:
            # Case 2: ë§¤ì¹­ ì•ˆ ëœ ì•„ì´í…œ (ê²€ì¦ ëŒ€ìƒ ì•„ë‹˜, ë¡œê·¸ë§Œ í™•ì¸)
            pass

    print(f"   -------------------------------------------------------------")
    
    if success_cnt == check_cnt:
        print(f"ğŸ‰ [Success] Vectors are perfectly aligned!")
    else:
        print(f"ğŸ”¥ [Fail] Some vectors do not match source. Check Logic!")
def check_embedding_sanity():
    print("ğŸ•µï¸â€â™‚ï¸ [Sanity Check] ID Mapping Verification Starting...")

    # 1. Pretrained Matrix ë¡œë“œ
    try:
        vectors = torch.load(ITEM_MATRIX_PATH, map_location='cpu')
        # ë§Œì•½ vectorsê°€ dict í˜•íƒœë¼ë©´ ê°€ì¤‘ì¹˜ í‚¤ë¥¼ ì°¾ì•„ì•¼ í•¨
        if isinstance(vectors, dict):
            vectors = vectors['weight'] if 'weight' in vectors else list(vectors.values())[0]
        
        print(f"âœ… Loaded Vectors: {vectors.shape}")
    except Exception as e:
        print(f"âŒ Failed to load vectors: {e}")
        return

    # 2. ì•„ì´í…œ ë©”íƒ€ë°ì´í„° ë¡œë“œ (ì´ë¦„ í™•ì¸ìš©)
    items_df = pd.read_parquet(ITEM_META_PATH)
    # article_idê°€ Stringì¸ì§€ í™•ì¸
    if 'article_id' in items_df.columns:
        items_df['article_id'] = items_df['article_id'].astype(str)
        items_df = items_df.set_index('article_id')
    
    # 3. í…ŒìŠ¤íŠ¸í•  ì•„ì´í…œ ì„ ì • (ìœ ëª…í•œê±°ë‚˜ ëœë¤ìœ¼ë¡œ)
    # ì˜ˆ: ë°ì´í„°í”„ë ˆì„ì˜ ì²« ë²ˆì§¸ ì•„ì´í…œ
    test_ids = items_df.index[:3].tolist() 
    
    # í•™ìŠµ ë•Œ ì‚¬ìš©í•œ item2idê°€ ìˆë‹¤ë©´ ê·¸ ìˆœì„œëŒ€ë¡œ ì¡°íšŒí•´ì•¼ í•¨.
    # ì—¬ê¸°ì„œëŠ” "Pretrained Matrixì˜ në²ˆì§¸ ì¤„ì´, items_dfì˜ në²ˆì§¸ ì•„ì´í…œê³¼ ì¼ì¹˜í•˜ëŠ”ì§€" ê°€ì •í•˜ê³  í…ŒìŠ¤íŠ¸
    
    vectors = F.normalize(vectors, p=2, dim=1)

    for i, target_id in enumerate(test_ids):
        if i >= len(vectors): break
        
        query_vec = vectors[i].unsqueeze(0) # ië²ˆì§¸ ë²¡í„° (ë¼ê³  ê°€ì •ë˜ëŠ” ê²ƒ)
        
        # ì „ì²´ì™€ì˜ ìœ ì‚¬ë„ ê³„ì‚°
        sims = torch.matmul(query_vec, vectors.T).squeeze()
        topk_val, topk_idx = torch.topk(sims, k=5) # ìê¸° ìì‹  í¬í•¨ ìƒìœ„ 5ê°œ
        
        target_name = items_df.loc[target_id]['prod_name'] if 'prod_name' in items_df.columns else "Unknown"
        print(f"\nğŸ¯ Query [{i}]: ID={target_id} ({target_name})")
        print("-" * 40)
        
        for rank, idx in enumerate(topk_idx.tolist()):
            idx = int(idx)
            # ìˆœì„œê°€ ë§ë‹¤ë©´ items_dfì˜ idxë²ˆì§¸ ì•„ì´í…œ ì •ë³´ë¥¼ ê°€ì ¸ì™€ì•¼ í•¨
            if idx < len(items_df):
                neighbor_id = items_df.index[idx]
                neighbor_name = items_df.iloc[idx]['prod_name'] if 'prod_name' in items_df.columns else "Unknown"
                score = topk_val[rank].item()
                print(f"   Rank {rank}: {neighbor_name} (Sim: {score:.4f})")
            else:
                print(f"   Rank {rank}: Index {idx} (Out of DF bounds)")
        
        print("-" * 40)

    print("\nğŸ¤” íŒë‹¨ ê¸°ì¤€:")
    print("1. Rank 0ì€ ë¬´ì¡°ê±´ ìê¸° ìì‹ ì´ ë‚˜ì™€ì•¼ í•¨ (Sim 1.0)")
    print("2. Rank 1~4ì— ì˜ë¯¸ì ìœ¼ë¡œ ë¹„ìŠ·í•œ ìƒí’ˆ(ì˜ˆ: ê°™ì€ ì¹´í…Œê³ ë¦¬)ì´ ë‚˜ì™€ì•¼ í•¨")
    print("ğŸ‘‰ ë§Œì•½ Rank 0ì— ì—‰ëš±í•œ ì´ë¦„ì´ ë‚˜ì˜¤ê±°ë‚˜, ìœ ì‚¬ ìƒí’ˆì´ ì „í˜€ ìŒ©ëš±ë§ë‹¤ë©´ 'ID ìˆœì„œ ê¼¬ì„' í™•ì •!")


# -------------------------------------------------------------------------
# 1. Feature Processor (Scaler ë¡œì§ ìˆ˜ì •)
# -------------------------------------------------------------------------
class FeatureProcessor:
    def __init__(self, user_path, item_path, seq_path, scaler=None):
        self.users = pd.read_parquet(user_path).set_index('customer_id')
        self.items = pd.read_parquet(item_path).set_index('article_id')
        self.seqs = pd.read_parquet(seq_path).set_index('customer_id')
        self.user_ids = self.users.index.tolist()
        self.user2id = {uid: i + 1 for i, uid in enumerate(self.user_ids)}
        self.item_ids = self.items.index.tolist()
        self.item2id = {iid: i + 1 for i, iid in enumerate(self.item_ids)}
        
        self.u_dense_cols = ['user_avg_price_log', 'total_cnt_log', 'recency_log']
        self.users_scaled = self.users.copy()
        self.user_scaler = StandardScaler()

        # [ìˆ˜ì •] Scaler ê³µìœ  ë¡œì§
        if scaler is None: # í•™ìŠµìš© (Fit ìˆ˜í–‰)
            self.users_scaled[self.u_dense_cols] = self.user_scaler.fit_transform(self.users[self.u_dense_cols])
        else: # ê²€ì¦ìš© (Trainì˜ ë¶„í¬ë¥¼ ê·¸ëŒ€ë¡œ ì‚¬ìš©)
            self.user_scaler = scaler
            self.users_scaled[self.u_dense_cols] = self.user_scaler.transform(self.users[self.u_dense_cols])

    def get_user_tensor(self, user_id):
        dense = torch.tensor(self.users_scaled.loc[user_id, self.u_dense_cols].values, dtype=torch.float32)
        cat = torch.tensor(int(self.users_scaled.loc[user_id, 'preferred_channel']) - 1, dtype=torch.long)
        return dense, cat

    def get_logq_probs(self, device):
        sorted_probs = self.items['raw_probability'].reindex(self.item_ids).fillna(0).values
   
        return torch.tensor(sorted_probs, dtype=torch.float32).to(device)

def load_and_align_embeddings(model, processor, model_dir, device):
    """
    Pretrained ì„ë² ë”©(66k)ì„ í˜„ì¬ ë°ì´í„°ì…‹(47k) ìˆœì„œì— ë§ì¶° ì¬ì •ë ¬í•˜ì—¬ ëª¨ë¸ì— ì£¼ì…í•˜ëŠ” í•¨ìˆ˜
    """
    print(f"\nğŸ”„ [Alignment] Starting Item Embedding Alignment...")
    
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")

    # 1. íŒŒì¼ ë¡œë“œ
    try:
        # ì„ë² ë”© ë¡œë“œ
        pretrained_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(pretrained_emb, dict):
             # state_dict í˜•íƒœë¡œ ì €ì¥ëœ ê²½ìš° 'weight' í‚¤ë¥¼ ì°¾ìŒ
            pretrained_emb = pretrained_emb.get('weight', pretrained_emb.get('item_content_emb.weight'))
        
        # ID ë¦¬ìŠ¤íŠ¸ ë¡œë“œ
        pretrained_ids = torch.load(ids_path, map_location='cpu')
        
        print(f"   - Pretrained Source: {pretrained_emb.shape} vectors, {len(pretrained_ids)} IDs")
        
    except Exception as e:
        print(f"âŒ [Error] Failed to load pretrained files: {e}")
        return model

    # 2. Dictionaryë¡œ ë³€í™˜ (ê²€ìƒ‰ ì†ë„ í–¥ìƒ: O(1))
    # { 'ì•„ì´í…œID_ìŠ¤íŠ¸ë§': ë²¡í„°_í…ì„œ }
    pretrained_map = {}
    for idx, item_id in enumerate(pretrained_ids):
        # item_idê°€ Tensorë©´ ê°’ì„ êº¼ë‚´ê³ , ì•„ë‹ˆë©´ ê·¸ëŒ€ë¡œ ë¬¸ìì—´ ë³€í™˜
        key = str(item_id.item()) if isinstance(item_id, torch.Tensor) else str(item_id)
        pretrained_map[key] = pretrained_emb[idx]

    # 3. íƒ€ê²Ÿ(í˜„ì¬ ëª¨ë¸)ì— ë§ëŠ” ìƒˆë¡œìš´ ì„ë² ë”© ë§¤íŠ¸ë¦­ìŠ¤ ìƒì„±
    # processor.item_ids ê°œìˆ˜ + 1 (Paddingìš© 0ë²ˆ ì¸ë±ìŠ¤)
    num_embeddings = len(processor.item_ids) + 1 
    emb_dim = pretrained_emb.shape[1]
    
    # ì´ˆê¸°í™”: ëœë¤ ê°’ìœ¼ë¡œ ì‹œì‘ (ë§¤ì¹­ ì•ˆ ë˜ëŠ” ì‹ ê·œ ì•„ì´í…œì„ ìœ„í•´)
    new_weight = torch.randn(num_embeddings, emb_dim) * 0.01 
    # Padding(0ë²ˆ)ì€ 0ìœ¼ë¡œ ê³ ì •
    new_weight[0] = 0.0 

    # 4. ë§¤í•‘ ìˆ˜í–‰ (Alignment)
    matched_count = 0
    missing_count = 0
    
    # processor.item_idsëŠ” ì‹¤ì œ ì•„ì´í…œ ë¦¬ìŠ¤íŠ¸ (1ë²ˆ ì¸ë±ìŠ¤ë¶€í„° ì‹œì‘)
    for i, current_id_str in enumerate(processor.item_ids):
        target_idx = i + 1  # ëª¨ë¸ ë‚´ ì¸ë±ìŠ¤ (0ì€ íŒ¨ë”©ì´ë¯€ë¡œ +1)
        
        if current_id_str in pretrained_map:
            # ë§¤ì¹­ ì„±ê³µ: ë²¡í„° ë³µì‚¬
            new_weight[target_idx] = pretrained_map[current_id_str]
            matched_count += 1
        else:
            # ë§¤ì¹­ ì‹¤íŒ¨: ëœë¤ ì´ˆê¸°í™” ìœ ì§€ (ì‹ ê·œ ì•„ì´í…œ ë“±)
            missing_count += 1
            
    # 5. ëª¨ë¸ì— ì£¼ì… (ìˆ˜ìˆ )
    with torch.no_grad():
        # ëª¨ë¸ì˜ ì„ë² ë”© ë ˆì´ì–´ êµì²´
        # [ì¤‘ìš”] freeze=Falseë¡œ ì„¤ì •í•˜ì—¬ Missing ì•„ì´í…œë„ í•™ìŠµë˜ê²Œ í•¨
        model.item_content_emb = nn.Embedding.from_pretrained(new_weight.to(device), freeze=False)
        
    print(f"âœ… [Alignment] Complete!")
    print(f"   - Matched: {matched_count} (Recovered from Pretrained)")
    print(f"   - Missing: {missing_count} (Initialized Randomly)")
    print(f"   - Total: {num_embeddings} rows injected into Model.")
    
    return model

def load_and_align_gnn_user_embeddings(gnn_model_path, gnn_map_path, target_user_ids, device='cpu'):
    logger.log(1, "ğŸ”„ Aligning GNN User Embeddings...")

    # 1. íŒŒì¼ ì¡´ì¬ í™•ì¸
    if not os.path.exists(gnn_model_path) or not os.path.exists(gnn_map_path):
        logger.log(1, f"âš ï¸ GNN files missing ({gnn_model_path} or {gnn_map_path}). Using Random Init.")
        return None

    try:
        # 2. GNN ëª¨ë¸ ê°€ì¤‘ì¹˜ ë¡œë“œ
        state_dict = torch.load(gnn_model_path, map_location=device)
        
        # SimGCL ì½”ë“œ ê¸°ì¤€ ë³€ìˆ˜ëª…: 'embedding_user.weight'
        # í˜¹ì‹œ ëª¨ë¥´ë‹ˆ ê²€ìƒ‰ ë¡œì§ ìœ ì§€
        gnn_matrix = None
        for key, tensor in state_dict.items():
            if 'embedding_user' in key and tensor.ndim == 2:
                gnn_matrix = tensor
                break
        
        if gnn_matrix is None:
            logger.log(1, "âŒ Could not find 'embedding_user' in GNN state_dict.")
            return None

        # 3. GNN ID ë§¤í•‘ ë¡œë“œ
        # SimGCL ì €ì¥ ì½”ë“œ: torch.save({'user2id': user2id, ...}, map_path)
        maps = torch.load(gnn_map_path)
        if 'user2id' not in maps:
            logger.log(1, "âŒ 'user2id' key missing in GNN map file.")
            return None
            
        gnn_user2id = maps['user2id'] # {user_str: int_idx}

        # 4. ì •ë ¬ (Alignment)
        num_target = len(target_user_ids) + 1
        dim = gnn_matrix.shape[1]
    
        # ê¸°ë³¸ì ìœ¼ë¡œ 0.0ìœ¼ë¡œ ì±„ì›Œì§ (Padding Vector ì—­í• )
        aligned_matrix = torch.zeros((num_target, dim), dtype=torch.float32)
        
        hit_count = 0
        
        for i, u_id in enumerate(target_user_ids):
                # FeatureProcessor ìˆœì„œìƒ ië²ˆì§¸ ìœ ì €ëŠ” -> ëª¨ë¸ ë‚´ë¶€ì—ì„œ i+1ë²ˆ ì¸ë±ìŠ¤ë¥¼ ì”€
            current_idx = i + 1 
                
            if u_id in gnn_user2id:
                    # GNNì—ì„œëŠ” 0ë¶€í„° ì‹œì‘í–ˆìœ¼ë¯€ë¡œ ê·¸ëŒ€ë¡œ ê°€ì ¸ì˜´
                origin_idx = gnn_user2id[u_id] 
                    
                    # ì¸ë±ìŠ¤ ë²”ìœ„ ì•ˆì „ì¥ì¹˜
                if origin_idx < gnn_matrix.shape[0]:
                        # â˜… ì—¬ê¸°ê°€ í•µì‹¬: GNN(origin) -> Tower(current=i+1)
                    aligned_matrix[current_idx] = gnn_matrix[origin_idx]
                    hit_count += 1
                else:
                    torch.nn.init.xavier_normal_(aligned_matrix[current_idx].unsqueeze(0))
            else:
                    # GNNì— ì—†ë˜ ìœ ì €ëŠ” ëœë¤ ì´ˆê¸°í™”
                torch.nn.init.xavier_normal_(aligned_matrix[current_idx].unsqueeze(0))

        logger.log(1, f"âœ… GNN Alignment: {hit_count}/{len(target_user_ids)} users aligned.")
        if aligned_matrix is not None:
            aligned_matrix = F.normalize(aligned_matrix, p=2, dim=1)
            
        logger.log(1, f"âœ… GNN Alignment: {hit_count}/{len(target_user_ids)} users aligned.")
        return aligned_matrix

    except Exception as e:
        logger.log(1, f"âŒ Error during GNN alignment: {e}")
        return None
    
   
def load_and_align_item_vectors(pretrained_path, id_path, target_item_ids, embed_dim=128):
    logger.log(1, "Aligning Item Vectors (Pretrained -> Current Model)...")
    
    if not os.path.exists(pretrained_path) or not os.path.exists(id_path):
        logger.log(1, "âš ï¸ Pretrained item files missing. Returning Random.")
        return None
        
    master_matrix = torch.load(pretrained_path, map_location='cpu') 
    master_ids = torch.load(id_path)
    
    logger.log(2, f"Loaded Master Matrix: {master_matrix.shape}, IDs: {len(master_ids)}")
    
    master_id2idx = {pid: i for i, pid in enumerate(master_ids)}
    num_target = len(target_item_ids) + 1
    aligned_matrix = torch.zeros((num_target, embed_dim), dtype=torch.float32)
    
    for i, target_id in enumerate(target_item_ids):
        # [ì¤‘ìš”] Tower ì¸ë±ìŠ¤ëŠ” 1ë¶€í„°
        current_idx = i + 1
        
        if target_id in master_id2idx:
            origin_idx = master_id2idx[target_id]
            # Master(origin) -> Tower(current=i+1)
            aligned_matrix[current_idx] = master_matrix[origin_idx]
        else:
            torch.nn.init.xavier_normal_(aligned_matrix[current_idx].unsqueeze(0))
            
        if aligned_matrix is not None:
            aligned_matrix = F.normalize(aligned_matrix, p=2, dim=1)
        
        return aligned_matrix
# -------------------------------------------------------------------------
# 2. Final Dataset (Slicing ë¡œì§ ìˆ˜ì •)
# -------------------------------------------------------------------------
class UserTowerDataset(Dataset):
    def __init__(self, processor, max_seq_len=50, is_training=True):
        self.processor = processor
        self.user_ids = processor.user_ids 
        self.max_len = max_seq_len
        self.is_training = is_training
        self.min_cut_len = 3      
        self.last_item_prob = 0.2

    def __len__(self):
        return len(self.user_ids)

    def __getitem__(self, idx):
        u_id_str = self.user_ids[idx]
        u_dense, u_cat = self.processor.get_user_tensor(u_id_str)
        
        processed_tokens = []
        processed_deltas = []
        
        # ... (ì‹œí€€ìŠ¤ ë¡œë“œ ë¡œì§ì€ ê¸°ì¡´ê³¼ ë™ì¼) ...
        if u_id_str in self.processor.seqs.index:
            seq_row = self.processor.seqs.loc[u_id_str]
            # (ì¤‘ëµ: í† í° íŒŒì‹± ë¡œì§ ë™ì¼)
            for i, d in zip(seq_row['sequence_ids'], seq_row['sequence_deltas']):
                 token = self.processor.item2id.get(i, 0)
                 if token == 0: continue
                 processed_tokens.append(token)
                 processed_deltas.append(d)

        seq_len = len(processed_tokens)

        # ------------------------------------------------------------------
        # [ìˆ˜ì • 1] All-Actionì„ ìœ„í•œ Slicing ë¡œì§ ë³€ê²½
        # ------------------------------------------------------------------
        input_seq = []
        target_seq = [] 

        if seq_len > 0:
            if self.is_training:
                # 1. ëœë¤ ì»·ì´ ê°€ëŠ¥í•œì§€ í™•ì¸ (ìµœì†Œ 2ê°œëŠ” ìˆì–´ì•¼ Input/Target ë‚˜ëˆ”)
                can_sample = seq_len > self.min_cut_len

                # 2. ë¡œì§ ë¶„ê¸°
                # (ìë¥¼ ìˆ˜ ì—†ê±°ë‚˜ OR 80% í™•ë¥ ) -> ì „ì²´ ì‚¬ìš©
                if not can_sample or random.random() < 0.8:
                    # [ìˆ˜ì • í¬ì¸íŠ¸] ì „ì²´ë¥¼ ë‹¤ ì“¸ ë•Œë„ ShiftëŠ” í•„ìˆ˜ì…ë‹ˆë‹¤!
                    # ì›ë³¸: [A, B, C, D]
                    # Input: [A, B, C]  (ë§ˆì§€ë§‰ DëŠ” ì •ë‹µìœ¼ë¡œ ì¨ì•¼ í•˜ë‹ˆê¹Œ Inputì—ì„œ ì œì™¸)
                    # Target: [B, C, D] (A ë‹¤ìŒì€ Bë‹ˆê¹Œ 1ë²ˆë¶€í„° ì‹œì‘)
                    input_seq = processed_tokens[:-1]
                    target_seq = processed_tokens[1:]
                
                else:
                    # 20% í™•ë¥  -> Random Cut
                    # randint ë²”ìœ„ ì—ëŸ¬ ë°©ì§€
                    max_cut = seq_len - 1
                    if max_cut < self.min_cut_len:
                        cut_idx = seq_len # ì˜ˆì™¸ì²˜ë¦¬
                    else:
                        cut_idx = random.randint(self.min_cut_len, max_cut)
                    
                    # cut_idx+1 ê¹Œì§€ ê°€ì ¸ì™€ì„œ Input/Target ë¶„ë¦¬
                    full_slice = processed_tokens[:cut_idx+1]
                    input_seq = full_slice[:-1]
                    target_seq = full_slice[1:]
            
            else:
                # í‰ê°€ ì‹œ
                input_seq = processed_tokens[:]
                target_seq = [0] * len(input_seq)
        # ------------------------------------------------------------------
        # Padding & Truncation (Window Sliding)
        # ------------------------------------------------------------------
        # Max Lenì— ë§ì¶° ë’¤ì—ì„œë¶€í„° ìë¦„
        input_ids = input_seq[-self.max_len:]
        target_ids = target_seq[-self.max_len:]
        
        # DeltaëŠ” Input ê¸¸ì´ì— ë§ì¶¤
        input_deltas = processed_deltas[:len(input_seq)][-self.max_len:]

        return {
            'user_idx': torch.tensor(idx + 1, dtype=torch.long),
            'user_dense': u_dense, 'user_cat': u_cat,
            # ë¦¬ìŠ¤íŠ¸ -> í…ì„œ ë³€í™˜
            'seq_ids': torch.tensor(input_ids, dtype=torch.long),
            'seq_deltas': torch.tensor(input_deltas, dtype=torch.long),
            'target_ids': torch.tensor(target_ids, dtype=torch.long) # [ë³€ê²½] ì‹œí€€ìŠ¤ í˜•íƒœ
        }

def user_tower_collate_fn(batch):
    u_idx = torch.stack([b['user_idx'] for b in batch])
    u_dense = torch.stack([b['user_dense'] for b in batch])
    u_cat = torch.stack([b['user_cat'] for b in batch])
    
    # Pad Sequence (Batch First)
    seq_ids = pad_sequence([b['seq_ids'] for b in batch], batch_first=True, padding_value=0)
    seq_deltas = pad_sequence([b['seq_deltas'] for b in batch], batch_first=True, padding_value=0)
    target_ids = pad_sequence([b['target_ids'] for b in batch], batch_first=True, padding_value=0) # [ë³€ê²½] Padding
    
    seq_mask = (seq_ids != 0).long()
    
    # í‰ê°€ìš©(Validation)ì„ ìœ„í•´ ë§ˆì§€ë§‰ íƒ€ê²Ÿ ì•„ì´í…œ í•˜ë‚˜ëŠ” ë³„ë„ë¡œ ë½‘ì•„ë‘˜ ìˆ˜ ìˆìŒ
    # í•™ìŠµì‹œëŠ” target_ids ì „ì²´ë¥¼ ì”€
    last_target = torch.tensor([b['target_ids'][-1] if len(b['target_ids']) > 0 else 0 for b in batch], dtype=torch.long)

    return u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, last_target

# -------------------------------------------------------------------------
# 3. Model Components (Simplified for Convergence)
# -------------------------------------------------------------------------
# [ìˆ˜ì •] ì´ˆê¸° ìˆ˜ë ´ì„ ìœ„í•´ ë³µì¡í•œ Gating ëŒ€ì‹  Robustí•œ MLP Fusion ì‚¬ìš©
class RobustFusion(nn.Module):
    def __init__(self, dim=128):
        super().__init__()
        # 3ê°œì˜ 128ì°¨ì› ë²¡í„°ë¥¼ Concat -> 384
        self.fusion_mlp = nn.Sequential(
            nn.Linear(dim * 3, dim * 2),
            nn.LayerNorm(dim * 2),
            nn.GELU(),
            nn.Dropout(0.1),
            nn.Linear(dim * 2, dim),
            nn.LayerNorm(dim) # ìµœì¢… ì¶œë ¥ ì •ê·œí™” ë„ì›€
        )

    def forward(self, v_gnn, v_seq, v_meta):
        combined = torch.cat([v_gnn, v_seq, v_meta], dim=-1)
        return self.fusion_mlp(combined)

class HybridUserTower(nn.Module):
    def __init__(self, num_users, num_items, gnn_emb_init, item_emb_init):
        super().__init__()
        self.embed_dim = 128
        
        # A. Pretrained Layers
        self.gnn_user_emb = nn.Embedding.from_pretrained(gnn_emb_init, freeze=True)
        self.gnn_projector = nn.Sequential(
            nn.Linear(gnn_emb_init.shape[1], 256), # í•œë²ˆ í™• ë„“í˜”ë‹¤ê°€
            nn.LayerNorm(256),
            nn.GELU(),
            nn.Dropout(DROPOUT),
            nn.Linear(256, 128), # ë‹¤ì‹œ ì¤„ì„ (ì •ë³´ ì••ì¶• ë° ì •ë ¬)
            nn.LayerNorm(128)    # ë§ˆì§€ë§‰ì— ì •ê·œí™” í•„ìˆ˜
        )   
        self.item_content_emb = nn.Embedding.from_pretrained(item_emb_init, freeze=True)
        
        # B. Sequence Layers
        self.time_emb = nn.Embedding(1001, 128)
        encoder_layer = nn.TransformerEncoderLayer(
        d_model=128, 
        nhead=4, # í—¤ë“œ ìˆ˜ë„ 4 -> 8ë¡œ ëŠ˜ë¦¬ë©´ ë” ì¢‹ìŠµë‹ˆë‹¤ (ì„ íƒì‚¬í•­)
        dim_feedforward=512, 
        dropout=DROPOUT, 
        batch_first=True,
        norm_first=True
        )
        self.seq_encoder = nn.TransformerEncoder(encoder_layer, num_layers=4)
        
        # C. Meta Layers
        self.channel_emb = nn.Embedding(2, 32)
        self.meta_mlp = nn.Sequential(nn.Linear(35, 128), nn.GELU(), nn.Linear(128, 128), nn.LayerNorm(128))
        
        # D. Fusion Layer (Simplified)
        self.fusion_layer = RobustFusion(dim=128)

    def forward(self, u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat):
        B, L = seq_ids.shape
        
        # 1. GNN Features (Static -> Broadcast)
        v_gnn = self.gnn_projector(self.gnn_user_emb(u_idx))
        v_gnn = F.normalize(v_gnn, p=2, dim=1)
        # [ìˆ˜ì •] (B, D) -> (B, L, D) ë¡œ í™•ì¥
        v_gnn_seq = v_gnn.unsqueeze(1).expand(-1, L, -1)
        
        # 2. Meta Features (Static -> Broadcast)
        cat_vec = self.channel_emb(u_cat)
        v_meta = self.meta_mlp(torch.cat([u_dense, cat_vec], dim=1))
        v_meta = F.normalize(v_meta, p=2, dim=1)
        # [ìˆ˜ì •] (B, D) -> (B, L, D) ë¡œ í™•ì¥
        v_meta_seq = v_meta.unsqueeze(1).expand(-1, L, -1)
        
        # 3. Sequence Features (Transformer with Causal Mask)
        seq_input = self.item_content_emb(seq_ids) * math.sqrt(self.embed_dim) + self.time_emb(seq_deltas.clamp(max=1000))
        
        # [í•µì‹¬] Causal Mask ìƒì„± (ë¯¸ë˜ ì°¸ì¡° ë°©ì§€)
        # ìƒì‚¼ê°í–‰ë ¬(Upper Triangular)ì„ -infë¡œ ë§ˆìŠ¤í‚¹
        causal_mask = torch.triu(torch.ones(L, L, device=seq_ids.device) * float('-inf'), diagonal=1)
        
        # Padding Mask (Key Padding Mask)
        # PyTorch TransformerëŠ” (B, L) í˜•íƒœì˜ True/False ë§ˆìŠ¤í¬ë¥¼ ë°›ìŒ (Trueê°€ ë¬´ì‹œë¨)
        key_padding_mask = (seq_mask == 0)

        # Transformer Forward
        # is_causal=True (PyTorch 2.0+) í˜¹ì€ mask=causal_mask ì‚¬ìš©
        seq_out = self.seq_encoder(seq_input, mask=causal_mask, src_key_padding_mask=key_padding_mask)
        
        # [ìˆ˜ì •] Attention Pooling ëŒ€ì‹ , ì¼ë‹¨ ëª¨ë“  ìŠ¤í…ì˜ ì¶œë ¥ì„ ì‚¬ìš© (All-Action)
        v_seq = F.normalize(seq_out, p=2, dim=2) # (B, L, D)

        # 4. Final Fusion (All Steps)
        # (B, L, D) + (B, L, D) + (B, L, D) -> (B, L, D)
        # RobustFusion(MLP)ì€ ë§ˆì§€ë§‰ ì°¨ì›ë§Œ ë§ìœ¼ë©´ 3D í…ì„œë„ ì²˜ë¦¬ ê°€ëŠ¥
        output = self.fusion_layer(v_gnn_seq, v_seq, v_meta_seq)
        
        return F.normalize(output, p=2, dim=2) # (B, L, D) ë¦¬í„´

# -------------------------------------------------------------------------
# 4. Improved Loss Function (Mathematical Fix)
# -------------------------------------------------------------------------
def logq_correction_loss(user_emb, item_emb, pos_item_ids, item_probs, temperature=0.07, lambda_logq=0.0):
    # 1. ë‚´ì  (Cosine Similarity)
    scores = torch.matmul(user_emb, item_emb.T)
    
    # 2. LogQ Correction (ë¨¼ì € ìˆ˜í–‰)
    if lambda_logq > 0.0:
        log_q = torch.log(item_probs[pos_item_ids] + 1e-9).view(1, -1) # [1, Batch]
        scores = scores - (lambda_logq * log_q)

    # 3. Temperature Scaling (ë‚˜ì¤‘ì— ìˆ˜í–‰)
    logits = scores / temperature

    # 4. In-batch Masking
    is_collision = (pos_item_ids.unsqueeze(1) == pos_item_ids.unsqueeze(0))
    mask = is_collision.fill_diagonal_(False)
    logits = logits.masked_fill(mask, -1e4) # FP16 Safe value

    labels = torch.arange(logits.size(0), device=logits.device)
    return F.cross_entropy(logits, labels)
def evaluate_recall_multi_k(model, processor, target_df_path, k_list=[20, 100, 500], batch_size=1024):
    model.eval()
    
    # Target Dictionary ë¡œë“œ
    target_df = pd.read_parquet(target_df_path)
    # customer_idê°€ indexì¸ dict ìƒì„±
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    # Valid Dataset ë¡œë”
    val_loader = DataLoader(
        UserTowerDataset(processor, is_training=False), 
        batch_size=batch_size, 
        shuffle=False, 
        collate_fn=user_tower_collate_fn
    )
    
    # [í•µì‹¬] ì „ì²´ ì•„ì´í…œ ë²¡í„° ìºì‹±
    # processor.item_idsëŠ” train_procê³¼ ë™ê¸°í™”ë˜ì–´ ìˆìœ¼ë¯€ë¡œ, ëª¨ë¸ì˜ ì„ë² ë”© ìˆœì„œì™€ ì¼ì¹˜í•¨.
    with torch.no_grad():
        all_item_vecs = F.normalize(
            model.item_content_emb(torch.arange(1, len(processor.item_ids)+1).to(DEVICE)), 
            p=2, dim=1
        )

    hit_counts = {k: 0 for k in k_list}
    total_users = 0
    
    with torch.no_grad():
        for batch in tqdm(val_loader, desc="Evaluating"):
            # Unpacking (Valid ëª¨ë“œì¼ ë•Œ ë°˜í™˜ê°’ ê°œìˆ˜ ì£¼ì˜)
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, _, _ = [x.to(DEVICE) for x in batch]
            
            # User ID String ë³µì›
            batch_uids = [processor.user_ids[i-1] for i in u_idx.cpu().numpy()]
            
            # Targetì´ ìˆëŠ” ìœ ì €ë§Œ í•„í„°ë§
            valid_idx_list = [i for i, uid in enumerate(batch_uids) if uid in target_dict]
            if not valid_idx_list: continue
            
            v_idx = torch.tensor(valid_idx_list).to(DEVICE)
            
            # 1. Forward (Last Hidden State)
            seq_out = model(
                u_idx[v_idx], seq_ids[v_idx], seq_deltas[v_idx], 
                seq_mask[v_idx], u_dense[v_idx], u_cat[v_idx]
            )
            
            # Last Valid Step ì¶”ì¶œ
            lengths = seq_mask[v_idx].sum(dim=1)
            last_indices = (lengths - 1).clamp(min=0)
            
            batch_range = torch.arange(seq_out.size(0), device=DEVICE)
            last_user_vecs = seq_out[batch_range, last_indices]
            
            # 2. Similarity Search (Dot Product)
            # (Batch, Dim) @ (Dim, Num_Items) -> (Batch, Num_Items)
            scores = torch.matmul(last_user_vecs, all_item_vecs.T)
            
            # Top-K ì¶”ì¶œ
            _, topk_indices = torch.topk(scores, k=max(k_list), dim=1)
            pred_ids = (topk_indices + 1).cpu().numpy() # Index -> ItemID(1~)
            
            # 3. Hit Calculation
            for i, original_idx in enumerate(valid_idx_list):
                u_id = batch_uids[original_idx]
                actual_item_ids = target_dict[u_id] # ì •ë‹µ ì•„ì´í…œë“¤ (String List)
                
                # String ID -> Integer Index ë³€í™˜ (processor.item2id ì‚¬ìš©)
                # ë§Œì•½ Valid Setì— Trainì— ì—†ë˜ ì‹ ê·œ ì•„ì´í…œì´ ìˆë‹¤ë©´ ì—¬ê¸°ì„œ ê±¸ëŸ¬ì§ (ì•ˆì „!)
                actual_indices = set(
                    processor.item2id[tid] for tid in actual_item_ids if tid in processor.item2id
                )
                
                if not actual_indices: continue

                # ì„±ëŠ¥ ìµœì í™”ëœ Hit Check
                # pred_ids ìƒìœ„ kê°œ ì¤‘ì— actualì´ í•˜ë‚˜ë¼ë„ ìˆëŠ”ì§€ í™•ì¸
                for k in k_list:
                    # numpy array slicingì€ ë¹ ë¦„
                    preds_k = pred_ids[i, :k]
                    # êµì§‘í•©ì´ ìˆìœ¼ë©´ Hit
                    if not actual_indices.isdisjoint(preds_k):
                        hit_counts[k] += 1
                        
                total_users += 1
    
    # Metric ì§‘ê³„
    metrics = {f"R@{k}": (hit_counts[k] / total_users if total_users > 0 else 0.0) for k in k_list}
    logger.log(1, f"ğŸ“Š Eval Result: {metrics}")
    
    model.train() # ë‹¤ì‹œ Train ëª¨ë“œë¡œ ë³µê·€
    return metrics
# -------------------------------------------------------------------------
# 5. Training Loop
# -------------------------------------------------------------------------
def train_phase_2_5_emergency_fix():
    logger.log(1, "ğŸš€ Phase 2.5: Emergency Fix Running...")
    
    # [ìˆ˜ì •] Scalerë¥¼ Trainì—ì„œ Validë¡œ ë„˜ê²¨ì¤Œ
    train_proc = FeatureProcessor(USER_FEAT_PATH_PQ, ITEM_FEAT_PATH_PQ, SEQ_DATA_PATH_PQ, scaler=None)
    valid_proc = FeatureProcessor(USER_VAL_FEAT_PATH, ITEM_FEAT_PATH_PQ, SEQ_VAL_DATA_PATH, scaler=train_proc.user_scaler)
    valid_proc.item2id, valid_proc.item_ids = train_proc.item2id, train_proc.item_ids

    '''

    
        # 4. ì €ì¥ëœ ê°€ì¤‘ì¹˜(State Dict) ë®ì–´ì”Œìš°ê¸°
    if os.path.exists(SAVE_PATH_BEST_PREV):
        checkpoint = torch.load(SAVE_PATH_BEST_PREV, map_location=DEVICE)
        model.load_state_dict(checkpoint, strict=True) # strict=True: êµ¬ì¡°ê°€ ì™„ë²½íˆ ì¼ì¹˜í•´ì•¼ í•¨
        print(f"âœ… Successfully loaded model from: {SAVE_PATH_BEST_PREV}")
    else:
        print(f"âŒ Model file not found: {SAVE_PATH_BEST_PREV}")
        
    
    # Optimizer
    optimizer = optim.AdamW([
    # ìƒìœ„ ë ˆì´ì–´ (ìœ ì € íƒ€ì›Œ)
        {'params': model.seq_encoder.parameters(), 'lr': 1e-5},
        {'params': model.fusion_layer.parameters(), 'lr': 1e-5},
        {'params': model.meta_mlp.parameters(), 'lr': 1e-5},
        {'params': model.gnn_projector.parameters(), 'lr': 1e-5},
        
        # í•˜ìœ„ ë ˆì´ì–´ (ê±°ëŒ€ ì„ë² ë”©) - ì—¬ê¸°ê°€ í•µì‹¬!
        {'params': model.gnn_user_emb.parameters(), 'lr': 5e-6},
        {'params': model.item_content_emb.parameters(), 'lr': 5e-6},
    ], weight_decay=1e-4)
    '''
    
    
    
    num_users = len(train_proc.user_ids) + 1
    num_items = len(train_proc.item_ids) + 1
    dummy_gnn_tensor = torch.zeros((num_users, 64))
    dummy_item_tensor = torch.zeros((num_items, 128))

    model = HybridUserTower(
        num_users, 
        num_items, 
        gnn_emb_init=dummy_gnn_tensor, 
        item_emb_init=dummy_item_tensor
    ).to(DEVICE)
   
    model = load_and_align_embeddings(model, train_proc, model_dir=MODEL_DIR, device=DEVICE)
    verify_embedding_alignment(model, train_proc, model_dir=MODEL_DIR)

    model = load_and_align_gnn_items(model, train_proc, base_dir=BASE_DIR, device=DEVICE)
    verify_gnn_alignment(model, train_proc, base_dir=BASE_DIR)
    
    
    model_params = filter(lambda p: p.requires_grad, model.parameters())

# [ì¶”ì²œ ì„¤ì •]
    optimizer = optim.AdamW(
        model_params, 
        lr=5e-4,           # [ë³€ê²½] 1e-4ëŠ” ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. 3e-4 ~ 5e-4 ì¶”ì²œ (Effective Batchê°€ 1.5ë§Œ ì´ë¯€ë¡œ)
        betas=(0.9, 0.98), # [ê³ ê¸‰] ëŒ€ê·œëª¨ ë°°ì¹˜ì—ì„œëŠ” beta2ë¥¼ 0.999 -> 0.98ë¡œ ë‚®ì¶”ë©´ ì•ˆì •ì„±ì´ ì˜¬ë¼ê°‘ë‹ˆë‹¤.
        weight_decay=0.01, # [ë³€ê²½] 1e-4ëŠ” ë„ˆë¬´ ì‘ìŠµë‹ˆë‹¤. AdamWì˜ ê¸°ë³¸ê°’(0.01)ì´ ì¼ë°˜í™” ì„±ëŠ¥ì— ë” ì¢‹ìŠµë‹ˆë‹¤.
        eps=1e-6           # FP16(AMP) ì‚¬ìš© ì‹œ ìˆ˜ì¹˜ ì•ˆì •ì„± í™•ë³´
    )
    train_loader = DataLoader(UserTowerDataset(train_proc, is_training=True), 
                              batch_size=BATCH_SIZE, shuffle=True, 
                              collate_fn=user_tower_collate_fn)

    

    total_steps = len(train_loader) * EPOCHS 
    warmup_steps = int(total_steps * 0.1) # ì „ì²´ì˜ 10%ë¥¼ ì›œì—…

    scheduler = get_cosine_schedule_with_warmup(
        optimizer, 
        num_warmup_steps=warmup_steps, 
        num_training_steps=total_steps
    )
    scaler = torch.amp.GradScaler('cuda')
    item_probs = train_proc.get_logq_probs(DEVICE)
    best_r100 = 0.0


    
    for epoch in range(EPOCHS):
        model.train()
        total_loss = 0
        pbar = tqdm(train_loader, desc=f"Epoch {epoch+1}/{EPOCHS}")
        
        for batch in pbar:
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, _ = [x.to(DEVICE) for x in batch]
            
            # [ì¶”ê°€ 1] ê·¸ë¼ë””ì–¸íŠ¸ ì´ˆê¸°í™” (í•„ìˆ˜!)
            optimizer.zero_grad() 

            # 1. Forward
            with torch.amp.autocast('cuda'):
                user_seq_vecs = model(u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat)
                
                valid_mask = (target_ids != 0) 
                active_user_vecs = user_seq_vecs[valid_mask] 
                active_target_ids = target_ids[valid_mask]
                active_item_vecs = F.normalize(model.item_content_emb(active_target_ids), p=2, dim=1)
                
                loss = logq_correction_loss(
                    active_user_vecs, 
                    active_item_vecs, 
                    active_target_ids, 
                    item_probs, 
                    TEMPERATURE, 
                    LAMBDA_LOGQ 
                )

            scaler.scale(loss).backward()
            
            # [ê¸°ì¡´] Unscaleì€ step ì „ì— ëª…ì‹œì ìœ¼ë¡œ í•´ì£¼ëŠ” ê²Œ ì•ˆì „í•¨ (Gradient Clipping ë“±ì„ ìœ„í•´)
            scaler.unscale_(optimizer) 
            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0) # (ì„ íƒ) ì•ˆì „ì¥ì¹˜

            scaler.step(optimizer)
            scaler.update()
            
            # [ì¶”ê°€ 2] ìŠ¤ì¼€ì¤„ëŸ¬ ì—…ë°ì´íŠ¸ (ì´ê²Œ ìˆì–´ì•¼ LRì´ ì˜¤ë¦„!)
            scheduler.step() 
            
            total_loss += loss.item()
            
            # ì´ì œ lrì´ ì •ìƒì ìœ¼ë¡œ 0.00e+00 -> 1.25e-05 ... ì‹ìœ¼ë¡œ ì˜¤ë¥¼ ê²ë‹ˆë‹¤.
            pbar.set_postfix({'loss': f"{loss.item():.4f}", 'lr': f"{optimizer.param_groups[0]['lr']:.2e}"})

        avg_loss = total_loss / len(train_loader)
        logger.log(1, f"ğŸ“Š Epoch {epoch+1} Result: Avg Loss {avg_loss:.4f}")

        # ì •ê¸° í‰ê°€
        metrics = evaluate_recall_multi_k(
            model, 
            valid_proc, 
            TARGET_VAL_PATH, 
            k_list=[20, 100, 500], 
            batch_size=256
        )
        
        if metrics['R@100'] > best_r100:
            best_r100 = metrics['R@100']
            torch.save(model.state_dict(), SAVE_PATH_BEST)
            logger.log(1, f"ğŸŒŸ New Best R@100: {best_r100:.4f} - Model Saved!")




def test_dataset_train():
    logger.log(1, "ğŸš€ Phase 2.5: Emergency Fix Running...")
    
    # [ìˆ˜ì •] Scalerë¥¼ Trainì—ì„œ Validë¡œ ë„˜ê²¨ì¤Œ
    train_proc = FeatureProcessor(USER_FEAT_PATH_PQ, ITEM_FEAT_PATH_PQ, SEQ_DATA_PATH_PQ, scaler=None)
    valid_proc = FeatureProcessor(USER_VAL_FEAT_PATH, ITEM_FEAT_PATH_PQ, SEQ_VAL_DATA_PATH, scaler=train_proc.user_scaler)
    valid_proc.item2id, valid_proc.item_ids = train_proc.item2id, train_proc.item_ids
    
    num_users = len(train_proc.user_ids) + 1
    num_items = len(train_proc.item_ids) + 1
    dummy_gnn_tensor = torch.zeros((num_users, 64))
    dummy_item_tensor = torch.zeros((num_items, 128))

    model = HybridUserTower(
        num_users, 
        num_items, 
        gnn_emb_init=dummy_gnn_tensor, 
        item_emb_init=dummy_item_tensor
    ).to(DEVICE)
   
    model = load_and_align_embeddings(model, train_proc, model_dir=MODEL_DIR, device=DEVICE)
    verify_embedding_alignment(model, train_proc, model_dir=MODEL_DIR)

    model = load_and_align_gnn_items(model, train_proc, base_dir=BASE_DIR, device=DEVICE)
    verify_gnn_alignment(model, train_proc, base_dir=BASE_DIR)
    
    OVERFIT_BATCH_SIZE = 128  # ì‘ê²Œ ì„¤ì • (í™•ì‹¤í•œ ì•”ê¸° ìœ ë„)
    TEST_EPOCHS = 50          # ì¶©ë¶„íˆ ë°˜ë³µ
    TEST_LR = 1e-3            # í•™ìŠµë¥ ì„ ë†’ê²Œ ì„¤ì • (ë¹ ë¥¸ ìˆ˜ë ´)
    TEMP_TEST = 0.2           # ì˜¨ë„ë¥¼ ë†’ì—¬ì„œ ë‚œì´ë„ í•˜í–¥
        
    full_dataset = UserTowerDataset(train_proc, is_training=True)
    mini_dataset = torch.utils.data.Subset(full_dataset, range(OVERFIT_BATCH_SIZE))

    # 2. Mini Loader ìƒì„± (Shuffle ë” -> ìˆœì„œ ê³ ì •í•´ì„œ ì•”ê¸° ë•ê¸°)
    mini_loader = DataLoader(
        mini_dataset, 
        batch_size=OVERFIT_BATCH_SIZE, 
        shuffle=False, 
        collate_fn=user_tower_collate_fn
    )
    trainable_params = [n for n, p in model.named_parameters() if p.requires_grad]
    print(f"Total Trainable Params: {len(trainable_params)}")

    # User Towerì˜ í•µì‹¬ ë¶€í’ˆì´ í¬í•¨ë˜ì–´ ìˆëŠ”ì§€ í™•ì¸
    if any('seq_encoder' in n for n in trainable_params):
        print("âœ… User Tower (SeqEncoder) is Trainable")
    else:
        print("âŒ User Tower is FROZEN! (This is the bug)")

    if any('fusion_layer' in n for n in trainable_params):
        print("âœ… User Tower (Fusion) is Trainable")
    else:
        print("âŒ User Tower Fusion is FROZEN!")
    # 3. Optimizer ìƒˆë¡œ ì •ì˜ (Scheduler ì—†ì´ ë‹¨ìˆœí•˜ê²Œ)
    optimizer_test = optim.AdamW(model.parameters(), lr=TEST_LR, weight_decay=0.0) # Decay 0ìœ¼ë¡œ ì„¤ì • (ê³¼ì í•© ìœ ë„)
    scaler = torch.amp.GradScaler('cuda')
    item_probs = train_proc.get_logq_probs(DEVICE)
    # 4. Test Loop
    for epoch in range(TEST_EPOCHS):
        model.train()
        total_loss = 0
        
        # ë°°ì¹˜ëŠ” ë”± 1ë²ˆë§Œ ë”
        for batch in mini_loader:
            u_idx, u_dense, u_cat, seq_ids, seq_deltas, seq_mask, target_ids, _ = [x.to(DEVICE) for x in batch]
            
            optimizer_test.zero_grad()
            
            with torch.amp.autocast('cuda'):
                # Forward
                user_seq_vecs = model(u_idx, seq_ids, seq_deltas, seq_mask, u_dense, u_cat)
                
                # Masking & Flattening
                valid_mask = (target_ids != 0)
                active_user_vecs = user_seq_vecs[valid_mask]
                active_target_ids = target_ids[valid_mask]
                active_item_vecs = F.normalize(model.item_content_emb(active_target_ids), p=2, dim=1)
                
                # Loss Calculation (LogQ ë„ê³ , ì˜¨ë„ ë†’ì„)
                loss = logq_correction_loss(
                    active_user_vecs, 
                    active_item_vecs, 
                    active_target_ids, 
                    item_probs, 
                    temperature=TEMP_TEST, 
                    lambda_logq=0.0 
                )
            
            # Backward
            scaler.scale(loss).backward()
            scaler.step(optimizer_test)
            scaler.update()
            
            total_loss = loss.item()

        # ë¡œê·¸ ì¶œë ¥ (10 ì—í¬í¬ë§ˆë‹¤)
        if (epoch + 1) % 5 == 0:
            print(f"Epoch {epoch+1}/{TEST_EPOCHS} | Loss: {total_loss:.6f}")

    print("âœ… Test Finished.")
def check_shape_mismatch():
    print("ğŸš‘ [Emergency Check] Shape & Alignment Analysis")
    
    # 1. ì„ë² ë”© ë¡œë“œ
    try:
        vectors = torch.load(ITEM_MATRIX_PATH, map_location='cpu')
        if isinstance(vectors, dict):
            # ë§Œì•½ state_dictë¼ë©´ ê°€ì¤‘ì¹˜ ì¶”ì¶œ
            vectors = vectors.get('weight', vectors.get('item_content_emb.weight'))
        
        print(f"ğŸ“Š Embedding Matrix Shape: {vectors.shape}")
        # ì˜ˆ: torch.Size([105542, 128]) -> 10ë§Œ 5ì²œê°œ
    except Exception as e:
        print(f"âŒ Matrix Load Error: {e}")
        return

    # 2. ë©”íƒ€ë°ì´í„° ë¡œë“œ
    df = pd.read_parquet(ITEM_META_PATH)
    print(f"ğŸ“„ Metadata DataFrame Shape: {df.shape}")
    # ì˜ˆ: (50000, 25) -> 5ë§Œê°œ
    
    print(f"ğŸ“‹ Metadata Columns: {df.columns.tolist()}")

    # 3. ë¹„êµ ë¶„ì„
    n_vec = vectors.shape[0]
    n_meta = df.shape[0]
    
    print("\nâš–ï¸ [Conclusion]")
    if n_vec != n_meta:
        print(f"âŒ MISMATCH DETECTED! (Diff: {abs(n_vec - n_meta)})")
        print("ğŸ‘‰ ì„ë² ë”©ì€ {}ê°œì¸ë°, ë°ì´í„°ëŠ” {}ê°œì…ë‹ˆë‹¤.".format(n_vec, n_meta))
        print("ğŸ‘‰ ìˆœì„œê°€ ë³´ì¥ë˜ì§€ ì•Šìœ¼ë¯€ë¡œ, 'ID Mapping íŒŒì¼'ì´ ì—†ìœ¼ë©´ ì´ ì„ë² ë”©ì€ ì“¸ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    else:
        print("âœ… Counts match. (But order might still be wrong)")




# ìƒëµëœ í•¨ìˆ˜ë“¤(align, evaluate ë“±)ì€ ê¸°ì¡´ ì½”ë“œì™€ ë™ì¼í•˜ë‹¤ê³  ê°€ì •í•˜ê±°ë‚˜ ìœ„ì— ì •ì˜ëœ ê²ƒ ì‚¬ìš©
if __name__ == "__main__":
    #train_phase_2_5_warmup_finetune()
    #train_phase_2_5_fresh_start_v2()
    train_phase_2_5_emergency_fix()
     #test_dataset_train()
    #check_embedding_sanity()
     #check_shape_mismatch()