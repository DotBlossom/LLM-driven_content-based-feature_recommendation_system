            
import os
import torch
import torch.nn as nn
import numpy as np
import random
from dataclasses import dataclass
from torch.utils.data import DataLoader
from tqdm import tqdm

from v1_refine_usertower import FeatureProcessor, SASRecDataset, SASRecUserTower, dataset_peek, duorec_loss_refined, inbatch_corrected_logq_loss


# =====================================================================
# [Config] íŒŒì´í”„ë¼ì¸ ì„¤ì • 
# =====================================================================
@dataclass
class PipelineConfig:
    # Paths
    base_dir: str = r"D:\trainDataset\localprops"
    model_dir: str = r"C:\Users\candyform\Desktop\inferenceCode\models"
    
    # Hyperparameters
    batch_size: int = 896
    lr: float = 5e-5
    weight_decay: float = 1e-4
    epochs: int = 5
    
    # Model Args (SASRecUserTowerìš©)
    d_model: int = 128
    max_len: int = 50
    dropout: float = 0.3
    pretrained_dim: int = 128 # ì‚¬ì „í•™ìŠµ ì•„ì´í…œ ë²¡í„° ì°¨ì› 
    nhead: int = 4
    num_layers: int = 2
    
    # Loss Penalties
    lambda_logq: float = 0.1
    lambda_sup: float = 0.1
    lambda_cl: float = 0.1

    # ìë™ í• ë‹¹ë  ë©”íƒ€ë°ì´í„° í¬ê¸°
    num_items: int = 0
    num_prod_types: int = 0
    num_colors: int = 0
    num_graphics: int = 0
    num_sections: int = 0
    num_age_groups: int = 10

# =====================================================================
# Phase 1: Environment Setup
# =====================================================================
def setup_environment(seed: int = 42):
    """ë‚œìˆ˜ ê³ ì • ë° ë””ë°”ì´ìŠ¤ ì„¤ì • (Airflow Task ë…ë¦½ì„± ë³´ì¥)"""
    print("\nâš™ï¸ [Phase 1] Setting up environment...")
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âœ… Device set to: {device}")
    return device

# =====================================================================
# Phase 2: Data Preparation
# =====================================================================
def prepare_features(cfg: PipelineConfig):
    """FeatureProcessor ì´ˆê¸°í™” ë° ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸"""
    print("\nğŸ“Š [Phase 2] Loading Processors...")
    
    # ê²½ë¡œ ì„¤ì •
    user_path = os.path.join(cfg.base_dir, "features_user_w_meta.parquet") 
    item_path = os.path.join(cfg.base_dir, "features_item.parquet")
    seq_path = os.path.join(cfg.base_dir, "features_sequence_cleaned.parquet")
    
    
    # í‰ê°€í• ë•Œ, ì´ê±°ë¡œ val_proc ë§Œë“¤ì–´ì•¼í•¨.ê·¸ë¼ê³  valìš© useríŒŒì¼ë„ ë‹¤ì‹œ ë§Œë“¤ì–´ì•¼í•¨
    TARGET_VAL_PATH = os.path.join(cfg.base_dir, "features_target_val.parquet")
    USER_VAL_FEAT_PATH = os.path.join(cfg.base_dir, "features_user_val.parquet")
    SEQ_VAL_DATA_PATH = os.path.join(cfg.base_dir, "features_sequence_val.parquet")
    # val ê²½ë¡œ ë§Œë“¤ê¸° -> processor ì´ˆê¸°í™”ë¥¼ val_procìœ¼ë¡œ ë”°ë¡œ í•˜ê³ , returnì— ì¶”ê°€í•¨.
    # Processor ì´ˆê¸°í™” 
    processor = FeatureProcessor(user_path, item_path, seq_path)
    
    # Configì— ì„ë² ë”© ë ˆì´ì–´ ìƒì„±ì„ ìœ„í•œ ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸
    cfg.num_items = processor.num_items
    
    ####### ì‹¤ì œ item metadata idë‘ ë¬¶ì¸ìƒíƒœë¡œ ê°€ì ¸ì™€ì•¼í•˜ê³  ì—°ê²° í•„ìš” #######

    cfg.num_prod_types = int(processor.items['type_id'].max()) if 'type_id' in processor.items else 50
    cfg.num_colors = int(processor.items['color_id'].max()) if 'color_id' in processor.items else 50
    cfg.num_graphics = int(processor.items['graphic_id'].max()) if 'graphic_id' in processor.items else 50
    cfg.num_sections = int(processor.items['section_id'].max()) if 'section_id' in processor.items else 50

    print(f"âœ… Features Loaded. Total Items: {cfg.num_items}")
    return processor, cfg

# =====================================================================
# Phase 3: Embedding Alignment & DataLoader
# =====================================================================
def load_aligned_pretrained_embeddings(processor, model_dir, pretrained_dim):
    """Datasetì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì •ë ¬ëœ ì‚¬ì „í•™ìŠµ ë²¡í„°(N+1, Dim) ìƒì„±"""
    print(f"\nğŸ”„ [Phase 3-1] Aligning Pretrained Item Embeddings...")
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")

    num_embeddings = processor.num_items + 1 
    aligned_weight = torch.randn(num_embeddings, pretrained_dim) * 0.01 
    aligned_weight[0] = 0.0 # Padding
    
    try:
        pretrained_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(pretrained_emb, dict):
            pretrained_emb = pretrained_emb.get('weight', pretrained_emb.get('item_content_emb.weight'))
        pretrained_ids = torch.load(ids_path, map_location='cpu')
        
        pretrained_map = {str(iid.item()) if isinstance(iid, torch.Tensor) else str(iid): pretrained_emb[idx] 
                          for idx, iid in enumerate(pretrained_ids)}
        
        matched = 0
        for i, current_id_str in enumerate(processor.item_ids):
            if current_id_str in pretrained_map:
                aligned_weight[i + 1] = pretrained_map[current_id_str]
                matched += 1
                
        print(f"âœ… Matched: {matched}/{len(processor.item_ids)}")
    except Exception as e:
        print(f"âš ï¸ [Warning] Failed to load Pretrained files: {e}. Using random init.")
        
    return aligned_weight

def create_dataloaders(processor, cfg: PipelineConfig, aligned_pretrained_vecs=None):
    """Dataset ë° DataLoader ì¸ìŠ¤í„´ìŠ¤í™”"""
    print("\nğŸ“¦ [Phase 3-2] Creating DataLoaders...")
    
    # SASRecDataset ë‚´ë¶€ì—ì„œ aligned_pretrained_vecsë¥¼ ì°¸ì¡°í•˜ê²Œë” 
    
    train_dataset = SASRecDataset(processor, max_len=cfg.max_len, is_train=True)
    
    # Dataset ì¸ìŠ¤í„´ìŠ¤ì— ì •ë ¬ëœ pretrained vector ë£©ì—… í…Œì´ë¸” ì£¼ì… (ë™ì  ë°”ì¸ë”©)
    train_dataset.pretrained_lookup = aligned_pretrained_vecs 
    
    train_loader = DataLoader(
        train_dataset, 
        batch_size=cfg.batch_size, 
        shuffle=True, 
        num_workers=0, 
        pin_memory=True,
        drop_last=True
    )
    
    print(f"âœ… Train Loader Ready: {len(train_loader)} batches/epoch")
    return train_loader


import hashlib
import json

def get_hash_id(text, hash_size):
    """ë¬¸ìì—´ì„ ì¼ê´€ëœ ì •ìˆ˜ ID(1 ~ hash_size)ë¡œ í•´ì‹± (0ì€ Padding)"""
    if not text or str(text).lower() in ['unknown', 'nan', 'none']:
        return 0
    # MD5ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì´ì¬ ì„¸ì…˜ì´ ë°”ë€Œì–´ë„ í•­ìƒ ë™ì¼í•œ í•´ì‹œê°’ ë³´ì¥
    hash_obj = hashlib.md5(str(text).strip().lower().encode('utf-8'))
    # 16ì§„ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ hash_sizeë¡œ ë‚˜ëˆˆ ë‚˜ë¨¸ì§€ + 1
    return (int(hash_obj.hexdigest(), 16) % hash_size) + 1

def load_item_metadata_hashed(processor, base_dir, hash_size=1000):
    """JSON íŒŒì¼ì„ ì½ì–´ ì •ë ¬ëœ ë©”íƒ€ë°ì´í„° í•´ì‹œ í…ì„œ(N+1, 4)ë¥¼ ìƒì„±"""
    print("\nğŸ·ï¸ [Phase 3-2] Loading and Hashing Item Metadata...")
    json_path = os.path.join(base_dir, "filtered_data_reinforced.json")
    
    num_items = processor.num_items + 1
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” íŒ¨ë”©ì„ ìœ„í•´ 0ìœ¼ë¡œ ìœ ì§€ (N+1, 4ì°¨ì› ë°°ì—´)
    item_side_arr = np.zeros((num_items, 4), dtype=np.int64)
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            item_data = json.load(f)
    except Exception as e:
        print(f"âŒ [Error] Failed to load JSON: {e}")
        return torch.tensor(item_side_arr, dtype=torch.long)
    
    # ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´ O(1) Lookup Dictionary ìƒì„±
    # intí˜• article_idë¥¼ stringìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë§¤í•‘
    metadata_dict = {str(item.get('article_id', '')): item for item in item_data}
    
    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        idx = i + 1 # 1-based indexing
        
        if current_id_str in metadata_dict:
            meta = metadata_dict[current_id_str]
            
            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë° í•´ì‹± (í•´ë‹¹ í‚¤ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜)
            type_val = meta.get("product_type_name", "")
            color_val = meta.get("colour_group_name", "")
            graphic_val = meta.get("graphical_appearance_name", "")
            section_val = meta.get("section_name", "")
            
            item_side_arr[idx, 0] = get_hash_id(type_val, hash_size)
            item_side_arr[idx, 1] = get_hash_id(color_val, hash_size)
            item_side_arr[idx, 2] = get_hash_id(graphic_val, hash_size)
            item_side_arr[idx, 3] = get_hash_id(section_val, hash_size)
            
            matched += 1

    print(f"âœ… Metadata Matched & Hashed: {matched}/{len(processor.item_ids)} (Hash Size: {hash_size})")
    
    return torch.tensor(item_side_arr, dtype=torch.long)
# =====================================================================
# Phase 4: Model Setup
# =====================================================================
class DummyItemTower(nn.Module):
    """ì‹¤í–‰ í…ŒìŠ¤íŠ¸ìš© ë”ë¯¸ ì•„ì´í…œ íƒ€ì›Œ"""
    def __init__(self, num_items, dim):
        super().__init__()
        self.emb = nn.Embedding(num_items + 1, dim)
        self.log_q = nn.Parameter(torch.zeros(num_items + 1), requires_grad=False)
    def get_all_embeddings(self): return self.emb.weight
    def get_log_q(self): return self.log_q

def setup_models(cfg: PipelineConfig, device):
    """User Tower ì´ˆê¸°"""
    print("\nğŸ§  [Phase 4] Initializing Models...")
    
    user_tower = SASRecUserTower(cfg).to(device)
    


    print("âœ… Models initialized and moved to device.")
    return user_tower

# =====================================================================
# Phase 5: Training Loop (1 Epoch Runner)
# =====================================================================
def train_one_epoch(epoch, model, full_item_embeddings, log_q_tensor, dataloader, optimizer, scaler, cfg, device):
    """ë‹¨ì¼ ì—í¬í¬ í›ˆë ¨ í•¨ìˆ˜ (ì‹¤ì œ Loss ê³„ì‚° ë° ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì ìš©)"""
    model.train()
    total_loss_accum = 0.0
    main_loss_accum = 0.0
    cl_loss_accum = 0.0
    
        
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}", leave=False)
    for batch_idx, batch in enumerate(pbar):
        optimizer.zero_grad()

        # -------------------------------------------------------
        # 1. Data Unpacking (Dictionary to Device)
        # -------------------------------------------------------
        item_ids = batch['item_ids'].to(device)
        target_ids = batch['target_ids'].to(device)
        padding_mask = batch['padding_mask'].to(device)
        time_bucket_ids = batch['time_bucket_ids'].to(device)
        
        type_ids = batch['type_ids'].to(device)
        color_ids = batch['color_ids'].to(device)
        graphic_ids = batch['graphic_ids'].to(device)
        section_ids = batch['section_ids'].to(device)
        
        age_bucket = batch['age_bucket'].to(device)
        price_bucket = batch['price_bucket'].to(device)
        cnt_bucket = batch['cnt_bucket'].to(device)
        recency_bucket = batch['recency_bucket'].to(device)
        
        channel_ids = batch['channel_ids'].to(device)
        club_status_ids = batch['club_status_ids'].to(device)
        news_freq_ids = batch['news_freq_ids'].to(device)
        fn_ids = batch['fn_ids'].to(device)
        active_ids = batch['active_ids'].to(device)
        
        cont_feats = batch['cont_feats'].to(device)
        
        # Pretrained Vector ë£©ì—… ì²˜ë¦¬
        if 'pretrained_vecs' in batch:
            pretrained_vecs = batch['pretrained_vecs'].to(device)
        else:
            pretrained_vecs = dataloader.dataset.pretrained_lookup[item_ids.cpu()].to(device)
            
        forward_kwargs = {
            'pretrained_vecs': pretrained_vecs,
            'item_ids': item_ids,
            'time_bucket_ids': time_bucket_ids,
            'type_ids': type_ids,
            'color_ids': color_ids,
            'graphic_ids': graphic_ids,
            'section_ids': section_ids,
            'age_bucket': age_bucket,
            'price_bucket': price_bucket,
            'cnt_bucket': cnt_bucket,
            'recency_bucket': recency_bucket,
            'channel_ids': channel_ids,
            'club_status_ids': club_status_ids,
            'news_freq_ids': news_freq_ids,
            'fn_ids': fn_ids,
            'active_ids': active_ids,
            'cont_feats': cont_feats,
            'padding_mask': padding_mask,
            'training_mode': True
        }

        # =======================================================
        # [ëª¨ë‹ˆí„°ë§ ë¡œê·¸] ì²« ë°°ì¹˜ì—ì„œë§Œ ë°ì´í„° ìƒíƒœ ì ê²€
        # =======================================================
        if batch_idx == 0:
            print(f"\nğŸ“¦ [Batch 0 Monitor]")
            print(f"   - Item IDs: Shape {item_ids.shape} | Min {item_ids.min()} | Max {item_ids.max()}")
            print(f"   - Time Buckets: Min {time_bucket_ids.min()} | Max {time_bucket_ids.max()}")
            pad_ratio = (padding_mask.sum().item() / padding_mask.numel()) * 100
            print(f"   - Padding Ratio: {pad_ratio:.1f}%")
            print(f"   - Cont Feats Mean: {cont_feats.mean().item():.3f} | Std: {cont_feats.std().item():.3f}")
            
            print("\nğŸ¯ [First User Data State Check]")
            print("-" * 50)
            print(f"ğŸ‘¤ [User Profile]")
            print(f"   - Age Bucket ID:    {age_bucket[0].item()} (Target Age Group)")
            print(f"   - Price Bucket ID:  {price_bucket[0].item()} (Spending Power)")
            print(f"   - News Freq ID:     {news_freq_ids[0].item()} (Marketing Sensitivity)")
            
            valid_indices = torch.where(~padding_mask[0])[0]
            if len(valid_indices) > 0:
                print(f"\nğŸ›ï¸ [Item History - Last 3 Items]")
                sample_indices = valid_indices[-3:] 
                sample_types = type_ids[0][sample_indices].tolist()
                sample_times = time_bucket_ids[0][sample_indices].tolist()
                for i, (t_id, time_id) in enumerate(zip(sample_types, sample_times)):
                    print(f"   - Item {i+1}: Type Hash ID [{t_id}] | Time Bucket ID [{time_id}]")
            else:
                print("\nâš ï¸ [Warning] This user has NO valid sequence (All Padded).")
            print("-" * 50)

        # -------------------------------------------------------
        # 2. Forward & Real Loss Calculation (AMP)
        # -------------------------------------------------------
        with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
            # A. First View
            output_1 = model(**forward_kwargs)
            # B. Second View (Dropout ë§ˆìŠ¤í¬ê°€ ë‹¬ë¼ì§)
            output_2 = model(**forward_kwargs)

            # (1) Main Loss (All Time Steps)
            valid_mask = ~padding_mask.view(-1)
            flat_output = output_1.view(-1, cfg.d_model)[valid_mask]
            flat_targets = target_ids.view(-1)[valid_mask]
            
            

            main_loss = inbatch_corrected_logq_loss(
                user_emb=flat_output,
                item_tower_emb=full_item_embeddings,
                target_ids=flat_targets,
                log_q_tensor=log_q_tensor,
                lambda_logq=cfg.lambda_logq
            )
            
            # (2) DuoRec Loss (Last Time Step Only)
            last_output_1 = output_1[:, -1, :] 
            last_output_2 = output_2[:, -1, :]
            last_targets = target_ids[:, -1]

            cl_loss = duorec_loss_refined(
                user_emb_1=last_output_1,
                user_emb_2=last_output_2,
                target_ids=last_targets,
                lambda_sup=cfg.lambda_sup
            )

            # ìµœì¢… Loss ì¡°í•©
            total_loss = main_loss + (cfg.lambda_cl * cl_loss)

        # -------------------------------------------------------
        # 3. Backward & Optimizer Step
        # -------------------------------------------------------
        scaler.scale(total_loss).backward()
        scaler.unscale_(optimizer)
        # ê¸°ìš¸ê¸° í­ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™” (5.0ì€ íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ë§ì´ ì“°ì´ëŠ” ì—¬ìœ ìˆëŠ” ê°’)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
        scaler.step(optimizer)
        scaler.update()

        # ëˆ„ì 
        total_loss_accum += total_loss.item()
        main_loss_accum += main_loss.item()
        cl_loss_accum += cl_loss.item()
        
        pbar.set_postfix({
            'Loss': f"{total_loss.item():.4f}",
            'Main': f"{main_loss.item():.4f}",
            'CL': f"{cl_loss.item():.4f}"
        })
        
        # 100ë°°ì¹˜ë§ˆë‹¤ ë¡œê¹…
        if batch_idx % 100 == 0:
            print(f"   [Epoch {epoch}] Batch {batch_idx:04d}/{len(dataloader)} | Total Loss: {total_loss.item():.4f} (Main: {main_loss.item():.4f}, CL: {cl_loss.item():.4f})")

    avg_loss = total_loss_accum / len(dataloader)
    avg_main = main_loss_accum / len(dataloader)
    avg_cl = cl_loss_accum / len(dataloader)
    
    print(f"ğŸ Epoch {epoch} Completed | Avg Total: {avg_loss:.4f} (Main: {avg_main:.4f}, CL: {avg_cl:.4f})")
    return avg_loss
# =====================================================================
# Main Execution Pipeline
# =====================================================================
def run_pipeline():
    """Airflow DAGë‚˜ MLflow Runì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    print("ğŸš€ Starting User Tower Training Pipeline...")
    
    
    
    
    
    # 1. Config & Env
    cfg = PipelineConfig()
    device = setup_environment()
    processor, cfg = prepare_features(cfg)
    # item metadata cfg
    HASH_SIZE = 1000
    cfg.num_prod_types = HASH_SIZE
    cfg.num_colors = HASH_SIZE
    cfg.num_graphics = HASH_SIZE
    cfg.num_sections = HASH_SIZE
    
    # 2. Data

    aligned_vecs = load_aligned_pretrained_embeddings(processor, cfg.model_dir, cfg.pretrained_dim)
    
    full_item_embeddings = aligned_vecs.to(device)
    log_q_tensor = processor.get_logq_probs(device)
    
    
    item_metadata_tensor = load_item_metadata_hashed(processor, cfg.base_dir, hash_size=HASH_SIZE)
    processor.i_side_arr = item_metadata_tensor.numpy()
    train_loader = create_dataloaders(processor, cfg, aligned_vecs)
    dataset_peek(train_loader.dataset, processor)
    
    # 3. Models & Optimizer
    user_tower = setup_models(cfg, device)
    optimizer = torch.optim.AdamW(user_tower.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))
    
    # 4. Training Loop (Phase 5)
    # mlflow.start_run() ë¸”ë¡ìš©
    for epoch in range(1, cfg.epochs + 1):
        avg_loss = train_one_epoch(
            epoch=epoch,
            model=user_tower,
            full_item_embeddings=full_item_embeddings,
            log_q_tensor=log_q_tensor,

            dataloader=train_loader,
            optimizer=optimizer,
            scaler=scaler,
            cfg=cfg,
            device=device
        )
        # mlflow.log_metric("train_loss", avg_loss, step=epoch)
        
    print("ğŸ‰ Pipeline Execution Finished Successfully!")

if __name__ == "__main__":
    run_pipeline()