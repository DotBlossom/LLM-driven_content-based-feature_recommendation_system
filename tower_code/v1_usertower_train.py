            
import os
import pandas as pd
import torch
import torch.nn as nn
import numpy as np
import torch.nn.functional as F
import random
from dataclasses import dataclass
from torch.utils.data import DataLoader
from tqdm import tqdm
import pickle

import wandb
from v1_refine_usertower import FeatureProcessor, SASRecDataset, SASRecUserTower, dataset_peek, duorec_loss_refined, full_batch_hard_emphasis_loss, inbatch_corrected_logq_loss, inbatch_hnm_corrected_loss_with_stats,inbatch_mixed_hnm_loss_with_stats


# =====================================================================
# [Config] íŒŒì´í”„ë¼ì¸ ì„¤ì • 
# =====================================================================
@dataclass
class PipelineConfig:
    # Paths
    base_dir: str = r"D:\trainDataset\localprops"
    model_dir: str = r"C:\Users\candyform\Desktop\inferenceCode\models"
    
    # Hyperparameters
    batch_size: int = 768
    lr: float = 5e-4
    weight_decay: float = 1e-4
    epochs: int = 15
    
    # Model Args (SASRecUserTowerìš©)
    d_model: int = 128
    max_len: int = 50
    dropout: float = 0.2
    pretrained_dim: int = 128 # ì‚¬ì „í•™ìŠµ ì•„ì´í…œ ë²¡í„° ì°¨ì› 
    nhead: int = 4
    num_layers: int = 2
    
    # Loss Penalties
    lambda_logq: float = 1.0
    lambda_sup: float = 0.1
    lambda_cl: float = 0.2
   
    # [ì‹ ê·œ] HNM ì œì–´ íŒŒë¼ë¯¸í„°
    top_k_percent: float = 0.01 # ìƒìœ„ 15% í•˜ë“œ ë„¤ê±°í‹°ë¸Œ ì‚¬ìš© (10~20% ì‚¬ì´ ê¶Œì¥)
    hnm_threshold: float = 0.90
    hard_margin: float = 0.01

    # model ê´€ë¦¬
    freeze_item_tower: bool = True
    item_tower_pth_name: str = "encoder_ep03_loss0.8129.pth"
    # ìë™ í• ë‹¹ë  ë©”íƒ€ë°ì´í„° í¬ê¸°
    num_items: int = 0
    num_prod_types: int = 0
    num_colors: int = 0
    num_graphics: int = 0
    num_sections: int = 0
    num_age_groups: int = 10

# =====================================================================
# Phase 1: Environment Setup
# =====================================================================
def setup_environment(seed: int = 42):
    """ë‚œìˆ˜ ê³ ì • ë° ë””ë°”ì´ìŠ¤ ì„¤ì • (Airflow Task ë…ë¦½ì„± ë³´ì¥)"""
    print("\nâš™ï¸ [Phase 1] Setting up environment...")
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed_all(seed)
        
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"âœ… Device set to: {device}")
    return device

# =====================================================================
# Phase 2: Data Preparation
# =====================================================================
def prepare_features(cfg: PipelineConfig):
    """FeatureProcessor ì´ˆê¸°í™” ë° ë©”íƒ€ë°ì´í„° ì—…ë°ì´íŠ¸ (ë¡œì»¬ ìºì‹± ì ìš©)"""
    print("\nğŸ“Š [Phase 2] Loading Processors...")
    
    # 1. ìºì‹œ íŒŒì¼ ê²½ë¡œ ì„¤ì •
    cache_path = os.path.join(cfg.base_dir, "processor_cache.pkl")
    
    # 2. ìºì‹œ ì¡´ì¬ ì—¬ë¶€ í™•ì¸ ë° ë¡œë“œ
    if os.path.exists(cache_path):
        print(f"   âœ… [Cache Hit] Found cached processors at {cache_path}")
        print("   â³ Loading from local storage...")
        with open(cache_path, 'rb') as f:
            train_proc, val_proc = pickle.load(f)
            
    # 3. ìºì‹œê°€ ì—†ì„ ê²½ìš°: ì›ë³¸ íŒŒë¼ì¼“ ë¡œë“œ ë° ìƒì„±
    else:
        print("   âš ï¸ [Cache Miss] Cache not found. Processing from Parquet files...")
        
        # ê²½ë¡œ ì„¤ì •
        user_path = os.path.join(cfg.base_dir, "features_user_w_meta.parquet") 
        item_path = os.path.join(cfg.base_dir, "features_item.parquet")
        seq_path = os.path.join(cfg.base_dir, "features_sequence_cleaned.parquet")
        
        TARGET_VAL_PATH = os.path.join(cfg.base_dir, "features_target_val.parquet")
        USER_VAL_FEAT_PATH = os.path.join(cfg.base_dir, "features_user_w_meta_val.parquet")
        SEQ_VAL_DATA_PATH = os.path.join(cfg.base_dir, "features_sequence_val.parquet")
        
        # Processor ì´ˆê¸°í™” 
        train_proc = FeatureProcessor(user_path, item_path, seq_path)
        val_proc = FeatureProcessor(USER_VAL_FEAT_PATH, item_path, SEQ_VAL_DATA_PATH, base_processor=train_proc)
        
        # [ì‹ ê·œ] ìƒì„±ëœ Processor ê°ì²´ë¥¼ ë¡œì»¬ íŒŒì¼ë¡œ ì €ì¥ (HIGHEST_PROTOCOLë¡œ ì†ë„/ìš©ëŸ‰ ìµœì í™”)
        print("   ğŸ’¾ Saving processors to local cache for future use...")
        with open(cache_path, 'wb') as f:
            pickle.dump((train_proc, val_proc), f, protocol=pickle.HIGHEST_PROTOCOL)

    # 4. Config ì—…ë°ì´íŠ¸ (ìºì‹œì—ì„œ ë¶ˆëŸ¬ì™”ë“  ìƒˆë¡œ ë§Œë“¤ì—ˆë“  ë™ì¼í•˜ê²Œ ì ìš©)
    cfg.num_items = train_proc.num_items
    
    ####### ì‹¤ì œ item metadata idë‘ ë¬¶ì¸ìƒíƒœë¡œ ê°€ì ¸ì™€ì•¼í•˜ê³  ì—°ê²° í•„ìš” #######
    cfg.num_prod_types = int(train_proc.items['type_id'].max()) if 'type_id' in train_proc.items else 50
    cfg.num_colors = int(train_proc.items['color_id'].max()) if 'color_id' in train_proc.items else 50
    cfg.num_graphics = int(train_proc.items['graphic_id'].max()) if 'graphic_id' in train_proc.items else 50
    cfg.num_sections = int(train_proc.items['section_id'].max()) if 'section_id' in train_proc.items else 50

    print(f"âœ… Features Loaded. Total Items: {cfg.num_items}")
    return train_proc, val_proc, cfg
# =====================================================================
# Phase 3: Embedding Alignment & DataLoader
# =====================================================================
def load_aligned_pretrained_embeddings(processor, model_dir, pretrained_dim):
    """Datasetì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆë„ë¡ ì •ë ¬ëœ ì‚¬ì „í•™ìŠµ ë²¡í„°(N+1, Dim) ìƒì„±"""
    print(f"\nğŸ”„ [Phase 3-1] Aligning Pretrained Item Embeddings...")
    emb_path = os.path.join(model_dir, "pretrained_item_matrix.pt")
    ids_path = os.path.join(model_dir, "item_ids.pt")

    num_embeddings = processor.num_items + 1 
    aligned_weight = torch.randn(num_embeddings, pretrained_dim) * 0.01 
    aligned_weight[0] = 0.0 # Padding
    
    try:
        pretrained_emb = torch.load(emb_path, map_location='cpu')
        if isinstance(pretrained_emb, dict):
            pretrained_emb = pretrained_emb.get('weight', pretrained_emb.get('item_content_emb.weight'))
        pretrained_ids = torch.load(ids_path, map_location='cpu')
        
        pretrained_map = {str(iid.item()) if isinstance(iid, torch.Tensor) else str(iid): pretrained_emb[idx] 
                          for idx, iid in enumerate(pretrained_ids)}
        
        matched = 0
        for i, current_id_str in enumerate(processor.item_ids):
            if current_id_str in pretrained_map:
                aligned_weight[i + 1] = pretrained_map[current_id_str]
                matched += 1
                
        print(f"âœ… Matched: {matched}/{len(processor.item_ids)}")
    except Exception as e:
        print(f"âš ï¸ [Warning] Failed to load Pretrained files: {e}. Using random init.")
        
    return aligned_weight

def create_dataloaders(processor, cfg: PipelineConfig, aligned_pretrained_vecs=None, is_train=True):
    """Dataset ë° DataLoader ì¸ìŠ¤í„´ìŠ¤í™”"""
    mode_str = "Train" if is_train else "Validation"
    print(f"\nğŸ“¦ [Phase 3-2] Creating {mode_str} DataLoaders...")
    
    # ğŸ’¡ 1. is_train íŒŒë¼ë¯¸í„° ì „ë‹¬
    dataset = SASRecDataset(processor, max_len=cfg.max_len, is_train=is_train)
    
    # Dataset ì¸ìŠ¤í„´ìŠ¤ì— ì •ë ¬ëœ pretrained vector ë£©ì—… í…Œì´ë¸” ì£¼ì…
    dataset.pretrained_lookup = aligned_pretrained_vecs 
    
    loader = DataLoader(
        dataset, 
        batch_size=cfg.batch_size, 
        # ğŸ’¡ 2. ê²€ì¦ ì‹œì—ëŠ” ì…”í”Œì„ ë„ê³ , ìíˆ¬ë¦¬ ë°ì´í„°(ë§ˆì§€ë§‰ ë°°ì¹˜)ë„ ë²„ë¦¬ì§€ ì•Šê³  ëª¨ë‘ í‰ê°€
        shuffle=is_train, 
        num_workers=0, 
        pin_memory=True,
        drop_last=is_train 
    )
    
    print(f"âœ… {mode_str} Loader Ready: {len(loader)} batches/epoch")
    return loader

def load_item_tower_state_dict(model_dir: str, pth_filename: str, device):
    """
    [Data/IO] ë¬¼ë¦¬ì  íŒŒì¼(.pth)ì„ ì½ì–´ ë©”ëª¨ë¦¬(state_dict)ë¡œ ì˜¬ë¦¬ëŠ” ìˆœìˆ˜ IO ì—­í• .
    ëª¨ë¸ êµ¬ì¡°ë‚˜ í•™ìŠµ ìƒíƒœ(Freeze ì—¬ë¶€)ì—ëŠ” ì ˆëŒ€ ê´€ì—¬í•˜ì§€ ì•ŠìŒ.
    """
    file_path = os.path.join(model_dir, pth_filename)
    
    if not os.path.exists(file_path):
        print(f"âš ï¸ [IO Warning] Item Tower file not found: {file_path}")
        print("   -> Random initialization will be used.")
        return None
        
    print(f"ğŸ“¥ [IO] Loading Item Tower weights from {pth_filename}...")
    
    try:
        # map_locationì„ í†µí•´ CPU/GPU ë©”ëª¨ë¦¬ ë§¤í•‘ ìµœì í™”
        state_dict = torch.load(file_path, map_location=device)
        return state_dict
    except Exception as e:
        print(f"âŒ [IO Error] Failed to load .pth file: {e}")
        return None
    
import hashlib
import json

def get_hash_id(text, hash_size):
    """ë¬¸ìì—´ì„ ì¼ê´€ëœ ì •ìˆ˜ ID(1 ~ hash_size)ë¡œ í•´ì‹± (0ì€ Padding)"""
    if not text or str(text).lower() in ['unknown', 'nan', 'none']:
        return 0
    # MD5ë¥¼ ì‚¬ìš©í•˜ì—¬ íŒŒì´ì¬ ì„¸ì…˜ì´ ë°”ë€Œì–´ë„ í•­ìƒ ë™ì¼í•œ í•´ì‹œê°’ ë³´ì¥
    hash_obj = hashlib.md5(str(text).strip().lower().encode('utf-8'))
    # 16ì§„ìˆ˜ë¥¼ ì •ìˆ˜ë¡œ ë³€í™˜ í›„ hash_sizeë¡œ ë‚˜ëˆˆ ë‚˜ë¨¸ì§€ + 1
    return (int(hash_obj.hexdigest(), 16) % hash_size) + 1

def load_item_metadata_hashed(processor, base_dir, hash_size=1000):
    """JSON íŒŒì¼ì„ ì½ì–´ ì •ë ¬ëœ ë©”íƒ€ë°ì´í„° í•´ì‹œ í…ì„œ(N+1, 4)ë¥¼ ìƒì„±"""
    print("\nğŸ·ï¸ [Phase 3-2] Loading and Hashing Item Metadata...")
    json_path = os.path.join(base_dir, "filtered_data_reinforced.json")
    
    num_items = processor.num_items + 1
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” íŒ¨ë”©ì„ ìœ„í•´ 0ìœ¼ë¡œ ìœ ì§€ (N+1, 4ì°¨ì› ë°°ì—´)
    item_side_arr = np.zeros((num_items, 4), dtype=np.int64)
    
    try:
        with open(json_path, 'r', encoding='utf-8') as f:
            item_data = json.load(f)
    except Exception as e:
        print(f"âŒ [Error] Failed to load JSON: {e}")
        return torch.tensor(item_side_arr, dtype=torch.long)
    
    # ë¹ ë¥¸ ê²€ìƒ‰ì„ ìœ„í•´ O(1) Lookup Dictionary ìƒì„±
    # intí˜• article_idë¥¼ stringìœ¼ë¡œ ë³€í™˜í•˜ì—¬ ë§¤í•‘
    metadata_dict = {str(item.get('article_id', '')): item for item in item_data}
    
    matched = 0
    for i, current_id_str in enumerate(processor.item_ids):
        idx = i + 1 # 1-based indexing
        
        if current_id_str in metadata_dict:
            meta = metadata_dict[current_id_str]
            
            # ì¹´í…Œê³ ë¦¬ ë§¤í•‘ ë° í•´ì‹± (í•´ë‹¹ í‚¤ê°€ ì—†ìœ¼ë©´ ë¹ˆ ë¬¸ìì—´ ë°˜í™˜)
            type_val = meta.get("product_type_name", "")
            color_val = meta.get("colour_group_name", "")
            graphic_val = meta.get("graphical_appearance_name", "")
            section_val = meta.get("section_name", "")
            
            item_side_arr[idx, 0] = get_hash_id(type_val, hash_size)
            item_side_arr[idx, 1] = get_hash_id(color_val, hash_size)
            item_side_arr[idx, 2] = get_hash_id(graphic_val, hash_size)
            item_side_arr[idx, 3] = get_hash_id(section_val, hash_size)
            
            matched += 1

    print(f"âœ… Metadata Matched & Hashed: {matched}/{len(processor.item_ids)} (Hash Size: {hash_size})")
    
    return torch.tensor(item_side_arr, dtype=torch.long)
# =====================================================================
# Phase 4: Model Setup
# =====================================================================
class SASRecItemTower(nn.Module):
    def __init__(self, num_items, d_model, log_q_tensor=None):
        super().__init__()
        
        # ğŸ’¡ ë‹¨ìˆœíˆ ì„ë² ë”©ì´ë¼ê¸°ë³´ë‹¤ 'ë¯¸ì„¸ì¡°ì • ê°€ëŠ¥í•œ ì•„ì´í…œ ë²¡í„° í–‰ë ¬'ì„ì„ ëª…ì‹œ
        self.item_matrix = nn.Embedding(num_items + 1, d_model, padding_idx=0)
        
        if log_q_tensor is not None:
            self.register_buffer('log_q', log_q_tensor)
        else:
            self.register_buffer('log_q', torch.zeros(num_items + 1))

    def get_all_embeddings(self):
        return self.item_matrix.weight

    def get_log_q(self):
        return self.log_q
        
    def set_freeze_state(self, freeze: bool):
        for param in self.parameters():
            param.requires_grad = not freeze
            
    # ğŸ’¡ [í•µì‹¬] ë°–ì—ì„œ ì–µì§€ë¡œ ì‘¤ì…”ë„£ì§€ ì•Šê³ , í´ë˜ìŠ¤ ìŠ¤ìŠ¤ë¡œ ì¶”ë¡  ë²¡í„°ë¥¼ ë°›ì•„ ì´ˆê¸°í™”í•˜ëŠ” ë©”ì„œë“œ
    def init_from_pretrained(self, pretrained_vecs):
        """ì¶”ë¡ ëœ ì‚¬ì „í•™ìŠµ ë²¡í„°ë¥¼ ë¯¸ì„¸ì¡°ì • ê°€ëŠ¥í•œ íŒŒë¼ë¯¸í„°(Weight)ë¡œ ì´ˆê¸°í™”"""
        with torch.no_grad():
            self.item_matrix.weight.copy_(pretrained_vecs)
        print("âœ… Pretrained item vectors successfully loaded into learnable matrix!")
    
def setup_models(cfg: PipelineConfig, device, item_state_dict=None, log_q_tensor=None):
    print(f"\nğŸ§  [Phase 4] Initializing Models...")
    
    # 1. User Tower ìƒì„±
    user_tower = SASRecUserTower(cfg).to(device)
    
    # 2. Item Tower ë¼ˆëŒ€ ìƒì„±
    item_tower = SASRecItemTower(
        num_items=cfg.num_items, 
        d_model=cfg.d_model, 
        log_q_tensor=log_q_tensor
    ).to(device)
    
    # 3. Data ì£¼ì… (IO ë°ì´í„° -> Architecture)
    if item_state_dict is not None:
        try:
            # strict=False ì˜µì…˜: ì €ì¥ëœ ëª¨ë¸ê³¼ í˜„ì¬ êµ¬ì¡°ì˜ í‚¤ ì´ë¦„ì´ ì¡°ê¸ˆ ë‹¬ë¼ë„ ìœ ì—°í•˜ê²Œ ë¡œë“œ
            missing, unexpected = item_tower.load_state_dict(item_state_dict, strict=False)
            print(f"âœ… Item Tower weights successfully loaded!")
            if unexpected:
                print(f"   - Ignored extra keys from .pth: {unexpected[:3]}...")
            if missing:
                print(f"   âš ï¸ [CRITICAL WARNING] Missing keys: {missing}")
        except Exception as e:
            print(f"âŒ [Error] Weight injection failed: {e}")

    # 4. í•™ìŠµ ìƒíƒœ(Freeze/Unfreeze) í†µì œ ì ìš©
    item_tower.set_freeze_state(cfg.freeze_item_tower)
    
    # ì§ê´€ì ì¸ ë¡œê¹…
    mode_str = "FROZEN â„ï¸ (Speed Optimized)" if cfg.freeze_item_tower else "UNFROZEN ğŸ”¥ (Joint Fine-tuning)"
    print(f"âœ… Item Tower State: {mode_str}")
    
    return user_tower, item_tower

# =====================================================================
# Phase 5: Training Loop 
# =====================================================================
def train_user_tower(epoch, model, item_tower, log_q_tensor, dataloader, optimizer, scaler, cfg, device, seq_labels, static_labels):
    """ë‹¨ì¼ ì—í¬í¬ í›ˆë ¨ í•¨ìˆ˜ (ì‹¤ì œ Loss ê³„ì‚° ë° ë¡œê·¸ ëª¨ë‹ˆí„°ë§ ì ìš©)"""
    model.train()
    total_loss_accum = 0.0
    main_loss_accum = 0.0
    cl_loss_accum = 0.0
    
        
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}", leave=False)
    for batch_idx, batch in enumerate(pbar):
        optimizer.zero_grad()

        # -------------------------------------------------------
        # 1. Data Unpacking (Dictionary to Device)
        # -------------------------------------------------------
        item_ids = batch['item_ids'].to(device)
        target_ids = batch['target_ids'].to(device)
        padding_mask = batch['padding_mask'].to(device)
        time_bucket_ids = batch['time_bucket_ids'].to(device)
        
        type_ids = batch['type_ids'].to(device)
        color_ids = batch['color_ids'].to(device)
        graphic_ids = batch['graphic_ids'].to(device)
        section_ids = batch['section_ids'].to(device)
        
        age_bucket = batch['age_bucket'].to(device)
        price_bucket = batch['price_bucket'].to(device)
        cnt_bucket = batch['cnt_bucket'].to(device)
        recency_bucket = batch['recency_bucket'].to(device)
        
        channel_ids = batch['channel_ids'].to(device)
        club_status_ids = batch['club_status_ids'].to(device)
        news_freq_ids = batch['news_freq_ids'].to(device)
        fn_ids = batch['fn_ids'].to(device)
        active_ids = batch['active_ids'].to(device)
        
        cont_feats = batch['cont_feats'].to(device)
        
        # Pretrained Vector ë£©ì—… ì²˜ë¦¬
        if 'pretrained_vecs' in batch:
            pretrained_vecs = batch['pretrained_vecs'].to(device)
        else:
            pretrained_vecs = dataloader.dataset.pretrained_lookup[item_ids.cpu()].to(device)
            
        forward_kwargs = {
            'pretrained_vecs': pretrained_vecs,
            'item_ids': item_ids,
            'time_bucket_ids': time_bucket_ids,
            'type_ids': type_ids,
            'color_ids': color_ids,
            'graphic_ids': graphic_ids,
            'section_ids': section_ids,
            'age_bucket': age_bucket,
            'price_bucket': price_bucket,
            'cnt_bucket': cnt_bucket,
            'recency_bucket': recency_bucket,
            'channel_ids': channel_ids,
            'club_status_ids': club_status_ids,
            'news_freq_ids': news_freq_ids,
            'fn_ids': fn_ids,
            'active_ids': active_ids,
            'cont_feats': cont_feats,
            'padding_mask': padding_mask,
            'training_mode': True
        }

        # =======================================================
        # [ëª¨ë‹ˆí„°ë§ ë¡œê·¸] ì²« ë°°ì¹˜ì—ì„œë§Œ ë°ì´í„° ìƒíƒœ ì ê²€
        # =======================================================
        if batch_idx == 0:
            print(f"\nğŸ“¦ [Batch 0 Monitor]")
            print(f"   - Item IDs: Shape {item_ids.shape} | Min {item_ids.min()} | Max {item_ids.max()}")
            print(f"   - Time Buckets: Min {time_bucket_ids.min()} | Max {time_bucket_ids.max()}")
            pad_ratio = (padding_mask.sum().item() / padding_mask.numel()) * 100
            print(f"   - Padding Ratio: {pad_ratio:.1f}%")
            print(f"   - Cont Feats Mean: {cont_feats.mean().item():.3f} | Std: {cont_feats.std().item():.3f}")
            
            print("\nğŸ¯ [First User Data State Check]")
            print("-" * 50)
            print(f"ğŸ‘¤ [User Profile]")
            print(f"   - Age Bucket ID:    {age_bucket[0].item()} (Target Age Group)")
            print(f"   - Price Bucket ID:  {price_bucket[0].item()} (Spending Power)")
            print(f"   - News Freq ID:     {news_freq_ids[0].item()} (Marketing Sensitivity)")
            
            valid_indices = torch.where(~padding_mask[0])[0]
            if len(valid_indices) > 0:
                print(f"\nğŸ›ï¸ [Item History - Last 3 Items]")
                sample_indices = valid_indices[-3:] 
                sample_types = type_ids[0][sample_indices].tolist()
                sample_times = time_bucket_ids[0][sample_indices].tolist()
                for i, (t_id, time_id) in enumerate(zip(sample_types, sample_times)):
                    print(f"   - Item {i+1}: Type Hash ID [{t_id}] | Time Bucket ID [{time_id}]")
            else:
                print("\nâš ï¸ [Warning] This user has NO valid sequence (All Padded).")
            print("-" * 50)

        # -------------------------------------------------------
        # 2. Forward & Real Loss Calculation (AMP)
        # -------------------------------------------------------
        with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
            # A. First View
            output_1 = model(**forward_kwargs)
            # B. Second View (Dropout ë§ˆìŠ¤í¬ê°€ ë‹¬ë¼ì§)
            output_2 = model(**forward_kwargs)

            # (1) Main Loss (All Time Steps)
            #valid_mask = ~padding_mask.view(-1)
            #flat_output = output_1.view(-1, cfg.d_model)[valid_mask]
            #flat_targets = target_ids.view(-1)[valid_mask]
            
            last_output_1 = output_1[:, -1, :] # (Batch, Dim)
            last_targets = target_ids[:, -1]   # (Batch,)
            last_valid_mask = ~padding_mask[:, -1]
            
            valid_user_emb = last_output_1[last_valid_mask]
            valid_targets = last_targets[last_valid_mask]
            
            hnm_stats = {}
            
            if valid_user_emb.size(0) > 0:
                valid_user_emb = F.normalize(valid_user_emb, p=2, dim=1)
                
                # ğŸ’¡ [í•µì‹¬ ì¶”ê°€] í‰ê°€ë•Œì™€ ë™ì¼í•˜ê²Œ item_towerì—ì„œ ì‹¤ì‹œê°„ìœ¼ë¡œ ë²¡í„° ì¶”ì¶œ!
                # ë‚˜ì¤‘ì— Joint Trainingì„ ì¼¤ ë•Œ ì•„ì´í…œ ë²¡í„°ê°€ ì—…ë°ì´íŠ¸ë˜ë ¤ë©´ ì—¬ê¸°ì„œ ë½‘ì•„ì•¼ í•©ë‹ˆë‹¤.
                full_item_embeddings = item_tower.get_all_embeddings()
                norm_item_embeddings = F.normalize(full_item_embeddings, p=2, dim=1)
                main_loss, hnm_stats = full_batch_hard_emphasis_loss(
                    user_emb=valid_user_emb,
                    item_tower_emb=norm_item_embeddings, 
                    target_ids=valid_targets,
                    log_q_tensor=log_q_tensor,
                    top_k_percent=cfg.top_k_percent,
                    hard_margin=cfg.hard_margin,
                    hnm_threshold=cfg.hnm_threshold,   # Configì—ì„œ ê°€ì ¸ì˜¨ Threshold (ì˜ˆ: 0.85)
                    temperature=0.15, 
                    lambda_logq=cfg.lambda_logq        # ìƒí–¥ëœ 1.0 ì ìš©
                )
            else:
                main_loss = torch.tensor(0.0, device=device)
                hnm_stats = {"avg_hn_similarity": 0.0, "num_active_hard_negs": 0}
            
            # (2) DuoRec Loss (Last Time Step Only)
            last_output_1 = output_1[:, -1, :] 
            last_output_2 = output_2[:, -1, :]
            last_targets = target_ids[:, -1]

            cl_loss = duorec_loss_refined(
                user_emb_1=last_output_1,
                user_emb_2=last_output_2,
                target_ids=last_targets,
                lambda_sup=cfg.lambda_sup
            )

            # ìµœì¢… Loss ì¡°í•©
            total_loss = main_loss + (cfg.lambda_cl * cl_loss)

        # -------------------------------------------------------
        # 3. Backward & Optimizer Step
        # -------------------------------------------------------
        scaler.scale(total_loss).backward()
        scaler.unscale_(optimizer)
        # ê¸°ìš¸ê¸° í­ë°œ ë°©ì§€ë¥¼ ìœ„í•œ ì •ê·œí™” (5.0ì€ íŠ¸ëœìŠ¤í¬ë¨¸ì—ì„œ ë§ì´ ì“°ì´ëŠ” ì—¬ìœ ìˆëŠ” ê°’)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
        scaler.step(optimizer)
        scaler.update()

        # ëˆ„ì 
        total_loss_accum += total_loss.item()
        main_loss_accum += main_loss.item()
        cl_loss_accum += cl_loss.item()
        
        pbar.set_postfix({
            'Loss': f"{total_loss.item():.4f}",
            'Main': f"{main_loss.item():.4f}",
            'CL': f"{cl_loss.item():.4f}"
        })
        
        # 100ë°°ì¹˜ë§ˆë‹¤ ë¡œê¹…
        if batch_idx % 100 == 0:
            print(f"   [Epoch {epoch}] Batch {batch_idx:04d}/{len(dataloader)} | Total Loss: {total_loss.item():.4f} (Main: {main_loss.item():.4f}, CL: {cl_loss.item():.4f})")
        if batch_idx % 100 == 0:
            wandb.log({
                "Train/Main_Loss_Step": main_loss.item(),
                "HNM/Avg_Hard_Negative_Sim": hnm_stats.get("avg_hn_similarity", 0),
                "HNM/Num_K": hnm_stats.get("num_active_hard_negs", 0),
                "Step": epoch * len(dataloader) + batch_idx
            })
        # -------
        
    avg_loss = total_loss_accum / len(dataloader)
    avg_main = main_loss_accum / len(dataloader)
    avg_cl = cl_loss_accum / len(dataloader)

    with torch.no_grad():
        s_weights = torch.sigmoid(model.seq_gate).cpu().numpy()
        u_weights = torch.sigmoid(model.static_gate).cpu().numpy()
            
            # ë”•ì…”ë„ˆë¦¬ í˜•íƒœë¡œ ë³€í™˜í•˜ì—¬ WandBì— ì „ì†¡
    gate_log = {f"Gate/Seq_{label}": w for label, w in zip(seq_labels, s_weights)}
    gate_log.update({f"Gate/Static_{label}": w for label, w in zip(static_labels, u_weights)})
    wandb.log(gate_log)

    
    print(f"ğŸ Epoch {epoch} Completed | Avg Total: {avg_loss:.4f} (Main: {avg_main:.4f}, CL: {avg_cl:.4f})")
    return avg_loss


import torch
import torch
import torch.nn.functional as F
from tqdm import tqdm



# ğŸ’¡ ì¸ìì— processorë¥¼ ì¶”ê°€í–ˆìŠµë‹ˆë‹¤.
def evaluate_model(model, item_tower, dataloader, target_df_path, device, processor, k_list=[20, 100, 500]):
    """
    Validation ë°ì´í„°ì…‹ê³¼ ì •ë‹µì§€(target_dict)ë¥¼ ì´ìš©í•´ Recall@Kë¥¼ í‰ê°€í•˜ëŠ” í•¨ìˆ˜
    """
    model.eval()
    item_tower.eval()
    print(f"ğŸ¯ Loading targets from: {target_df_path}")
    target_df = pd.read_parquet(target_df_path)
    target_dict = target_df.set_index('customer_id')['target_ids'].to_dict()
    
    # Kê°’ ì¤‘ ê°€ì¥ í° ê°’ì„ ê¸°ì¤€ìœ¼ë¡œ í•œ ë²ˆë§Œ Top-K ì—°ì‚°ì„ ìˆ˜í–‰í•˜ì—¬ GPU ì—°ì‚° ì ˆì•½
    max_k = max(k_list)
    
    total_hits = {k: 0.0 for k in k_list}
    total_valid_users = 0
    
    with torch.no_grad():
        # 1. ì „ì²´ ì•„ì´í…œ ì„ë² ë”© ë¡œë“œ ë° ì •ê·œí™” (ë£¨í”„ ë°–ì—ì„œ í•œ ë²ˆë§Œ ìˆ˜í–‰)
        full_item_embeddings = item_tower.get_all_embeddings()
        norm_item_embeddings = F.normalize(full_item_embeddings, p=2, dim=1)
        
        '''
        print("\nğŸ” [Eval Monitor] Item Tower Check")
        print(f"   - Shape: {full_item_embeddings.shape}")
        print(f"   - Mean: {full_item_embeddings.mean().item():.6f} | Std: {full_item_embeddings.std().item():.6f}")
            # ì¸ë±ìŠ¤ 1ë²ˆ(ì²« ë²ˆì§¸ ì‹¤ì œ ì•„ì´í…œ)ì˜ ì• 5ê°œ ì°¨ì› ê°’ ì¶œë ¥
        if full_item_embeddings.size(0) > 1:
            print(f"   - Item [1] Sample: {full_item_embeddings[1][:5].tolist()}")
        '''
        
        
        
        
        # tqdmì„ ì´ìš©í•´ ì§„í–‰ ì‹œê°„ ë° ìƒíƒœ í‘œì‹œ
        for batch_idx, batch in enumerate(tqdm(dataloader, desc="Evaluating")):
            # Dataloaderì—ì„œ 'user_ids'ë¥¼ ë¬¸ìì—´ ë¦¬ìŠ¤íŠ¸ë¡œ ë°”ë¡œ ê°€ì ¸ì˜´
            user_ids = batch['user_ids'] 
            
            item_ids = batch['item_ids'].to(device)
            padding_mask = batch['padding_mask'].to(device)
            time_bucket_ids = batch['time_bucket_ids'].to(device)
            type_ids = batch['type_ids'].to(device)
            color_ids = batch['color_ids'].to(device)
            graphic_ids = batch['graphic_ids'].to(device)
            section_ids = batch['section_ids'].to(device)
            age_bucket = batch['age_bucket'].to(device)
            price_bucket = batch['price_bucket'].to(device)
            cnt_bucket = batch['cnt_bucket'].to(device)
            recency_bucket = batch['recency_bucket'].to(device)
            channel_ids = batch['channel_ids'].to(device)
            club_status_ids = batch['club_status_ids'].to(device)
            news_freq_ids = batch['news_freq_ids'].to(device)
            fn_ids = batch['fn_ids'].to(device)
            active_ids = batch['active_ids'].to(device)
            cont_feats = batch['cont_feats'].to(device)
            
            # Pretrained Vector ë£©ì—… ì²˜ë¦¬
            if 'pretrained_vecs' in batch:
                pretrained_vecs = batch['pretrained_vecs'].to(device)
                print("pretrained_vecs has been loaded")
            else:
                pretrained_vecs = dataloader.dataset.pretrained_lookup[item_ids.cpu()].to(device)
            
            # =======================================================
            '''
            if batch_idx == 0:
                print(f"\nğŸ” [Eval Monitor] Pretrained Vecs Check (Batch 0)")
                print(f"   - Shape: {pretrained_vecs.shape}")
                print(f"   - Mean: {pretrained_vecs.mean().item():.6f} | Std: {pretrained_vecs.std().item():.6f}")
                
                # íŒ¨ë”©(0)ì´ ì•„ë‹Œ ì‹¤ì œ ì•„ì´í…œ ID í•˜ë‚˜ë¥¼ ì°¾ì•„ í•´ë‹¹ ë²¡í„°ì˜ ê°’ í™•ì¸
                valid_mask = item_ids[0] != 0
                if valid_mask.any():
                    valid_idx = valid_mask.nonzero(as_tuple=True)[0][0]
                    sample_item_id = item_ids[0][valid_idx].item()
                    print(f"   - Item [{sample_item_id}] Sample: {pretrained_vecs[0][valid_idx][:5].tolist()}")
            '''
            forward_kwargs = {
                'pretrained_vecs': pretrained_vecs,
                'item_ids': item_ids,
                'time_bucket_ids': time_bucket_ids,
                'type_ids': type_ids,
                'color_ids': color_ids,
                'graphic_ids': graphic_ids,
                'section_ids': section_ids,
                'age_bucket': age_bucket,
                'price_bucket': price_bucket,
                'cnt_bucket': cnt_bucket,
                'recency_bucket': recency_bucket,
                'channel_ids': channel_ids,
                'club_status_ids': club_status_ids,
                'news_freq_ids': news_freq_ids,
                'fn_ids': fn_ids,
                'active_ids': active_ids,
                'cont_feats': cont_feats,
                'padding_mask': padding_mask,
                'training_mode': False # Dropout ë¹„í™œì„±í™”
            }

            # 2. User Tower Forward
            with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
                output = model(**forward_kwargs) # (Batch, Seq_Len, Dim)
                
            # 3. ì‹¤ì œ ë§ˆì§€ë§‰ ìœ íš¨ ì‹œì ì˜ ë²¡í„° ì¶”ì¶œ (ë‹¨ìˆœíˆ -1ì´ ì•„ë‹ˆë¼ Paddingì„ ê³ ë ¤)
            if output.dim() == 3:
                lengths = (~padding_mask).sum(dim=1)
                last_indices = (lengths - 1).clamp(min=0)
                batch_range = torch.arange(output.size(0), device=device)
                last_user_emb = output[batch_range, last_indices]
            else:
                last_user_emb = output
                
            # L2 ì •ê·œí™”
            last_user_emb = F.normalize(last_user_emb, p=2, dim=1)
            
            # 4. ì •ë‹µì§€(target_dict)ì— ì¡´ì¬í•˜ëŠ” ìœ íš¨í•œ ìœ ì €ë§Œ í•„í„°ë§
            valid_idx_list = [i for i, uid in enumerate(user_ids) if uid in target_dict and len(target_dict[uid]) > 0]
            if not valid_idx_list: 
                continue 
                
            v_idx = torch.tensor(valid_idx_list, device=device)
            valid_user_emb = last_user_emb[v_idx]
            
            # 5. ì „ì²´ ì•„ì´í…œê³¼ ë‚´ì í•˜ì—¬ Score ê³„ì‚°
            scores = torch.matmul(valid_user_emb, norm_item_embeddings.T)
            
            # 6. Top-K ì¸ë±ìŠ¤ ì¶”ì¶œ
            _, topk_indices = torch.topk(scores, k=max_k, dim=-1)
            pred_ids = topk_indices.cpu().numpy() 
            
            # 7. ì‹¤ì œ ì •ë‹µ(Set)ê³¼ êµì§‘í•© ë¹„êµí•˜ì—¬ Recall@K ì¸¡ì •
            for i, original_idx in enumerate(valid_idx_list):
                u_id = user_ids[original_idx]
                
                # ğŸ’¡ [ì•ˆì „ ì¥ì¹˜] ì •ë‹µì´ ë‹¨ì¼ ë¬¸ìì—´ì´ë“  ë¦¬ìŠ¤íŠ¸ë“  ë¬´ì¡°ê±´ ë¦¬ìŠ¤íŠ¸ë¡œ ì·¨ê¸‰í•˜ê²Œ ë§Œë“¦
                raw_targets = target_dict[u_id]
                if isinstance(raw_targets, str) or not hasattr(raw_targets, '__iter__'):
                    raw_targets = [raw_targets]
                
                # ğŸ’¡ ë¦¬ìŠ¤íŠ¸ë¡œ ë§Œë“¤ì–´ì§„ raw_targetsë¥¼ ìˆœíšŒ
                actual_indices = set(processor.item2id[iid] for iid in raw_targets if iid in processor.item2id)
                
                # ë§Œì•½ ì •ë‹µ ì•„ì´í…œë“¤ì´ ëª¨ë¸ì´ ëª¨ë¥´ëŠ”(OOT/Unseen) ì•„ì´í…œì´ë¼ ë§¤í•‘ í›„ ì„¸íŠ¸ê°€ ë¹„ì–´ìˆë‹¤ë©´, 
                # ë§ì¶œ ê°€ëŠ¥ì„±ì´ 0ì´ë¯€ë¡œ í‰ê°€ íƒ€ê²Ÿ ìœ ì €ì—ì„œ ì œì™¸ (ë¶„ëª¨ ì¦ê°€ ë°©ì§€)
                if not actual_indices:
                    continue
                
                total_valid_users += 1
                for k in k_list:
                    # ì˜ˆì¸¡í•œ Top-K ë¦¬ìŠ¤íŠ¸(pred_ids) ì¤‘ ë‹¨ í•˜ë‚˜ë¼ë„ ì‹¤ì œ êµ¬ë§¤ ëª©ë¡(actual_indices)ì— í¬í•¨ë˜ì–´ ìˆë‹¤ë©´ Hit
                    if not actual_indices.isdisjoint(pred_ids[i, :k]):
                        total_hits[k] += 1

    # ìµœì¢… Recall í¼ì„¼í‹°ì§€ ê³„ì‚°
    results = {}
    if total_valid_users > 0:
        for k in k_list:
            results[f'Recall@{k}'] = (total_hits[k] / total_valid_users) * 100
            
    print(f"\nğŸ“ˆ [Validation Results] Valid Users: {total_valid_users}")
    for k in k_list:
        print(f"   - Recall@{k:03d}: {results.get(f'Recall@{k}', 0):.2f}%")
        
    return results


from tqdm import tqdm
import wandb

def train_user_tower_all_time(epoch, model, item_tower, log_q_tensor, dataloader, optimizer, scaler, cfg, device, seq_labels=None, static_labels=None):
    """ë‹¨ì¼ ì—í¬í¬ í›ˆë ¨ í•¨ìˆ˜ (All Time Steps + Same-User Masking ì ìš©)"""
    model.train()
    total_loss_accum = 0.0
    main_loss_accum = 0.0
    cl_loss_accum = 0.0
    
    # ì•ˆì „ì„ ìœ„í•´ labelsê°€ Noneì¼ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ë¡œ ì´ˆê¸°í™”
    seq_labels = seq_labels or []
    static_labels = static_labels or []
    
    pbar = tqdm(dataloader, desc=f"Epoch {epoch}", leave=False)
    for batch_idx, batch in enumerate(pbar):
        optimizer.zero_grad()

        # -------------------------------------------------------
        # 1. Data Unpacking
        # -------------------------------------------------------
        item_ids = batch['item_ids'].to(device)
        target_ids = batch['target_ids'].to(device)
        padding_mask = batch['padding_mask'].to(device)
        time_bucket_ids = batch['time_bucket_ids'].to(device)
        
        type_ids = batch['type_ids'].to(device)
        color_ids = batch['color_ids'].to(device)
        graphic_ids = batch['graphic_ids'].to(device)
        section_ids = batch['section_ids'].to(device)
        
        age_bucket = batch['age_bucket'].to(device)
        price_bucket = batch['price_bucket'].to(device)
        cnt_bucket = batch['cnt_bucket'].to(device)
        recency_bucket = batch['recency_bucket'].to(device)
        
        channel_ids = batch['channel_ids'].to(device)
        club_status_ids = batch['club_status_ids'].to(device)
        news_freq_ids = batch['news_freq_ids'].to(device)
        fn_ids = batch['fn_ids'].to(device)
        active_ids = batch['active_ids'].to(device)
        cont_feats = batch['cont_feats'].to(device)
        
        if 'pretrained_vecs' in batch:
            pretrained_vecs = batch['pretrained_vecs'].to(device)
        else:
            pretrained_vecs = dataloader.dataset.pretrained_lookup[item_ids.cpu()].to(device)
            
        forward_kwargs = {
            'pretrained_vecs': pretrained_vecs,
            'item_ids': item_ids,
            'time_bucket_ids': time_bucket_ids,
            'type_ids': type_ids,
            'color_ids': color_ids,
            'graphic_ids': graphic_ids,
            'section_ids': section_ids,
            'age_bucket': age_bucket,
            'price_bucket': price_bucket,
            'cnt_bucket': cnt_bucket,
            'recency_bucket': recency_bucket,
            'channel_ids': channel_ids,
            'club_status_ids': club_status_ids,
            'news_freq_ids': news_freq_ids,
            'fn_ids': fn_ids,
            'active_ids': active_ids,
            'cont_feats': cont_feats,
            'padding_mask': padding_mask,
            'training_mode': True
        }

        # -------------------------------------------------------
        # 2. Forward & Loss Calculation (AMP)
        # -------------------------------------------------------
        with torch.amp.autocast(device_type='cuda', dtype=torch.float16, enabled=True):
            output_1 = model(**forward_kwargs)
            output_2 = model(**forward_kwargs)

            # =======================================================
            # ğŸ’¡ [í•µì‹¬] (1) Main Loss (All Time Steps -> 1D Flattening)
            # =======================================================
            valid_mask = ~padding_mask # (Batch, Seq) Trueë©´ ìœ íš¨ ë°ì´í„°
            
            # 1. 2D í…ì„œë¥¼ ìœ íš¨í•œ íƒ€ì„ìŠ¤í…ë§Œ 1Dë¡œ í•„í„°ë§ (N, Dim) ë° (N,)
            flat_output = output_1[valid_mask] 
            flat_targets = target_ids[valid_mask]
            
            # 2. ìœ ì € ID ë§¤í•‘ íŠ¸ë¦­: ë¬¸ìì—´ ID ëŒ€ì‹  í˜„ì¬ ë°°ì¹˜ì˜ í–‰(Row) ì¸ë±ìŠ¤ë¥¼ ê³ ìœ  IDë¡œ ì‚¬ìš©
            # (Batch, 1) ì‚¬ì´ì¦ˆì˜ ì¸ë±ìŠ¤ë¥¼ Seq ê¸¸ì´ë§Œí¼ ëŠ˜ë¦° ë’¤ ë˜‘ê°™ì´ Flatten í•©ë‹ˆë‹¤.
            batch_size, seq_len = item_ids.shape
            batch_row_indices = torch.arange(batch_size, device=device).unsqueeze(1).expand(-1, seq_len)
            flat_user_ids = batch_row_indices[valid_mask] # (N,) -> Same-User Maskingì— ì‚¬ìš©ë¨
            
            if flat_output.size(0) > 0:
                flat_user_emb = F.normalize(flat_output, p=2, dim=1)
                
                # ì‹¤ì‹œê°„ ì•„ì´í…œ ë²¡í„° ì¶”ì¶œ
                full_item_embeddings = item_tower.get_all_embeddings()
                norm_item_embeddings = F.normalize(full_item_embeddings, p=2, dim=1)
                
                # ë² ì´ìŠ¤ë¼ì¸ Loss í˜¸ì¶œ (Same-User Masking ì ìš©)
                main_loss = inbatch_corrected_logq_loss(
                    user_emb=flat_user_emb,
                    item_tower_emb=norm_item_embeddings,
                    target_ids=flat_targets,
                    user_ids=flat_user_ids,  # ë°°ì¹˜ ë‚´ ë¡œì»¬ ê³ ìœ  ID ì „ë‹¬
                    log_q_tensor=log_q_tensor,
                    temperature=0.1,         # Baseline ì˜¨ë„
                    lambda_logq=cfg.lambda_logq
                )
            else:
                main_loss = torch.tensor(0.0, device=device)
            
            # =======================================================
            # (2) DuoRec Loss (ì—¬ì „íˆ Last Time Step Only ì ìš©)
            # =======================================================
            # DuoRecì€ ì‹œí€€ìŠ¤ì˜ 'ìµœì¢… ì˜ë„' ì•ˆì •í™”ì— ëª©ì ì´ ìˆìœ¼ë¯€ë¡œ ë§ˆì§€ë§‰ ìŠ¤í…ë§Œ ì‚¬ìš©í•˜ëŠ” ê²ƒì´ ë§ìŠµë‹ˆë‹¤.
            last_indices = (valid_mask.sum(dim=1) - 1).clamp(min=0)
            batch_range = torch.arange(batch_size, device=device)
            
            last_output_1 = output_1[batch_range, last_indices]
            last_output_2 = output_2[batch_range, last_indices]
            last_targets = target_ids[batch_range, last_indices]
            
            cl_loss = duorec_loss_refined(
                user_emb_1=last_output_1,
                user_emb_2=last_output_2,
                target_ids=last_targets,
                lambda_sup=cfg.lambda_sup
            )

            # ìµœì¢… Loss ì¡°í•©
            total_loss = main_loss + (cfg.lambda_cl * cl_loss)

        # -------------------------------------------------------
        # 3. Backward & Optimizer Step
        # -------------------------------------------------------
        scaler.scale(total_loss).backward()
        scaler.unscale_(optimizer)
        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5.0)
        scaler.step(optimizer)
        scaler.update()

        # ëˆ„ì  ë° ë¡œê¹…
        total_loss_accum += total_loss.item()
        main_loss_accum += main_loss.item()
        cl_loss_accum += cl_loss.item()
        
        pbar.set_postfix({
            'Loss': f"{total_loss.item():.4f}",
            'Main': f"{main_loss.item():.4f}",
            'CL': f"{cl_loss.item():.4f}"
        })
        
        if batch_idx % 100 == 0:
            wandb.log({
                "Train/Main_Loss_Step": main_loss.item(),
                "Train/CL_Loss_Step": cl_loss.item(),
                "Step": epoch * len(dataloader) + batch_idx
            })

    avg_loss = total_loss_accum / len(dataloader)
    avg_main = main_loss_accum / len(dataloader)
    avg_cl = cl_loss_accum / len(dataloader)

    # Gate Weights Logging
    with torch.no_grad():
        s_weights = torch.sigmoid(model.seq_gate).cpu().numpy()
        u_weights = torch.sigmoid(model.static_gate).cpu().numpy()
        
        gate_log = {}
        if seq_labels and len(seq_labels) == len(s_weights):
            gate_log.update({f"Gate/Seq_{label}": w for label, w in zip(seq_labels, s_weights)})
        if static_labels and len(static_labels) == len(u_weights):
            gate_log.update({f"Gate/Static_{label}": w for label, w in zip(static_labels, u_weights)})
            
        if gate_log:
            wandb.log(gate_log)

    print(f"ğŸ Epoch {epoch} Completed | Avg Total: {avg_loss:.4f} (Main: {avg_main:.4f}, CL: {avg_cl:.4f})")
    return avg_loss
# =====================================================================
# Main Execution Pipeline
# =====================================================================
def run_pipeline():
    """Airflow DAGë‚˜ MLflow Runì—ì„œ ì§ì ‘ í˜¸ì¶œí•˜ëŠ” ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    print("ğŸš€ Starting User Tower Training Pipeline...")
    
    
    SEQ_LABELS = ['item_id', 'time', 'type', 'color', 'graphic', 'section']
    STATIC_LABELS = ['age', 'price', 'cnt', 'recency', 'channel', 'club', 'news', 'fn', 'active', 'cont']
    # 1. Config & Env
    cfg = PipelineConfig()
    device = setup_environment()
    processor, val_processor, cfg = prepare_features(cfg)
    
    # item metadata cfg
    HASH_SIZE = 1000
    cfg.num_prod_types = HASH_SIZE
    cfg.num_colors = HASH_SIZE
    cfg.num_graphics = HASH_SIZE
    cfg.num_sections = HASH_SIZE
    
    # 2. Data ê°€ì ¸ì˜¤ê¸°
    aligned_vecs = load_aligned_pretrained_embeddings(processor, cfg.model_dir, cfg.pretrained_dim)
    # âŒ full_item_embeddings = aligned_vecs.to(device) # ë” ì´ìƒ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ
    
    item_state_dict = load_item_tower_state_dict(cfg.model_dir, cfg.item_tower_pth_name, device)
    log_q_tensor = processor.get_logq_probs(device)
    
    item_metadata_tensor = load_item_metadata_hashed(processor, cfg.base_dir, hash_size=HASH_SIZE)
    processor.i_side_arr = item_metadata_tensor.numpy()
    
    train_loader = create_dataloaders(processor, cfg, aligned_vecs, is_train=True)
    val_loader = create_dataloaders(val_processor, cfg, aligned_vecs, is_train=False)
    dataset_peek(train_loader.dataset, processor)
    
    
    
        
    wandb.init(
        project="SASRec-User-Tower-causality-Optimization", # í”„ë¡œì íŠ¸ëª…
        name=f"run_lr_{cfg.lr}_epoch_{cfg.epochs}", # ì‹¤í—˜ ì´ë¦„
        config=cfg.__dict__ # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥
    )
    
    
    # -----------------------------------------------------------
    # 3. Models & Optimizer Setup (ì´ˆê¸° ìƒíƒœ: Epoch 1ìš© ì„¸íŒ…)
    # -----------------------------------------------------------
    user_tower, item_tower = setup_models(cfg, device, item_state_dict, log_q_tensor)
    TARGET_VAL_PATH = os.path.join(cfg.base_dir, "features_target_val.parquet")
    
    # ğŸ’¡ [í•µì‹¬ ë°˜ì˜] ì•„ê¹Œ ë§Œë“  ê¹”ë”í•œ ë©”ì„œë“œë¡œ ì‚¬ì „í•™ìŠµ ë²¡í„° ê°•ì œ ì£¼ì…!
    item_tower.init_from_pretrained(aligned_vecs.to(device))
    
    # ğŸ’¡ [ì´ˆê¸°í™”] Epoch 1ì—ì„œëŠ” User Towerë§Œ í•™ìŠµí•˜ë„ë¡ Item Tower ì™„ì „ ë™ê²°
    item_tower.set_freeze_state(True)
    print(f"â„ï¸ Epoch 1: Item Tower FROZEN! (User Tower LR: {cfg.lr})")
    
    # User Towerë§Œ í¬í•¨ëœ Optimizer ìƒì„±
    optimizer = torch.optim.AdamW(user_tower.parameters(), lr=cfg.lr, weight_decay=cfg.weight_decay)
    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))
    
    # ğŸ’¡ [ìŠ¤ì¼€ì¤„ëŸ¬] Validation ì§€í‘œ(Recall@100)ë¥¼ ë³´ê³  ì •ì²´ ì‹œ í•™ìŠµë¥  ê°ì†Œ (patience=1)
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, mode='max', factor=0.5, patience=1
    )
    
    # Best Model íŠ¸ë˜í‚¹ ë³€ìˆ˜
    best_recall_100 = 0.0

    # -----------------------------------------------------------
    # 4. Training Loop
    # -----------------------------------------------------------
    for epoch in range(1, cfg.epochs + 1):
        
        # ğŸ’¡ [ë™ì  Unfreeze] Epoch 2 ì§„ì… ì‹œ ë”± í•œ ë²ˆ ì‹¤í–‰í•˜ì—¬ Joint Training ì‹œì‘
        if epoch == 2:
            print("\nğŸ”¥ [Dynamic Unfreeze] Epoch 2: Item Tower Joint Training ì‹œì‘!")
            item_tower.set_freeze_state(False)
            item_finetune_lr = cfg.lr * 0.05 # ì•„ì´í…œì€ ë§¤ìš° ë¯¸ì„¸í•˜ê²Œë§Œ ì¡°ì • (User LRì˜ 5%)
            
            # ê¸°ì¡´ ì˜µí‹°ë§ˆì´ì €ì— ì•„ì´í…œ íƒ€ì›Œì˜ íŒŒë¼ë¯¸í„° ê·¸ë£¹ì„ ëŸ°íƒ€ì„ì— ë™ì ìœ¼ë¡œ ì¶”ê°€
            optimizer.add_param_group({
                'params': item_tower.parameters(), 
                'lr': item_finetune_lr
            })
            print(f"   - User Tower LR: {cfg.lr}")
            print(f"   - Item Tower LR: {item_finetune_lr} (Fine-tuning mode)")

        # ------------------- í›ˆë ¨ (Train) -------------------
        avg_loss = train_user_tower_all_time(
            epoch=epoch,
            model=user_tower,
            item_tower=item_tower, # ì •ì  ë²¡í„° ëŒ€ì‹  ëª¨ë¸ ê°ì²´ ìì²´ë¥¼ ë„˜ê¹€
            log_q_tensor=log_q_tensor,
            dataloader=train_loader,
            optimizer=optimizer,
            scaler=scaler,
            cfg=cfg,
            device=device,
            seq_labels = SEQ_LABELS,
            static_labels = STATIC_LABELS
        )
        
        # ------------------- í‰ê°€ (Evaluate) -------------------
        val_metrics = evaluate_model(
            model=user_tower, 
            item_tower=item_tower, 
            dataloader=val_loader,
            target_df_path=TARGET_VAL_PATH,
            device=device,
            processor=processor,
            k_list=[20, 100, 500]
        )
        
        current_recall_100 = val_metrics.get('Recall@100', 0.0)
        
        # ------------------- ìŠ¤ì¼€ì¤„ëŸ¬ & Best Model ì €ì¥ -------------------
        scheduler.step(current_recall_100)
        
        if current_recall_100 > best_recall_100:
            print(f"ğŸŒŸ [New Best!] Recall@100 updated: {best_recall_100:.2f}% -> {current_recall_100:.2f}%")
            best_recall_100 = current_recall_100
            
            # ìµœê³  ì„±ëŠ¥ ë‹¬ì„± ì‹œ íŒŒë¼ë¯¸í„° ë®ì–´ì“°ê¸° ì €ì¥
            torch.save(user_tower.state_dict(), os.path.join(cfg.model_dir, "best_user_tower_c.pth"))
            torch.save(item_tower.state_dict(), os.path.join(cfg.model_dir, "best_item_tower_c.pth"))
            print("   ğŸ’¾ Best model weights saved to disk.")
        else:
            print(f"   - (Current Best: {best_recall_100:.2f}%)")
            
    print("\nğŸ‰ Pipeline Execution Finished Successfully!")

def run_resume_pipeline(resume_epoch=6, last_best_recall=9.69):
    """ì €ì¥ëœ ëª¨ë¸ì„ ë¶ˆëŸ¬ì™€ Epoch 6ë¶€í„° ì¬í•™ìŠµì„ ì§„í–‰í•˜ëŠ” ì—”íŠ¸ë¦¬ í¬ì¸íŠ¸"""
    print(f"ğŸš€ Resuming User Tower Training from Epoch {resume_epoch}...")
    # ëª¨ë¸ êµ¬ì¡°ì™€ ì¼ì¹˜í•˜ëŠ” ì´ë¦„í‘œ ì •ì˜
    
    
    
    
    
    
    SEQ_LABELS = ['item_id', 'time', 'type', 'color', 'graphic', 'section']
    STATIC_LABELS = ['age', 'price', 'cnt', 'recency', 'channel', 'club', 'news', 'fn', 'active', 'cont']
    
    cfg = PipelineConfig()
    device = setup_environment()
    processor, val_processor, cfg = prepare_features(cfg)
    # processor.analyze_distributions()
    HASH_SIZE = 1000 
    cfg.num_prod_types = HASH_SIZE
    cfg.num_colors = HASH_SIZE
    cfg.num_graphics = HASH_SIZE
    cfg.num_sections = HASH_SIZE
    # ì•„ì´í…œ ê°œìˆ˜ë„ processorì—ì„œ ê°€ì ¸ì™€ì„œ ì •í™•íˆ ë§¤ì¹­ (ë§¤ìš° ì¤‘ìš”)
    cfg.num_items = len(processor.item2id)
    aligned_vecs = load_aligned_pretrained_embeddings(processor, cfg.model_dir, cfg.pretrained_dim)
    log_q_tensor = processor.get_logq_probs(device)
    item_metadata_tensor = load_item_metadata_hashed(processor, cfg.base_dir, hash_size=HASH_SIZE)
    processor.i_side_arr = item_metadata_tensor.numpy()
    
    
    wandb.init(
        project="SASRec-User-Tower-Optimization", # í”„ë¡œì íŠ¸ëª…
        name=f"run_lr_{cfg.lr}_epoch_{cfg.epochs}", # ì‹¤í—˜ ì´ë¦„
        config=cfg.__dict__ # í•˜ì´í¼íŒŒë¼ë¯¸í„° ì €ì¥
    )
    
    
    train_loader = create_dataloaders(processor, cfg, aligned_vecs, is_train=True)
    val_loader = create_dataloaders(val_processor, cfg, aligned_vecs, is_train=False)
    
    # 2. ëª¨ë¸ ìƒì„±
    # item_state_dictëŠ” ì´ˆê¸°í™”ìš©ì´ë¯€ë¡œ ë¹„ì›Œë‘ê±°ë‚˜ ê¸°ë³¸ ë¡œë“œ í›„ ê°€ì¤‘ì¹˜ë¥¼ ë®ì–´ì”Œì›ë‹ˆë‹¤.
    user_tower, item_tower = setup_models(cfg, device, {}, log_q_tensor)
    
    # 3. [í•µì‹¬] ê°€ì¤‘ì¹˜ ë¶ˆëŸ¬ì˜¤ê¸° (Best ëª¨ë¸ ë¡œë“œ)
    print("ğŸ“‚ Loading best weights for Resume...")
    user_weight_path = os.path.join(cfg.model_dir, "best_user_tower_fout.pth")
    item_weight_path = os.path.join(cfg.model_dir, "best_item_tower_fout.pth")

    if os.path.exists(user_weight_path) and os.path.exists(item_weight_path):
        # torch.loadëŠ” íŒŒì¼ë§Œ ì½ê³ , strict ì˜µì…˜ì€ load_state_dictì— ì¤ë‹ˆë‹¤.
        user_state_dict = torch.load(user_weight_path, map_location=device)
        user_tower.load_state_dict(user_state_dict, strict=False) 
        
        item_state_dict = torch.load(item_weight_path, map_location=device)
        item_tower.load_state_dict(item_state_dict, strict=False)
        
        print("âœ… Successfully loaded best weights from disk (Feature Gates Initialized).")
        # 4. Optimizer & Scheduler ì„¤ì •
        # ì¬í•™ìŠµ ì‹œì—ëŠ” Item Towerë¥¼ ë°”ë¡œ í•™ìŠµ ê°€ëŠ¥ ìƒíƒœë¡œ ë‘¡ë‹ˆë‹¤.
        item_tower.set_freeze_state(True)
    
    # ë‘ íƒ€ì›Œì˜ íŒŒë¼ë¯¸í„°ë¥¼ ì²˜ìŒë¶€í„° ë‚˜ëˆ„ì–´ ê´€ë¦¬
    user_lr = 5e-4   # ì¬í•™ìŠµì´ë¯€ë¡œ ê¸°ì¡´ LRë³´ë‹¤ ì ˆë°˜ ì •ë„ë¡œ ë‚®ê²Œ ì‹œì‘í•˜ëŠ” ê²ƒì„ ì¶”ì²œ
    item_lr = user_lr * 0.05
    
    optimizer = torch.optim.AdamW([
        {'params': user_tower.parameters(), 'lr': user_lr},
        {'params': item_tower.parameters(), 'lr': item_lr}
    ], weight_decay=cfg.weight_decay)
    
    scaler = torch.amp.GradScaler('cuda', enabled=(device.type == 'cuda'))
    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(
        optimizer, 
        mode='max',          # Recall@100 ê¸°ì¤€
        factor=0.3,          # [ì¡°ì •] 0.5ë³´ë‹¤ ì¡°ê¸ˆ ë” ê³¼ê°í•˜ê²Œ ê¹ì•„ì„œ ì •ì°© ìœ ë„
        patience=3,          # [ì¡°ì •] 2ì—ì„œ 3ìœ¼ë¡œ ì¦ê°€. HNMì€ ì ì‘ ê¸°ê°„ì´ í•„ìš”í•¨
        threshold=1e-4,      # ë¯¸ì„¸í•œ ê°œì„ ë„ ì¸ì •
        min_lr=1e-6,         # ìµœì†Œ í•™ìŠµë¥  í•˜í•œì„ 
    )
    
    best_recall_100 = last_best_recall # 9.69% ë¶€í„° ì‹œì‘
    TARGET_VAL_PATH = os.path.join(cfg.base_dir, "features_target_val.parquet")

    # 5. Training Loop (Epoch 6 ~ 10 ë“±)
    total_epochs = resume_epoch + 4 # ì˜ˆ: 5ì—í¬í¬ ë” í•™ìŠµ
    for epoch in range(resume_epoch, total_epochs + 1):
        
        avg_loss = train_user_tower(
            epoch=epoch,
            model=user_tower,
            item_tower=item_tower,
            log_q_tensor=log_q_tensor,
            dataloader=train_loader,
            optimizer=optimizer,
            scaler=scaler,
            cfg=cfg,
            device=device,
            seq_labels = SEQ_LABELS,
            static_labels = STATIC_LABELS
        )
        
        val_metrics = evaluate_model(
            model=user_tower, 
            item_tower=item_tower, 
            dataloader=val_loader,
            target_df_path=TARGET_VAL_PATH,
            device=device,
            processor=processor,
            k_list=[20, 100, 500]
        )
        
        current_recall_100 = val_metrics.get('Recall@100', 0.0)
        scheduler.step(current_recall_100)
        
        if current_recall_100 > best_recall_100:
            print(f"ğŸŒŸ [New Best!] Recall@100 updated: {best_recall_100:.2f}% -> {current_recall_100:.2f}%")
            best_recall_100 = current_recall_100
            torch.save(user_tower.state_dict(), os.path.join(cfg.model_dir, "best_user_tower_hmn.pth"))
            torch.save(item_tower.state_dict(), os.path.join(cfg.model_dir, "best_item_tower_hmn.pth"))
            print("ğŸ’¾ Best model weights updated.")
        else:
            print(f" - (Current Best: {best_recall_100:.2f}%)")

    print("\nğŸ‰ Resume Training Finished!")

if __name__ == "__main__":
    # 5ì—í¬í¬ê¹Œì§€ í•™ìŠµí–ˆìœ¼ë¯€ë¡œ 6ë²ˆë¶€í„° ì¬ê°œ
    #run_resume_pipeline(resume_epoch=26, last_best_recall=17.55)
    run_pipeline()