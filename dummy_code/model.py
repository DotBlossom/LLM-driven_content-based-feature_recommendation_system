'''
from typing import Any, Dict, List, Tuple
from fastapi import APIRouter
from pydantic import BaseModel
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
import random
import utils.vocab as vocab
from database import ProductInferenceVectors
from sqlalchemy.orm import Session
import copy
import random

#################### !!!!!!!! ì¹´í…Œê³ ë¦¬ ì œì™¸í•˜ê³  í•™ìŠµí•˜ê¸°

def prepare_training_data(raw_json):
    features = raw_json['feature_data']['clothes']
    
    # âœ‚ï¸ í•™ìŠµìš© í…ìŠ¤íŠ¸ ë§Œë“¤ ë•ŒëŠ” ì¹´í…Œê³ ë¦¬ ì‚­ì œ!
    if 'category' in features:
        del features['category'] 
        
    # ë‚¨ì€ ê±´: "color: black, material: wool..." (ìˆœìˆ˜ íŠ¹ì§•ë“¤)
    return str(features)


# ItemTowerEmbedding(S1) * N -> save..DB -> stage2 (optimizer pass -> triplet)  

model_router = APIRouter()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")



# í•„ë“œ ìˆœì„œ ì •ì˜ (Field Embedding), ì„ì‹œ, data ë³´ê³  ê²°ì •
# key ìˆœì„œ == ì˜¤ëŠ” json ë°ì´íƒ€Load ìˆœì„œ
ALL_FIELD_KEYS = vocab.ORDERED_FEATURE_KEYS 
FIELD_TO_IDX = {k: i for i, k in enumerate(ALL_FIELD_KEYS)}
NUM_TOTAL_FIELDS = len(ALL_FIELD_KEYS)



class TrainingItem(BaseModel):

    product_id: int
    feature_data: Dict[str, Any]

# --- Global Configuration (ì „ì²´ ì‹œìŠ¤í…œì´ ì°¸ì¡°í•˜ëŠ” ê³µí†µ ì°¨ì›) ---
EMBED_DIM_CAT = 64 # Featureì˜ ì„ë² ë”© ì°¨ì› (Transformer d_model)
OUTPUT_DIM_TRIPLET = 128 # Stage 2 ìµœì¢… ì••ì¶• ì°¨ì›
OUTPUT_DIM_ITEM_TOWER = 128 # Stage 1 ìµœì¢… ì¶œë ¥ ì°¨ì› (Triplet Tower Input)
RE_MAX_CAPACITY = 500 # <<<<<<<<<<<< RE í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ í• ë‹¹
# ----------------------------------------------------------------------
# 1. Utility Modules (Shared for both Item Tower and Optimization Tower)
# ----------------------------------------------------------------------

# --- Residual Block (Corrected for Skip Connection) ---
class SEResidualBlock(nn.Module):

    def __init__(self, dim, dropout=0.2, expansion_factor=4):
        super().__init__()
        
        # 1. Feature Transformation (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜, SwiGLU ìŠ¤íƒ€ì¼ë¡œ í™•ì¥ ì œì•ˆ)
        # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì ì¸ ê¸°ì¡´ Linear ë°©ì‹ì„ ìœ ì§€í•˜ë˜ SEë¥¼ ì¶”ê°€í•¨
        self.block = nn.Sequential(
            nn.Linear(dim, dim * expansion_factor), # ë‚´ë¶€ í™•ì¥
            nn.LayerNorm(dim * expansion_factor),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * expansion_factor, dim), # ë‹¤ì‹œ ì••ì¶•
            nn.LayerNorm(dim),
        )
        
        # 2. SE-Block (Channel Attention, SE-Net êµ¬ì¡° ë°˜ì˜, Gating=Relu íŒŒíŠ¸)
        # ì…ë ¥ ë²¡í„°ì˜ ê° ì°¨ì›(feature)ì— ëŒ€í•´ ì¤‘ìš”ë„(0~1)ë¥¼ ê³„ì‚°
        self.se_block = nn.Sequential(
            nn.Linear(dim, dim // 4),  # Squeeze (ì •ë³´ ì••ì¶•)
            nn.ReLU(),
            nn.Linear(dim // 4, dim),  # Excitation (ì¤‘ìš”ë„ ë³µì›)
            nn.Sigmoid()               # 0~1 ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜
        )

        self.act = nn.GELU()
    
    def forward(self, x):
        residual = x
        
        # (A) Main Path
        out = self.block(x)
        
        # (B) SE-Attention Path
        # ë²¡í„°ì˜ ê¸€ë¡œë²Œ ì •ë³´ë¥¼ ë³´ê³ , ì–´ë–¤ ì°¨ì›ì„ ê°•ì¡°í• ì§€ ê²°ì •
        # MLP ì¶œë ¥ê°’(out)ì— ì¤‘ìš”ë„(weight)ë¥¼ ê³±í•¨
        weight = self.se_block(out)
        out = out * weight 
        
        # (C) Residual Connection
        return self.act(residual + out)




# --- Deep Residual Head (Pyramid Funnel) ---
class DeepResidualHead(nn.Module):
    """
    [Architecture]
    Input(64) -> [Expand 2x] -> 128 -> [Expand 2x] -> 256 
    -> [Deep Interaction (SE-ResBlock)] -> 256 
    -> [Compression] -> Output(128)
    + Global Skip Connection
    """
    def __init__(self, input_dim, output_dim=128):
        super().__init__()
        
        # ì°¨ì› ì •ì˜ (64 -> 128 -> 256)
        mid_dim = input_dim * 2      # 128
        hidden_dim = input_dim * 4   # 256
        
        # 1. Progressive Expansion 
        self.expand_layer1 = nn.Sequential(
            nn.Linear(input_dim, mid_dim),  # 64 -> 128
            nn.LayerNorm(mid_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        self.expand_layer2 = nn.Sequential(
            nn.Linear(mid_dim, hidden_dim), # 128 -> 256
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        # 2. Deep Interaction (Peak Dimensionì—ì„œ ìˆ˜í–‰)
        # ê°€ì¥ ì°¨ì›ì´ ë†’ì€ 256 ìƒíƒœì—ì„œ SE-Blockìœ¼ë¡œ ì •ë°€í•œ íŠ¹ì§• ì¶”ì¶œ ìˆ˜í–‰
        self.res_blocks = nn.Sequential(
            SEResidualBlock(hidden_dim, dropout=0.2), # 256 ìœ ì§€
            SEResidualBlock(hidden_dim, dropout=0.2)  # 256 ìœ ì§€
        )
        
        # 3. Final Projection (Compression)
        # 256 -> 128 ë¡œ ì••ì¶•í•˜ì—¬ ìµœì¢… ì„ë² ë”© ìƒì„±
        self.final_proj = nn.Linear(hidden_dim, output_dim)
        
        # 4. Global Skip Connection (Input Shortcut) ResNet ì”ì°¨
        self.input_skip = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        # --- [Step 1] Progressive Expansion ---
        m = self.expand_layer1(x)  # 64 -> 128
        h = self.expand_layer2(m)  # 128 -> 256
        
        # --- [Step 2] Feature Interaction (SE-Attention) ---
        h = self.res_blocks(h)     # 256 -> 256
        
        # --- [Step 3] Compression ---
        main_out = self.final_proj(h) # 256 -> 128
        
        # --- [Step 4] Global Shortcut ---
        skip_out = self.input_skip(x) # 64 -> 128
        
        return main_out + skip_out
    
    
# ----------------------------------------------------------------------
# 3. Main Model: CoarseToFineItemTower (Stage 1)
# ----------------------------------------------------------------------
class CoarseToFineItemTower(nn.Module):
    """
    [Item Tower - Residual Field Embedding Ver.]
    TabTransformerì˜ ì•„ì´ë””ì–´ë¥¼ ì‘ìš©í•˜ì—¬, STDì™€ REë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ í†µí•©í•˜ê³ 
    ê³„ì¸µì  ì”ì°¨ ì—°ê²°(Inheritance)ì„ í†µí•´ í•™ìŠµ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•œ êµ¬ì¡°.
    """
    def __init__(self, 
                 embed_dim=EMBED_DIM_CAT,     # 64
                 nhead=4, 
                 num_layers=2,                # TabTransformerëŠ” ì–•ì•„ë„ ì¶©ë¶„í•¨
                 max_fields=50,               # ì˜ˆìƒë˜ëŠ” ìµœëŒ€ í•„ë“œ(ì»¬ëŸ¼) ê°œìˆ˜
                 output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. Vocab Size ê°€ì ¸ì˜¤ê¸°
        std_vocab_size, _ = vocab.get_vocab_sizes()
        
        # 2. Embeddings
        # A. STD Value Embedding (Base) , RE Value Embedding (Delta / Child)
        self.std_embedding = nn.Embedding(std_vocab_size, embed_dim, padding_idx=vocab.PAD_ID)
        # self.re_embedding = nn.Embedding(RE_MAX_CAPACITY, embed_dim, padding_idx=vocab.PAD_ID)
        self.re_token_embedding = nn.Embedding(vocab.RE_VOCAB_SIZE, embed_dim, padding_idx=vocab.RE_TOKENIZER.pad_token_id)
        # REëŠ” Delta(ì°¨ì´ì )ë§Œ í•™ìŠµí•˜ë¯€ë¡œ 0 ê·¼ì²˜ ì´ˆê¸°í™” (í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±)
        nn.init.normal_(self.re_token_embedding.weight, mean=0.0, std=0.01)

        # C. Field Embedding (Shared Key)
        # ê° ì»¬ëŸ¼(Color, Brand ë“±)ì˜ ì—­í• ì„ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”©
        self.field_embedding = nn.Parameter(torch.randn(1, max_fields, embed_dim))
        
        # 3. Unified Transformer Encoder
        # STDì™€ REê°€ í•œ ê³µê°„ì—ì„œ ìƒí˜¸ì‘ìš© (Self-Attn ì‚¬ìš©)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=nhead, 
            dim_feedforward=embed_dim * 4,
            batch_first=True,
            dropout=0.1,
            activation='gelu'
            #,norm_first=True # ìµœì‹  íŠ¸ë Œë“œ (ì•ˆì •ì  ìˆ˜ë ´)
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # 4. Projection Head
        # ì…ë ¥ ì°¨ì›: (STDí•„ë“œìˆ˜ + REí•„ë“œìˆ˜) * embed_dim -> Flatten í›„ ì••ì¶•
        self.head = DeepResidualHead(input_dim=embed_dim, output_dim=output_dim) 
        
    # $$Input Sequence = [\underbrace{Token_A}_{STDìë¦¬}, \underbrace{Token_B}_{RE(ì”ì°¨)ìë¦¬}]$$

    def forward(self, std_input: torch.Tensor, re_input: torch.Tensor) -> torch.Tensor:
        """
        std_input: (Batch, Num_Fields) - ì˜ˆ: [Color_ID, Category_ID, ...]
        re_input:  (Batch, Num_Fields) - ì˜ˆ: [MatteBlack_ID, 0, ...] (ìˆœì„œê°€ STDì™€ ëŒ€ì‘ë˜ì–´ì•¼ í•¨)
        """
        B, num_fields = std_input.shape
        
        # --- [Logic 1] Hierarchical Embedding Construction ---
        
        # (A) Field Embedding (Broadcasting)
        # í˜„ì¬ ë°°ì¹˜ì˜ í•„ë“œ ê°œìˆ˜ë§Œí¼ ìë¦„ (í˜¹ì‹œ ëª¨ë¥¼ ê°€ë³€ ê¸¸ì´ì— ëŒ€ë¹„)
        field_emb = self.field_embedding[:, :num_fields, :] # (1, F, D)
        
        # (B) STD (Parent)
        std_val = self.std_embedding(std_input) # (B, F, D)
        std_token = std_val + field_emb
        
        re_tokens = self.re_token_embedding(re_input)
        re_mask = (re_input != vocab.RE_TOKENIZER.pad_token_id).float().unsqueeze(-1) # (B, F, S, 1)
        
        # 3. Sum / Count (ìœ íš¨ í† í° ê°œìˆ˜ë¡œ ë‚˜ëˆ„ê¸°)
        sum_re = torch.sum(re_tokens * re_mask, dim=2) # (B, F, D)
        count_re = torch.clamp(re_mask.sum(dim=2), min=1e-9) # (B, F, 1)
        
    
        # (C) RE (Child = Delta + Parent + Field)
        re_delta = sum_re / count_re # (B, F, D) -> í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•ë¨!
        
    
        # re_delta = self.re_embedding(re_input) # (B, F, D)
        
        # * í•µì‹¬: REê°€ 0(PAD)ì´ì–´ë„ std_val + field_embê°€ ë‚¨ì•„ì„œ 'Parent' ì—­í• ì„ ìˆ˜í–‰í•¨
        # * detach(): REì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ STD ì„ë² ë”©ì„ ë§ê°€ëœ¨ë¦¬ì§€ ì•Šë„ë¡ ì°¨ë‹¨
        re_token = re_delta + std_val.detach() + field_emb
        
        # --- [Logic 2] Unified Sequence ---
        combined_seq = torch.cat([std_token, re_token], dim=1)
        
        # Mask ìƒì„±
        # 1. STD, REê°€ ìœ íš¨í•œê°€?
        std_valid = (std_input != vocab.PAD_ID)
        re_valid = (re_input != vocab.RE_TOKENIZER.pad_token_id).any(dim=2)

        mask_part_std = std_valid
        mask_part_re = re_valid | std_valid

        full_mask = torch.cat([mask_part_std, mask_part_re], dim=1) # (B, 2*F)

        # ì´í›„ Transformerì— ì „ë‹¬
        context_out = self.transformer(combined_seq, src_key_padding_mask=~full_mask)

        # [Smart Pooling] íŒ¨ë”© ì œì™¸ í‰ê· 
        mask_expanded = full_mask.unsqueeze(-1).float() # (B, 2*F, 1)
        sum_embeddings = torch.sum(context_out * mask_expanded, dim=1)
        sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9) # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        
        pooled = sum_embeddings / sum_mask
        
        return self.head(pooled)
    
# ----------------------------------------------------------------------
# 4. OptimizedItemTower (Stage 2 Adapter - Triplet Training)
#    Projection Head --> Contrastive Loss(Opt.z) / Representation(Encoder)
# ----------------------------------------------------------------------

class OptimizedItemTower(nn.Module):
    """
    [Optimization Tower]: Projection Head, Distance/metric Learningìš©
    """
    def __init__(self, input_dim=OUTPUT_DIM_ITEM_TOWER, output_dim=OUTPUT_DIM_TRIPLET):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.LayerNorm(input_dim),
            nn.GELU(), #nn.GELU(), 
            nn.Linear(input_dim, output_dim),
        )
        
    def forward(self, x):
        # [Log 1] ì…ë ¥ ë°ì´í„° í™•ì¸
        if not self.training: 
            print(f"\n  [Model Internal] Input Vector Shape: {x.shape}")
            print(f"  [Model Internal] Input Sample (First 5): {x[0, :5].detach().cpu().numpy()}")

        # ë ˆì´ì–´ í†µê³¼
        x = self.layer(x)
        
        # ì •ê·œí™” (L2 Normalization)
    
        return F.normalize(x, p=2, dim=1)




# x = F.normalize(x, p=2, dim=1) ì‹¤ì œ ì¶”ë¡ ë–„ëŠ” hìª½ model loadí•˜ì—¬ ì“°ì. (same d)



    
# ----------------------------------------------------------------------
# 5. Dataset & Sampler & Training Function (Stage 2 Logic) / first INPUT from DB
# ----------------------------------------------------------------------


class SimCSEModelWrapper(nn.Module):
    def __init__(self, encoder, projector):
        super().__init__()
        self.encoder = encoder      # ì´ê²ƒì´ CoarseToFineItemTower
        self.projector = projector  # ì´ê²ƒì´ OptimizedItemTower


    def forward(self, t_std, t_re):
        # 1. ë°›ì€ 2ê°œ ì¸ìë¥¼ encoderì—ê²Œ ê·¸ëŒ€ë¡œ í† ìŠ¤
        enc_out = self.encoder(t_std, t_re) 
        
        # 2. ê·¸ ê²°ê³¼ë¥¼ projectorì—ê²Œ í† ìŠ¤
        return self.projector(enc_out)

class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def _apply_dropout_and_convert(self, product: TrainingItem):
        """
        1. Feature Dropout ìˆ˜í–‰
        """
        # 1. Deep Copy (ì›ë³¸ ë³´ì¡´)
        feat_data = copy.deepcopy(product.feature_data)
        
        clothes = feat_data.get("clothes", {})
        reinforced = feat_data.get("reinforced_feature_value", {})
        
        # 2. Random Dropout (Key ì‚­ì œ) - ì—¬ê¸°ê°€ ë°ì´í„° ì¦ê°•(Augmentation) í•µì‹¬
        if self.dropout_prob > 0:
            # list(...)ë¡œ ê°ì‹¸ì•¼ ì‚­ì œ ì¤‘ ë”•ì…”ë„ˆë¦¬ í¬ê¸° ë³€ê²½ ì—ëŸ¬ ë°©ì§€
            for k in list(clothes.keys()):
                if random.random() < self.dropout_prob:
                    del clothes[k]
            for k in list(reinforced.keys()):
                if random.random() < self.dropout_prob:
                    del reinforced[k]

        
        # 3.preprocess_batch_inputì´ 'feature_data' ì†ì„±ì„ ì°¸ì¡°í•˜ë¯€ë¡œ ê·¸ í˜•íƒœë¥¼ ë§ì¶°ì¤Œ.
        return TrainingItem(
            product_id=product.product_id,
            feature_data=feat_data # ë“œëì•„ì›ƒ ì ìš©ëœ ë°ì´í„°
        )

    def __getitem__(self, idx):
        item = self.products[idx]
        
        # ë·° 1 ìƒì„± (ë“œëì•„ì›ƒ A ì ìš©)
        view1_obj = self._apply_dropout_and_convert(item)
        
        # ë·° 2 ìƒì„± (ë“œëì•„ì›ƒ B ì ìš©)
        view2_obj = self._apply_dropout_and_convert(item)
        
        return view1_obj, view2_obj


# ----------------------------------------------------------------------
# 6. userTowerClass
#     
# ----------------------------------------------------------------------
import torch
import torch.nn as nn
import torch.nn.functional as F

# [ì°¸ê³ ] ë‹˜ê»˜ì„œ ì‘ì„±í•˜ì‹  Utility Modules (SEResidualBlock, DeepResidualHead)ê°€
# ì´ë¯¸ import ë˜ì–´ ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.

class LightGCNEncoder(nn.Module):
    """
    User-Item ê·¸ë˜í”„ êµ¬ì¡°ë¥¼ í•™ìŠµí•˜ì—¬ 'ì¥ê¸°ì ì¸ ì„ í˜¸ë„(Long-term Preference)' ì¶”ì¶œ
    """
    def __init__(self, num_users, num_items, embed_dim, n_layers=3):
        super().__init__()
        self.num_users = num_users
        self.num_items = num_items
        self.n_layers = n_layers
        
        # ì´ˆê¸° ì„ë² ë”© (User + Item)
        # 0 ~ num_users-1: User
        # num_users ~ num_users+num_items-1: Item
        self.embedding = nn.Embedding(num_users + num_items, embed_dim)
        nn.init.normal_(self.embedding.weight, std=0.1)

    def forward(self, adj_matrix):
        """
        adj_matrix: Normalized Sparse Adjacency Matrix
        """
        all_emb = self.embedding.weight
        embs = [all_emb]

        # Graph Convolution (No Nonlinearity)
        for _ in range(self.n_layers):
            all_emb = torch.sparse.mm(adj_matrix, all_emb)
            embs.append(all_emb)
        
        # Layer Combination (Mean or Weighted Sum)
        embs = torch.stack(embs, dim=1)
        light_out = torch.mean(embs, dim=1)
        
        # User ë¶€ë¶„ê³¼ Item ë¶€ë¶„ì„ ë¶„ë¦¬í•´ì„œ ë°˜í™˜
        user_emb_final, item_emb_final = torch.split(light_out, [self.num_users, self.num_items])
        return user_emb_final, item_emb_final


class SequentialEncoder(nn.Module):
    """
    ìµœê·¼ í–‰ë™ ì´ë ¥ì„ í†µí•´ 'ë‹¨ê¸°ì ì¸ ì˜ë„(Short-term Intent)' ì¶”ì¶œ (SASRec Style)
    """
    def __init__(self, num_items, embed_dim, max_len=50, num_blocks=2, num_heads=2):
        super().__init__()
        self.item_emb = nn.Embedding(num_items, embed_dim, padding_idx=0)
        self.pos_emb = nn.Embedding(max_len, embed_dim)
        self.emb_dropout = nn.Dropout(0.1)
        
        # SASRec Block (Standard Transformer Encoder)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=num_heads, 
            dim_feedforward=embed_dim*4, 
            dropout=0.1, 
            activation='gelu',
            batch_first=True,
            norm_first=True # Pre-LN for stability
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_blocks)
        
        self.max_len = max_len

    def forward(self, history_ids):
        """
        history_ids: (Batch, Max_Len) - Paddingì€ 0
        """
        seq_len = history_ids.size(1)
        
        # 1. Embedding + Positional
        # positions: [0, 1, 2, ... seq_len-1]
        positions = torch.arange(seq_len, dtype=torch.long, device=history_ids.device)
        positions = positions.unsqueeze(0).expand(history_ids.size(0), -1)
        
        x = self.item_emb(history_ids) + self.pos_emb(positions)
        x = self.emb_dropout(x)

        # 2. Causality Mask (ë¯¸ë˜ ì •ë³´ ì°¸ì¡° ë°©ì§€)
        # mask: (Seq_Len, Seq_Len) Upper triangular is -inf
        mask = torch.triu(torch.ones(seq_len, seq_len), diagonal=1).bool().to(history_ids.device)

        # 3. Padding Mask
        # key_padding_mask: (Batch, Seq_Len) True where value is 0
        pad_mask = (history_ids == 0)

        # 4. Transformer Passing
        # x: (Batch, Seq_Len, Dim)
        output = self.transformer(x, mask=mask, src_key_padding_mask=pad_mask)

        # 5. Gather Last Valid Item (ì‹œí€€ìŠ¤ì˜ ë§ˆì§€ë§‰ ì‹œì ì´ í˜„ì¬ ì˜ë„)
        # (Batch, Dim) ì¶”ì¶œ ë¡œì§ì€ ìƒëµí•˜ê³ , í¸ì˜ìƒ ë§ˆì§€ë§‰ ì»¬ëŸ¼ í˜¹ì€ 
        # ì‹¤ì œ ë°ì´í„° ê¸¸ì´ì— ë§ì¶° gather í–ˆë‹¤ê³  ê°€ì •. ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ë§ˆì§€ë§‰ í† í° ì‚¬ìš©.
        # ì‹¤ì œ êµ¬í˜„ì‹œ: last_indices = (history_ids != 0).sum(1) - 1 ë“±ì„ ì‚¬ìš©
        
        # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ Mean Pooling í˜¹ì€ Last Token ì‚¬ìš© (ì„±ëŠ¥ì€ Lastê°€ ë³´í†µ ì¢‹ìŒ)
        # íŒ¨ë”©ì´ ì•„ë‹Œ í† í° ì¤‘ ë§ˆì§€ë§‰ ë²¡í„°ë¥¼ ê°€ì ¸ì˜¤ëŠ” ë¡œì§:
        # (êµ¬í˜„ í¸ì˜ìƒ Global Pooling ì˜ˆì‹œ)
        mask_expanded = (~pad_mask).unsqueeze(-1).float()
        sum_emb = torch.sum(output * mask_expanded, dim=1)
        sum_cnt = torch.clamp(mask_expanded.sum(dim=1), min=1e-9)
        seq_vector = sum_emb / sum_cnt

        return seq_vector


class HybridGNNUserTower(nn.Module):
    def __init__(self, 
                 num_users, 
                 num_items, 
                 embed_dim=64, 
                 output_dim=128, # Item Tower output_dimê³¼ ë§ì¶°ì•¼ í•¨
                 max_history_len=50):
        super().__init__()
        
        # 1. GNN Component (Long-term)
        self.gnn_encoder = LightGCNEncoder(num_users, num_items, embed_dim)
        
        # 2. Sequential Component (Short-term)
        self.seq_encoder = SequentialEncoder(num_items, embed_dim, max_len=max_history_len)
        
        # 3. Fusion Head (User's DeepResidualHead)
        # ì…ë ¥: GNN(64) + Seq(64) = 128 -> ì¶œë ¥: 128
        self.fusion_head = DeepResidualHead(input_dim=embed_dim * 2, output_dim=output_dim)

    def forward(self, user_ids, history_ids, adj_matrix):
        """
        user_ids: (Batch,)
        history_ids: (Batch, Max_Len)
        adj_matrix: Global Sparse Adjacency Matrix (User-Item Graph)
        """
        
        # --- A. GNN Flow (Global Preference) ---
        # ì „ì²´ ê·¸ë˜í”„ë¥¼ í†µí•´ ì—…ë°ì´íŠ¸ëœ ëª¨ë“  ìœ ì € ë²¡í„°ë¥¼ ê°€ì ¸ì˜´
        # (Inference ì‹œì—ëŠ” ë¯¸ë¦¬ ê³„ì‚°ëœ ë²¡í„°ë¥¼ Lookupë§Œ í•˜ë©´ ë¨)
        all_user_embs, _ = self.gnn_encoder(adj_matrix) 
        user_long_term = all_user_embs[user_ids] # (Batch, embed_dim)

        # --- B. Sequential Flow (Current Intent) ---
        user_short_term = self.seq_encoder(history_ids) # (Batch, embed_dim)

        # --- C. Contrastive Learning Prep (Optional) ---
        # í•™ìŠµ ì‹œ, user_long_termê³¼ user_short_termì´ ì„œë¡œ "ë¹„ìŠ·í•œ ì •ë³´ë¥¼ ë‹´ë„ë¡" 
        # Auxiliary Lossë¥¼ ì¶”ê°€í•˜ë©´ ì„±ëŠ¥ì´ ì˜¬ë¼ê°. (Self-Supervised Learning)
        
        # --- D. Fusion ---
        combined = torch.cat([user_long_term, user_short_term], dim=1) # (Batch, 128)
        
        # Item Towerì˜ DeepHeadì™€ ë™ì¼í•œ êµ¬ì¡°ë¥¼ í†µê³¼í•˜ì—¬ ìµœì¢… ë§¤í•‘
        final_user_vector = self.fusion_head(combined) # (Batch, 128)
        
        return final_user_vector

def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [ê¸°ëŠ¥]
    1. DBì—ì„œ (product_id, vector) ìŒì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
    2. DB ID -> Model Index ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3. User Towerì˜ Embedding Layerì— ë„£ì„ Weight Matrixë¥¼ ë§Œë“­ë‹ˆë‹¤.
    
    [Return]
    - embedding_matrix: (Num_Products + 1, 128) - 0ë²ˆì€ Padding
    - id_map: {real_db_id: model_index}
    """
    print("â³ Fetching product vectors from DB...")
    
    # 1. DB Query (IDì™€ Serving Vectorë§Œ ê°€ì ¸ì˜´)
    # vector_servingì´ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìµœì¢… ì•„ì´í…œ ë²¡í„°ë¼ê³  ê°€ì •
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_embedding
    ).filter(
        ProductInferenceVectors.vector_embedding.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128 # ê³ ì • ì°¨ì›
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    id_map = {} # Real ID -> Model Index

    # 3. ë§¤í•‘ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listëŠ” DBì—ì„œ List[float] í˜•íƒœë¡œ ì˜¨ë‹¤ê³  ê°€ì •
        if vector_list is None: continue
            
        # ë§¤í•‘ ì €ì¥
        id_map[real_id] = idx 
        
        # í…ì„œì— ê°’ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print("âœ… Pretrained Embedding Matrix Created.")
    print(f"   Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map


class FinalUserTower(nn.Module):
    def __init__(self, 
                 num_total_products: int,
                 pretrained_item_matrix: torch.Tensor = None,
                 max_seq_len: int = 50,
                 d_model: int = 128,
                 nhead: int = 4,
                 num_layers: int = 2,
                 output_dim: int = 128):
        super().__init__()
        
        # 1. Embeddings
        # num_total_products + 1 (Padding=0)
        self.item_embedding = nn.Embedding(num_total_products + 1, d_model, padding_idx=0)
        
        # [ì¤‘ìš”] Pretrained Weight ë¡œë“œ (User History ì…ë ¥ìš©)
        if pretrained_item_matrix is not None:
            self.load_pretrained_weights(pretrained_item_matrix)
            
        self.position_embedding = nn.Embedding(max_seq_len, d_model)
        self.season_embedding = nn.Embedding(5, d_model, padding_idx=0) # 0:Pad, 1~4:Seasons
        self.gender_embedding = nn.Embedding(3, d_model, padding_idx=0) # 0:Unk, 1:M, 2:F
        
        # 2. Transformer
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, 
            batch_first=True, dropout=0.1
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        self.user_query_token = nn.Parameter(torch.randn(1, 1, d_model)) 

        # 3. Heads
        self.deep_head = DeepResidualHead(input_dim=d_model, output_dim=output_dim)
        self.final_projector = OptimizedItemTower(input_dim=output_dim, output_dim=output_dim)

    def load_pretrained_weights(self, matrix):
        # Matrix Shape Check: (Num_Items + 1, Dim)
        expected_shape = self.item_embedding.weight.shape
        if matrix.shape != expected_shape:
            print(f"âš ï¸ Shape Mismatch! Model: {expected_shape}, Input: {matrix.shape}")
            # Shapeì´ ë‹¤ë¥´ë©´ ì¼ë¶€ë§Œ ë¡œë“œí•˜ê±°ë‚˜ ì—ëŸ¬ ì²˜ë¦¬ (ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœ ê²½ê³  í›„ ìŠ¬ë¼ì´ì‹±)
            min_rows = min(expected_shape[0], matrix.shape[0])
            self.item_embedding.weight.data[:min_rows] = matrix[:min_rows]
        else:
            self.item_embedding.weight.data.copy_(matrix)
        
        # Fine-tuning ì—¬ë¶€ (True: í•™ìŠµë¨, False: ê³ ì •ë¨)
        self.item_embedding.weight.requires_grad = False 

    def forward(self, history_ids, season_idx, gender_idx):
        """
        history_ids: (Batch, Seq_Len)
        season_idx: (Batch, )
        gender_idx: (Batch, )
        """
        B, L = history_ids.shape
        device = history_ids.device
        
        # [Step 1] Input Embedding & Context Injection
        seq_emb = self.item_embedding(history_ids) # (B, L, D)
        pos_emb = self.position_embedding(torch.arange(L, device=device)) # (L, D) -> Broadcasting
        
        # Global Context (Season, Gender)ë¥¼ ì‹œí€€ìŠ¤ ì „ì²´ì— ë”í•¨
        season_emb = self.season_embedding(season_idx).unsqueeze(1) # (B, 1, D)
        gender_emb = self.gender_embedding(gender_idx).unsqueeze(1) # (B, 1, D)
        
        x = seq_emb + pos_emb + season_emb + gender_emb # (B, L, D)
        
        # [Step 2] Append CLS Token & Masking
        cls_token = self.user_query_token.expand(B, -1, -1) # (B, 1, D)
        x = torch.cat([cls_token, x], dim=1) # (B, L+1, D)
        
        # Padding Mask (Trueê°€ ë§ˆìŠ¤í‚¹ë¨)
        # 0ì€ Padding ID
        padding_mask = (history_ids == 0) # (B, L)
        cls_mask = torch.zeros((B, 1), dtype=torch.bool, device=device) # CLS í† í°ì€ ë§ˆìŠ¤í‚¹ ì•ˆí•¨
        full_mask = torch.cat([cls_mask, padding_mask], dim=1) # (B, L+1)
        
        # [Step 3] Transformer Encoding
        out = self.transformer(x, src_key_padding_mask=full_mask)
        
        # [Step 4] Extract CLS & Projection
        raw_user_vector = out[:, 0, :] # (B, d_model) -> 0ë²ˆì§¸ í† í°(CLS)ë§Œ ì‚¬ìš©
        deep_feat = self.deep_head(raw_user_vector) 
        final_vector = self.final_projector(deep_feat)
        
        return final_vector
        
        '''