uvicorn main:app --reload

사전학습
모델1 + 모델2 를 학습데이터로 학습

평가
모델1(아이템 타워 몸통) 모델2(마지막레이어 정규화) -> 이 params 학습이 pth1 pth2 사용하기
pth1 pth2 기반으로 모델 로드하고, eval하여 상품임베딩벡터 생성 및 serving 가능상태


swagger
 http://127.0.0.1:8000/docs


 [입력 데이터] (Batch Size = 32)
      |
      V
[SimCSERecSysDataset] -> (View1 데이터, View2 데이터) 생성
      |
      V
[preprocess (collate)] -> 텐서 변환 (t_std1, t_re1), (t_std2, t_re2)
      |
      | --- (여기까지는 데이터 준비) ---
      |
      V
[모델 실행 1] emb1 = model(t_std1, t_re1)  
      ★ 중요: 여기서 Cross-Attention 발생! (STD <-> RE)
      ★ 결과: 32개의 완성된 벡터 (emb1)
      |
[모델 실행 2] emb2 = model(t_std2, t_re2)
      ★ 중요: 여기서도 Cross-Attention 발생!
      ★ 결과: 32개의 완성된 벡터 (emb2)
      |
      | --- (모델 역할 끝. 이제 채점 준비) ---
      |
      V
[torch.cat] embeddings = cat([emb1, emb2])
      ★ 의미: 32개 + 32개 = 64개의 벡터를 한 리스트로 만듦
      |
      V
[NTXentLoss] loss = func(embeddings, labels)
      ★ 동작: 64개끼리 서로 지지고 볶아서(유사도 계산),
              "같은 상품 출신끼리 붙어있니?"를 검사함.


              "clothes": {
            "category": [
                "01outer_01coat", 
                "01outer_02jacket", 
                "01outer_03jumper",
                "01outer_04cardigan",
                "02top_01blouse", 
                "02top_02t-shirt", 
                "02top_03sweater", 
                "02top_04shirt", 
                "02top_05vest", 
                "03-1onepiece(dress)", 
                "03-2onepiece(jumpsuite)", 
                "04bottom_01pants", 
                "04bottom_02skirt"
            ],
						"season": ["spring&fall", "summer", "winter"],
					  "fiber_composition": ["Cotton", "Hemp", "cellulose fiber Others", "Silk", "Wool", "protein fiber Others", "Viscos rayon", "regenerated fiber Others", "Polyester", "Nylon", "Polyurethane", "synthetic fiber Others"],
					  "elasticity": ["none at all", "none", "contain", "contain little", "contain a lot"],
					  "transparency": ["none at all", "none", "contain", "contain little", "contain a lot"],
						"isfleece": ["fleece_contain", "fleece_none"],
						"color": ["Black", "White", "Gray", "Red", "Orange", "Pink", "Yellow", "Brown", "Green", "Blue", "Purple", "Beige", "Mixed"],
			      "gender": ["male", "female", "both"],
			      "category_specification": ["outer","top","onepiece","bottom"],
			      "top.length_type": ["crop", "nomal", "long", "midi", "short"],
					  "top.sleeve_length_type": ["sleeveless", "short sleeves", "long sleeves"],
					  "top.neck_color_design": ["shirts collar", "bow collar", "sailor collar", "shawl collar", "polo collar", "Peter Pan collar", "tailored collar", "Chinese collar", "band collar", "hood", "round neck", "U-neck", "V-neck", "halter neck", "off shoulder", "one shoulder", "square neck", "turtle neck", "boat neck", "cowl neck", "sweetheart neck", "no neckline", "Others"],
					  "top.sleeve_design": ["basic sleeve", "ribbed sleeve", "shirt sleeve", "puff sleeve", "cape sleeve", "petal sleeve", "Others"]
			      "pant.silhouette": ["skinny", "normal", "wide", "loose", "bell-bottom", "Others"],
			      "skirt.design": ["A-line and bell line", "mermaid line", "Others"]
	      },
"reinforced_feature_value" : {
															"category" : [""],
															"fiber_composition":[""],
															"color": [""],
															"category_specification": [""],
															"specification.metadata":[""]
						},							








구조: Encoder -> Embedding(h) -> MLP Layer(Projection Head) -> Output(z) -> Loss

원리: z 공간에서는 Contrastive Loss에 의해 데이터가 구체 표면으로 찌그러지며 정보 손실
반면 그 전 단계인 h는 데이터의 원본 정보를 상대적 보존

학습할 때: Projection Head를 붙여서 z 값으로 Loss 계산.

서빙할 때: Projection Head를 떼어버리고 h 값을 사용.

효과: 이렇게 하면 Representation Quality가 10~15% 향상 data


Reinforce에서 제목에서 나온 토크나이저가 중요하겠네? 
일단 학습단이니 뭐 .. reinfoced 없어도 상품만 분류하는거니까.

제목 처리 .
그냥 문제 성능보단 해결 과정을 좀 .


text concate

STD (Query): "나는 **'남성 바지'**라는 큰 틀이야. 내 구체적인 특징이 뭐지?" (질문자)

RE (Key/Value): "소재는 데님이고, 핏은 와이드야." (구조화된 대답)

Title (Key/Value): "상품명은 '빈티지 워싱 쿨링 진'이야." (비구조화된 대답)



data aug by local modal
빠른학습모드로 1000개정도 먼저 이미지 매칭해서 던져보자 제목증강 + reinfoece