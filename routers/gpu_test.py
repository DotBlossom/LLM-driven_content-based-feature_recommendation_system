from fastapi import APIRouter, HTTPException, BackgroundTasks
from pydantic import BaseModel
from typing import List, Optional

import torch
from pytorch_metric_learning import losses, miners, distances

from pydantic import BaseModel
from typing import List, Optional
import model

gpu_test_router = APIRouter() 

class ClothesInfo(BaseModel):
    category: List[str] 

class ProductItem(BaseModel):
    id: int
    clothes: ClothesInfo
    vector: Optional[List[float]] = None 

class TrainRequest(BaseModel):
    products: List[ProductItem]
    epochs: int = 5
    batch_size: int = 32

class InferenceRequest(BaseModel):
    vector: List[float]

'''
@gpu_test_router.post("/train")
async def train_endpoint(req: TrainRequest, background_tasks: BackgroundTasks):
    product_list = [item.dict() for item in req.products]
    background_tasks.add_task(model.train_model, product_list, req.epochs, req.batch_size)
    return {"message": "Training started in background."}


@gpu_test_router.post("/train_sync")
def train_sync_endpoint(req: TrainRequest):
    product_list = [item.dict() for item in req.products]
    try:
        history = model.train_model(product_list, req.epochs, req.batch_size)
        return {"status": "success", "history": history}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@gpu_test_router.post("/inference")
def inference_endpoint(req: InferenceRequest):
    if len(req.vector) != 512:
        raise HTTPException(status_code=400, detail="Input vector must be 512 dimensions.")
    try:
        optimized_vec = model.load_and_infer(req.vector)
        return {"input_dim": 512, "output_dim": 128, "vector": optimized_vec}
    except FileNotFoundError:
        raise HTTPException(status_code=404, detail="Model not found. Please train the model first.")
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))



@gpu_test_router.get("/metric")
def test_result():
    print(f"PyTorch Version: {torch.__version__}")
    print(f"CUDA Available: {torch.cuda.is_available()}")

    # 2. Metric Learning í…ŒìŠ¤íŠ¸ (Triplet Loss ì˜ˆì œ)
    if torch.cuda.is_available():
        device = torch.device("cuda")
        print("âœ… GPU ëª¨ë“œë¡œ Metric Learningì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.")
    else:
        device = torch.device("cpu")
        print("âš ï¸ CPU ëª¨ë“œì…ë‹ˆë‹¤.")

    # ë”ë¯¸ ë°ì´í„° ìƒì„± (ë°°ì¹˜ì‚¬ì´ì¦ˆ 32, 128ì°¨ì› ë²¡í„°)
    embeddings = torch.randn(32, 128).to(device)
    labels = torch.randint(0, 10, (32,)).to(device)

    # ë¼ì´ë¸ŒëŸ¬ë¦¬ ê¸°ëŠ¥ ì‚¬ìš© (ê±°ë¦¬ ê³„ì‚° -> ë§ˆì´ë‹ -> ë¡œìŠ¤ ê³„ì‚°)
    distance_func = distances.CosineSimilarity()
    loss_func = losses.TripletMarginLoss(distance=distance_func)
    miner_func = miners.TripletMarginMiner(distance=distance_func)

    # ë§ˆì´ë‹ ë° ë¡œìŠ¤ ê³„ì‚°
    hard_pairs = miner_func(embeddings, labels)
    loss = loss_func(embeddings, labels, hard_pairs)

    print(f"ê³„ì‚°ëœ Loss ê°’: {loss.item()}")
    print("ğŸ‰ ì„¤ì¹˜ê°€ ì™„ë²½í•©ë‹ˆë‹¤!")
    return {
        "ê³„ì‚°ëœ Loss ê°’" : loss.item(),
        "completed" : "yes"
    }
    
    
'''