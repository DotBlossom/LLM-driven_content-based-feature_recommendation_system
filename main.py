from typing import AsyncGenerator
from fastapi import FastAPI, APIRouter
from fastapi.concurrency import asynccontextmanager
from fastapi.middleware.cors import CORSMiddleware
import torch
import uvicorn

from utils.dependencies import initialize_global_models #initialize_rec_service

from APIController.controller import controller_router
from database import engine, Base
from APIController.serving_controller import serving_controller_router

# from train import train_router



        
@asynccontextmanager
async def lifespan(app:FastAPI) -> AsyncGenerator[None, None]:

    # ğŸŒŸ 1. STARTUP (ì•± ì‹œì‘ ì‹œ ì‹¤í–‰)
    
    print("âœ¨ Lifespan ì‹œì‘: DB conn ...")
    #Base.metadata.drop_all(bind=engine)
    Base.metadata.create_all(bind=engine)
    print("ë“±ë¡ëœ í…Œì´ë¸” ëª©ë¡:", Base.metadata.tables.keys())
    print("âœ¨ Lifespan ì‹œì‘: DB conn ì™„ë£Œ...")
    
    print("âœ¨ Lifespan ì‹œì‘: ëª¨ë¸ ë¡œë”© ì¤‘...")
    
    
    # dependencies.pyì— ì •ì˜ëœ ëª¨ë¸ ë¡œë”© ë¡œì§ì„ í˜¸ì¶œí•©ë‹ˆë‹¤.
    # ëª¨ë¸ ë¡œë”©ì´ ì™„ë£Œëœ í›„, ì•±ì´ ìš”ì²­ì„ ì²˜ë¦¬í•  ì¤€ë¹„ê°€ ë©ë‹ˆë‹¤.
    initialize_global_models()

    
    
    print("âœ… ëª¨ë¸ ë¡œë”© ë° ì¤€ë¹„ ì™„ë£Œ.")
    
    # initialize_rec_service()
    print("âœ… ì¶”ì²œì‹œìŠ¤í…œ ë¡œë”© ë° ì¤€ë¹„ ì™„ë£Œ.")
    
    # yield ì „ì˜ ì½”ë“œëŠ” Startup ì‹œì ì— ì‹¤í–‰ë©ë‹ˆë‹¤.
    yield
    
    # ğŸŒŸ 2. SHUTDOWN (ì•± ì¢…ë£Œ ì‹œ ì‹¤í–‰)
    # yield í›„ì˜ ì½”ë“œëŠ” ì• í”Œë¦¬ì¼€ì´ì…˜ì´ ì¢…ë£Œë  ë•Œ(ì„œë²„ê°€ êº¼ì§ˆ ë•Œ) ì‹¤í–‰ë©ë‹ˆë‹¤.
    print("ğŸ”¥ Lifespan ì¢…ë£Œ: ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì¤‘...")
    # ì˜ˆ: ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° í•´ì œ, ìºì‹œ ì •ë¦¬, ëª¨ë¸ íŒŒì¼ ë©”ëª¨ë¦¬ì—ì„œ ì‚­ì œ ë“±
    # cleanup_global_models() # í•„ìš”í•œ ê²½ìš° ì •ë¦¬ í•¨ìˆ˜ë¥¼ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    print("ğŸ‘‹ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ.")
######################################


app = FastAPI(title="Model Inference API", lifespan=lifespan)

# CORS configuration for test
origins = [
    "*" 
]

app.add_middleware(
    CORSMiddleware,
    allow_origins=origins,
    allow_methods=["*"],
    allow_headers=["*"],
)

#router
api_router = APIRouter(prefix="/ai-api")
api_router.include_router(serving_controller_router, prefix="/serving")
#api_router.include_router(train_router, prefix="/train")
app.include_router(api_router)

#separatable Instance
control_router = APIRouter(prefix="/api")
control_router.include_router(controller_router, prefix="/controller")

app.include_router(control_router)





#health check line
@app.get("/")
def home():
    cuda_status = torch.cuda.is_available()
    return {
    "message": "FastAPIê°€ ì •ìƒ ì‘ë™ ì¤‘ì…ë‹ˆë‹¤!",
    "cuda_available": cuda_status  # boolean ê°’ ê·¸ëŒ€ë¡œ ì „ë‹¬
    }


#query test
@app.get("/items/{item_id}")
def read_item(item_id: int, q: str = None):
    return {"item_id": item_id, "query_param": q}



if __name__ == "__main__":
    uvicorn.run("main:app", host="127.0.0.1", port=5050, reload=True)