from typing import Any, Dict, List, Tuple
from fastapi import APIRouter
from pydantic import BaseModel
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
import random
import utils.vocab as vocab
from database import ProductInferenceVectors
from sqlalchemy.orm import Session
import copy
import random


# ItemTowerEmbedding(S1) * N -> save..DB -> stage2 (optimizer pass -> triplet)  

model_router = APIRouter()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# í•„ë“œ ìˆœì„œ ì •ì˜ (Field Embedding), ì„ì‹œ, data ë³´ê³  ê²°ì •
# key ìˆœì„œ == ì˜¤ëŠ” json ë°ì´íƒ€Load ìˆœì„œ
ALL_FIELD_KEYS = vocab.ORDERED_FEATURE_KEYS 
FIELD_TO_IDX = {k: i for i, k in enumerate(ALL_FIELD_KEYS)}
NUM_TOTAL_FIELDS = len(ALL_FIELD_KEYS)


class TrainingItem(BaseModel):

    product_id: int
    feature_data: Dict[str, Any]

# --- Global Configuration (ì „ì²´ ì‹œìŠ¤í…œì´ ì°¸ì¡°í•˜ëŠ” ê³µí†µ ì°¨ì›) ---
EMBED_DIM_CAT = 64 # Featureì˜ ì„ë² ë”© ì°¨ì› (Transformer d_model)
OUTPUT_DIM_TRIPLET = 128 # Stage 2 ìµœì¢… ì••ì¶• ì°¨ì›
OUTPUT_DIM_ITEM_TOWER = 128 # Stage 1 ìµœì¢… ì¶œë ¥ ì°¨ì› (Triplet Tower Input)
RE_MAX_CAPACITY = 500 # <<<<<<<<<<<< RE í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ í• ë‹¹
# ----------------------------------------------------------------------
# 1. Utility Modules (Shared for both Item Tower and Optimization Tower)
# ----------------------------------------------------------------------

# --- Residual Block (Corrected for Skip Connection) ---
class SEResidualBlock(nn.Module):

    def __init__(self, dim, dropout=0.2, expansion_factor=4):
        super().__init__()
        
        # 1. Feature Transformation (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜, SwiGLU ìŠ¤íƒ€ì¼ë¡œ í™•ì¥ ì œì•ˆ)
        # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì ì¸ ê¸°ì¡´ Linear ë°©ì‹ì„ ìœ ì§€í•˜ë˜ SEë¥¼ ì¶”ê°€í•¨
        self.block = nn.Sequential(
            nn.Linear(dim, dim * expansion_factor), # ë‚´ë¶€ í™•ì¥
            nn.LayerNorm(dim * expansion_factor),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * expansion_factor, dim), # ë‹¤ì‹œ ì••ì¶•
            nn.LayerNorm(dim),
        )
        
        # 2. SE-Block (Channel Attention, SE-Net êµ¬ì¡° ë°˜ì˜, Gating=Relu íŒŒíŠ¸)
        # ì…ë ¥ ë²¡í„°ì˜ ê° ì°¨ì›(feature)ì— ëŒ€í•´ ì¤‘ìš”ë„(0~1)ë¥¼ ê³„ì‚°
        self.se_block = nn.Sequential(
            nn.Linear(dim, dim // 4),  # Squeeze (ì •ë³´ ì••ì¶•)
            nn.ReLU(),
            nn.Linear(dim // 4, dim),  # Excitation (ì¤‘ìš”ë„ ë³µì›)
            nn.Sigmoid()               # 0~1 ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜
        )

        self.act = nn.GELU()
    
    def forward(self, x):
        residual = x
        
        # (A) Main Path
        out = self.block(x)
        
        # (B) SE-Attention Path
        # ë²¡í„°ì˜ ê¸€ë¡œë²Œ ì •ë³´ë¥¼ ë³´ê³ , ì–´ë–¤ ì°¨ì›ì„ ê°•ì¡°í• ì§€ ê²°ì •
        # MLP ì¶œë ¥ê°’(out)ì— ì¤‘ìš”ë„(weight)ë¥¼ ê³±í•¨
        weight = self.se_block(out)
        out = out * weight 
        
        # (C) Residual Connection
        return self.act(residual + out)




# --- Deep Residual Head (Pyramid Funnel) ---
class DeepResidualHead(nn.Module):
    """
    [Architecture]
    Input(64) -> [Expand 2x] -> 128 -> [Expand 2x] -> 256 
    -> [Deep Interaction (SE-ResBlock)] -> 256 
    -> [Compression] -> Output(128)
    + Global Skip Connection
    """
    def __init__(self, input_dim, output_dim=128):
        super().__init__()
        
        # ì°¨ì› ì •ì˜ (64 -> 128 -> 256)
        mid_dim = input_dim * 2      # 128
        hidden_dim = input_dim * 4   # 256
        
        # 1. Progressive Expansion 
        self.expand_layer1 = nn.Sequential(
            nn.Linear(input_dim, mid_dim),  # 64 -> 128
            nn.LayerNorm(mid_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        self.expand_layer2 = nn.Sequential(
            nn.Linear(mid_dim, hidden_dim), # 128 -> 256
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        # 2. Deep Interaction (Peak Dimensionì—ì„œ ìˆ˜í–‰)
        # ê°€ì¥ ì°¨ì›ì´ ë†’ì€ 256 ìƒíƒœì—ì„œ SE-Blockìœ¼ë¡œ ì •ë°€í•œ íŠ¹ì§• ì¶”ì¶œ ìˆ˜í–‰
        self.res_blocks = nn.Sequential(
            SEResidualBlock(hidden_dim, dropout=0.2), # 256 ìœ ì§€
            SEResidualBlock(hidden_dim, dropout=0.2)  # 256 ìœ ì§€
        )
        
        # 3. Final Projection (Compression)
        # 256 -> 128 ë¡œ ì••ì¶•í•˜ì—¬ ìµœì¢… ì„ë² ë”© ìƒì„±
        self.final_proj = nn.Linear(hidden_dim, output_dim)
        
        # 4. Global Skip Connection (Input Shortcut) ResNet ì”ì°¨
        self.input_skip = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        # --- [Step 1] Progressive Expansion ---
        m = self.expand_layer1(x)  # 64 -> 128
        h = self.expand_layer2(m)  # 128 -> 256
        
        # --- [Step 2] Feature Interaction (SE-Attention) ---
        h = self.res_blocks(h)     # 256 -> 256
        
        # --- [Step 3] Compression ---
        main_out = self.final_proj(h) # 256 -> 128
        
        # --- [Step 4] Global Shortcut ---
        skip_out = self.input_skip(x) # 64 -> 128
        
        return main_out + skip_out
    
    
# ----------------------------------------------------------------------
# 3. Main Model: CoarseToFineItemTower (Stage 1)
# ----------------------------------------------------------------------
class CoarseToFineItemTower(nn.Module):
    """
    [Item Tower - Residual Field Embedding Ver.]
    TabTransformerì˜ ì•„ì´ë””ì–´ë¥¼ ì‘ìš©í•˜ì—¬, STDì™€ REë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ í†µí•©í•˜ê³ 
    ê³„ì¸µì  ì”ì°¨ ì—°ê²°(Inheritance)ì„ í†µí•´ í•™ìŠµ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•œ êµ¬ì¡°.
    """
    def __init__(self, 
                 embed_dim=EMBED_DIM_CAT,     # 64
                 nhead=4, 
                 num_layers=2,                # TabTransformerëŠ” ì–•ì•„ë„ ì¶©ë¶„í•¨
                 max_fields=50,               # ì˜ˆìƒë˜ëŠ” ìµœëŒ€ í•„ë“œ(ì»¬ëŸ¼) ê°œìˆ˜
                 output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. Vocab Size ê°€ì ¸ì˜¤ê¸°
        std_vocab_size, _ = vocab.get_vocab_sizes()
        
        # 2. Embeddings
        # A. STD Value Embedding (Base) , RE Value Embedding (Delta / Child)
        self.std_embedding = nn.Embedding(std_vocab_size, embed_dim, padding_idx=vocab.PAD_ID)
        # self.re_embedding = nn.Embedding(RE_MAX_CAPACITY, embed_dim, padding_idx=vocab.PAD_ID)
        self.re_token_embedding = nn.Embedding(vocab.RE_VOCAB_SIZE, embed_dim, padding_idx=vocab.RE_TOKENIZER.pad_token_id)
        # REëŠ” Delta(ì°¨ì´ì )ë§Œ í•™ìŠµí•˜ë¯€ë¡œ 0 ê·¼ì²˜ ì´ˆê¸°í™” (í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±)
        nn.init.normal_(self.re_token_embedding.weight, mean=0.0, std=0.01)

        # C. Field Embedding (Shared Key)
        # ê° ì»¬ëŸ¼(Color, Brand ë“±)ì˜ ì—­í• ì„ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”©
        self.field_embedding = nn.Parameter(torch.randn(1, max_fields, embed_dim))
        
        # 3. Unified Transformer Encoder
        # STDì™€ REê°€ í•œ ê³µê°„ì—ì„œ ìƒí˜¸ì‘ìš© (Self-Attn ì‚¬ìš©)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=nhead, 
            dim_feedforward=embed_dim * 4,
            batch_first=True,
            dropout=0.1,
            activation='gelu'
            #,norm_first=True # ìµœì‹  íŠ¸ë Œë“œ (ì•ˆì •ì  ìˆ˜ë ´)
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # 4. Projection Head
        # ì…ë ¥ ì°¨ì›: (STDí•„ë“œìˆ˜ + REí•„ë“œìˆ˜) * embed_dim -> Flatten í›„ ì••ì¶•
        self.head = DeepResidualHead(input_dim=embed_dim, output_dim=output_dim) 
        
    # $$Input Sequence = [\underbrace{Token_A}_{STDìë¦¬}, \underbrace{Token_B}_{RE(ì”ì°¨)ìë¦¬}]$$

    def forward(self, std_input: torch.Tensor, re_input: torch.Tensor) -> torch.Tensor:
        """
        std_input: (Batch, Num_Fields) - ì˜ˆ: [Color_ID, Category_ID, ...]
        re_input:  (Batch, Num_Fields) - ì˜ˆ: [MatteBlack_ID, 0, ...] (ìˆœì„œê°€ STDì™€ ëŒ€ì‘ë˜ì–´ì•¼ í•¨)
        """
        B, num_fields = std_input.shape
        
        # --- [Logic 1] Hierarchical Embedding Construction ---
        
        # (A) Field Embedding (Broadcasting)
        # í˜„ì¬ ë°°ì¹˜ì˜ í•„ë“œ ê°œìˆ˜ë§Œí¼ ìë¦„ (í˜¹ì‹œ ëª¨ë¥¼ ê°€ë³€ ê¸¸ì´ì— ëŒ€ë¹„)
        field_emb = self.field_embedding[:, :num_fields, :] # (1, F, D)
        
        # (B) STD (Parent)
        std_val = self.std_embedding(std_input) # (B, F, D)
        std_token = std_val + field_emb
        
        re_tokens = self.re_token_embedding(re_input)
        re_mask = (re_input != vocab.RE_TOKENIZER.pad_token_id).float().unsqueeze(-1) # (B, F, S, 1)
        
        # 3. Sum / Count (ìœ íš¨ í† í° ê°œìˆ˜ë¡œ ë‚˜ëˆ„ê¸°)
        sum_re = torch.sum(re_tokens * re_mask, dim=2) # (B, F, D)
        count_re = torch.clamp(re_mask.sum(dim=2), min=1e-9) # (B, F, 1)
        
    
        # (C) RE (Child = Delta + Parent + Field)
        re_delta = sum_re / count_re # (B, F, D) -> í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•ë¨!
        
    
        # re_delta = self.re_embedding(re_input) # (B, F, D)
        
        # * í•µì‹¬: REê°€ 0(PAD)ì´ì–´ë„ std_val + field_embê°€ ë‚¨ì•„ì„œ 'Parent' ì—­í• ì„ ìˆ˜í–‰í•¨
        # * detach(): REì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ STD ì„ë² ë”©ì„ ë§ê°€ëœ¨ë¦¬ì§€ ì•Šë„ë¡ ì°¨ë‹¨
        re_token = re_delta + std_val.detach() + field_emb
        
        # --- [Logic 2] Unified Sequence ---
        combined_seq = torch.cat([std_token, re_token], dim=1)
        
        # Mask ìƒì„±
        # 1. STD, REê°€ ìœ íš¨í•œê°€?
        std_valid = (std_input != vocab.PAD_ID)
        re_valid = (re_input != vocab.RE_TOKENIZER.pad_token_id).any(dim=2)

        mask_part_std = std_valid
        mask_part_re = re_valid | std_valid

        full_mask = torch.cat([mask_part_std, mask_part_re], dim=1) # (B, 2*F)

        # ì´í›„ Transformerì— ì „ë‹¬
        context_out = self.transformer(combined_seq, src_key_padding_mask=~full_mask)

        # [Smart Pooling] íŒ¨ë”© ì œì™¸ í‰ê· 
        mask_expanded = full_mask.unsqueeze(-1).float() # (B, 2*F, 1)
        sum_embeddings = torch.sum(context_out * mask_expanded, dim=1)
        sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9) # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        
        pooled = sum_embeddings / sum_mask
        
        return self.head(pooled)
    
# ----------------------------------------------------------------------
# 4. OptimizedItemTower (Stage 2 Adapter - Triplet Training)
#    Projection Head --> Contrastive Loss(Opt.z) / Representation(Encoder)
# ----------------------------------------------------------------------

class OptimizedItemTower(nn.Module):
    """
    [Optimization Tower]: Projection Head, Distance/metric Learningìš©
    """
    def __init__(self, input_dim=OUTPUT_DIM_ITEM_TOWER, output_dim=OUTPUT_DIM_TRIPLET):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.LayerNorm(input_dim),
            nn.GELU(), #nn.GELU(), 
            nn.Linear(input_dim, output_dim),
        )
        
    def forward(self, x):
        # [Log 1] ì…ë ¥ ë°ì´í„° í™•ì¸
        if not self.training: 
            print(f"\n  [Model Internal] Input Vector Shape: {x.shape}")
            print(f"  [Model Internal] Input Sample (First 5): {x[0, :5].detach().cpu().numpy()}")

        # ë ˆì´ì–´ í†µê³¼
        x = self.layer(x)
        
        # ì •ê·œí™” (L2 Normalization)
    
        return F.normalize(x, p=2, dim=1)




# x = F.normalize(x, p=2, dim=1) ì‹¤ì œ ì¶”ë¡ ë–„ëŠ” hìª½ model loadí•˜ì—¬ ì“°ì. (same d)

'''

êµ¬ì¡°: Encoder -> Embedding(h) -> MLP Layer(Projection Head) -> Output(z) -> Loss

ì›ë¦¬: z ê³µê°„ì—ì„œëŠ” Contrastive Lossì— ì˜í•´ ë°ì´í„°ê°€ êµ¬ì²´ í‘œë©´ìœ¼ë¡œ ì°Œê·¸ëŸ¬ì§€ë©° ì •ë³´ ì†ì‹¤
ë°˜ë©´ ê·¸ ì „ ë‹¨ê³„ì¸ hëŠ” ë°ì´í„°ì˜ ì›ë³¸ ì •ë³´ë¥¼ ìƒëŒ€ì  ë³´ì¡´

í•™ìŠµí•  ë•Œ: Projection Headë¥¼ ë¶™ì—¬ì„œ z ê°’ìœ¼ë¡œ Loss ê³„ì‚°.

ì„œë¹™í•  ë•Œ: Projection Headë¥¼ ë–¼ì–´ë²„ë¦¬ê³  h ê°’ì„ ì‚¬ìš©.

íš¨ê³¼: ì´ë ‡ê²Œ í•˜ë©´ Representation Qualityê°€ 10~15% í–¥ìƒ data

'''


    
# ----------------------------------------------------------------------
# 5. Dataset & Sampler & Training Function (Stage 2 Logic) / first INPUT from DB
# ----------------------------------------------------------------------


class SimCSEModelWrapper(nn.Module):
    def __init__(self, encoder, projector):
        super().__init__()
        self.encoder = encoder      # ì´ê²ƒì´ CoarseToFineItemTower
        self.projector = projector  # ì´ê²ƒì´ OptimizedItemTower


    def forward(self, t_std, t_re):
        # 1. ë°›ì€ 2ê°œ ì¸ìë¥¼ encoderì—ê²Œ ê·¸ëŒ€ë¡œ í† ìŠ¤
        enc_out = self.encoder(t_std, t_re) 
        
        # 2. ê·¸ ê²°ê³¼ë¥¼ projectorì—ê²Œ í† ìŠ¤
        return self.projector(enc_out)

class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def _apply_dropout_and_convert(self, product: TrainingItem):
        """
        1. Feature Dropout ìˆ˜í–‰
        2. Dictionary -> Fixed Size Tensor ë³€í™˜ (Hashing í¬í•¨)
        """
        # (1) Dropout Logic
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ (Shallow copy of dict structure is enough usually, but deep for safety)
        feat_data = copy.deepcopy(product.feature_data)
        
        clothes = feat_data.get("clothes", {})
        reinforced = feat_data.get("reinforced_feature_value", {})
        
        # Random Dropout (Key ì‚­ì œ)
        if self.dropout_prob > 0:
            for k in list(clothes.keys()):
                if random.random() < self.dropout_prob:
                    del clothes[k]
            for k in list(reinforced.keys()):
                if random.random() < self.dropout_prob:
                    del reinforced[k]

        # (2) Tensor Conversion Logic (Alignment)
        std_ids = []
        re_ids = []
        debug_output = {}
        # ë¯¸ë¦¬ ì •ì˜ëœ ALL_FIELD_KEYS ìˆœì„œëŒ€ë¡œ ìˆœíšŒí•˜ë©° ID ì¶”ì¶œ
        for idx, key in enumerate(ALL_FIELD_KEYS):
            # A. STD ID ì¶”ì¶œ
            std_val = clothes.get(key) # ì—†ìœ¼ë©´ None
            # Noneì´ë©´ MockVocab ë‚´ë¶€ì—ì„œ PAD_ID(0) ë°˜í™˜
            s_id = vocab.get_std_id(key, std_val) 
            std_ids.append(s_id)
            
            # B. RE ID ì¶”ì¶œ (Hashing)
            # RE ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ìˆ˜ ìˆìŒ (["Matte Black"]) -> ì²«ë²ˆì§¸ ê°’ ì‚¬ìš©
            re_val_list = reinforced.get(key)
            re_val = None
            if re_val_list and isinstance(re_val_list, list) and len(re_val_list) > 0:
                re_val = re_val_list[0]
            elif isinstance(re_val_list, str):
                re_val = re_val_list
            
            # Hashing í•¨ìˆ˜ í˜¸ì¶œ (ì €ì¥ X)
            r_id = vocab.get_re_hash_id(re_val)
            re_ids.append(r_id)
            
            # --- ë””ë²„ê·¸ ë¡œê·¸ ê¸°ë¡ ---
            if idx < 3: # ì²˜ìŒ 3ê°œ í•„ë“œë§Œ ê¸°ë¡
                debug_output[key] = {
                    "STD_Val": std_val,
                    "STD_ID": s_id,
                    "RE_Val": re_val,
                    "RE_ID_Hash": r_id
                }

        # --- ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ë°°ì¹˜ì—ì„œ ì²« ë²ˆì§¸ ì•„ì´í…œë§Œ ê°€ì •í•˜ê³  ì¶œë ¥) ---
        if product.product_id == self.products[0].product_id: # ì²« ë²ˆì§¸ ìƒí’ˆì— ëŒ€í•´ì„œë§Œ ì¶œë ¥ (ì „ì²´ ìƒí’ˆ ì¶œë ¥í•˜ë©´ ë„ˆë¬´ ê¸¸ì–´ì§)
            print("\n[DATASET DEBUG] Feature Extraction & Hashing Check:")
            for k, v in debug_output.items():
                print(f"  > Key: {k.upper()} | STD Val: '{v['STD_Val']}' -> ID {v['STD_ID']} | RE Val: '{v['RE_Val']}' -> ID {v['RE_ID_Hash']}")
            print(f"  > Final Tensors Length: STD={len(std_ids)}, RE={len(re_ids)} (Should be {len(ALL_FIELD_KEYS)})")
        # -------------------------------------------------------------
            
        return torch.tensor(std_ids, dtype=torch.long), torch.tensor(re_ids, dtype=torch.long)

    def __getitem__(self, idx):
        item = self.products[idx]
        
        # Contrastive Learningì„ ìœ„í•œ 2ê°œì˜ View ìƒì„±
        # ê°ê° ì„œë¡œ ë‹¤ë¥¸ Dropoutì´ ì ìš©ë¨
        v1_std, v1_re = self._apply_dropout_and_convert(item)
        v2_std, v2_re = self._apply_dropout_and_convert(item)
        
        return (v1_std, v1_re), (v2_std, v2_re)






''' 
class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def input_feature_dropout(self, product: TrainingItem) -> TrainingItem:
        """
        [Augmentation Logic]
        JSON êµ¬ì¡°("clothes", "reinforced_feature_value")ì— ë§ì¶°
        ëœë¤í•˜ê²Œ ì†ì„±(Key-Value)ì„ ì œê±°í•©ë‹ˆë‹¤.
        """
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ Deep Copy (ë§¤ìš° ì¤‘ìš”)
        aug_p = copy.deepcopy(product)
        
        feature_dict = aug_p.feature_data
        
        # 1. Standard Features (clothes) Dropout
   
        clothes_data = feature_dict.get("clothes")
        if clothes_data:
            keys = list(clothes_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del clothes_data[k]
        
        # 2. Reinforced Features Dropout
  
        re_data = feature_dict.get("reinforced_feature_value")
        if re_data:
            keys = list(re_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del re_data[k]
                    
        return aug_p
    def __getitem__(self, idx):
        raw_product = self.products[idx]
        
        # SimCSE: ê°™ì€ ìƒí’ˆì„ ë‘ ë²ˆ ë³€í˜•í•´ì„œ (View1, View2) ìƒì„±
        view1 = self.input_feature_dropout(raw_product)
        view2 = self.input_feature_dropout(raw_product)
        
        return view1, view2
'''


    
# ----------------------------------------------------------------------
# 6. userTowerClass
#     
# ----------------------------------------------------------------------


def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [ê¸°ëŠ¥]
    1. DBì—ì„œ (product_id, vector) ìŒì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
    2. DB ID -> Model Index ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3. User Towerì˜ Embedding Layerì— ë„£ì„ Weight Matrixë¥¼ ë§Œë“­ë‹ˆë‹¤.
    
    [Return]
    - embedding_matrix: (Num_Products + 1, 128) - 0ë²ˆì€ Padding
    - id_map: {real_db_id: model_index}
    """
    print("â³ Fetching product vectors from DB...")
    
    # 1. DB Query (IDì™€ Serving Vectorë§Œ ê°€ì ¸ì˜´)
    # vector_servingì´ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìµœì¢… ì•„ì´í…œ ë²¡í„°ë¼ê³  ê°€ì •
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_serving
    ).filter(
        ProductInferenceVectors.vector_serving.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128 # ê³ ì • ì°¨ì›
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    id_map = {} # Real ID -> Model Index

    # 3. ë§¤í•‘ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listëŠ” DBì—ì„œ List[float] í˜•íƒœë¡œ ì˜¨ë‹¤ê³  ê°€ì •
        if vector_list is None: continue
            
        # ë§¤í•‘ ì €ì¥
        id_map[real_id] = idx 
        
        # í…ì„œì— ê°’ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print("âœ… Pretrained Embedding Matrix Created.")
    print(f"   Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map

class SymmetricUserTower(nn.Module):
    def __init__(self, 
                 num_total_products: int,    # DBì— ìˆëŠ” ì´ ìƒí’ˆ ê°œìˆ˜ (Padding ì œì™¸)
                 max_seq_len: int = 50,
                 input_dim: int = 128,       # Item Vector ì°¨ì›
                 d_model: int = 128,
                 nhead: int = 4,
                 num_layers: int = 2,
                 dropout: float = 0.1):
        super().__init__()
        
        self.max_seq_len = max_seq_len
        
        # --- 1. Embeddings ---
        
        # (A) Item Lookup Table (Pre-trained)
        # num_embeddings = ìƒí’ˆê°œìˆ˜ + 1 (for Padding Index 0)
        self.item_embedding = nn.Embedding(num_total_products + 1, input_dim, padding_idx=0)
        
        # (B) Positional Embedding
        self.position_embedding = nn.Embedding(max_seq_len + 1, d_model)
        
        # (C) User Profile (ì˜ˆì‹œ)
        self.gender_emb = nn.Embedding(3, 16, padding_idx=0)
        self.age_emb = nn.Embedding(10, 16, padding_idx=0)
        self.profile_projector = nn.Sequential(
            nn.Linear(16 + 16, d_model),
            nn.LayerNorm(d_model),
            nn.GELU()
        )

        # --- 2. Encoder ---
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,
            batch_first=True, dropout=dropout, activation='gelu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # --- 3. Head ---
        self.encoder_head = DeepResidualHead(input_dim=d_model, output_dim=d_model)
        
        # [Stage 2 ì˜ì—­: Projection & Matching]

        self.projector = nn.Sequential(
            nn.Linear(128, 128),
            nn.LayerNorm(128),
            nn.GELU(),
            nn.Linear(128, 128)
        )

    def load_pretrained_weights(self, pretrained_matrix: torch.Tensor, freeze: bool = True):
        """
        [í•µì‹¬ ë¡œì§] DBì—ì„œ ê°€ì ¸ì˜¨ ë²¡í„°ë¥¼ ì„ë² ë”© ë ˆì´ì–´ì— ë®ì–´ì”Œì›ë‹ˆë‹¤.
        """
        # ì°¨ì› ê²€ì‚¬
        if self.item_embedding.weight.shape != pretrained_matrix.shape:
            raise ValueError(f"Shape Mismatch! Model: {self.item_embedding.weight.shape}, DB: {pretrained_matrix.shape}")
            
        # 1. ê°€ì¤‘ì¹˜ ë³µì‚¬ (Copy)
        self.item_embedding.weight.data.copy_(pretrained_matrix)
        print("âœ… Pretrained Item Vectors Loaded into User Tower.")
        
        # 2. ê°€ì¤‘ì¹˜ ë™ê²° (Freeze) - ì•„ì´í…œ ë²¡í„°ëŠ” ë” ì´ìƒ í•™ìŠµë˜ì§€ ì•ŠìŒ (ì¼ë°˜ì )
        if freeze:
            self.item_embedding.weight.requires_grad = False
            print("â„ï¸ Item Embeddings are FROZEN (Not trainable).")
        else:
            print("ğŸ”¥ Item Embeddings are TRAINABLE (Fine-tuning mode).")

    def forward(self, history_ids, profile_data):
        # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼: history_idsëŠ” ë§¤í•‘ëœ Model Indexì—¬ì•¼ í•¨) ...
        B, L = history_ids.shape
        device = history_ids.device
        
        # (A) Lookup -> (B, L, 128) : ì—¬ê¸°ì„œ DB ë²¡í„°ê°€ íŠ€ì–´ë‚˜ì˜´
        seq_emb = self.item_embedding(history_ids)
        
        # ... (ì´í•˜ ë™ì¼: Positional ë”í•˜ê³  Transformer í†µê³¼) ...
        positions = torch.arange(L, device=device).unsqueeze(0).expand(B, L)
        pos_emb = self.position_embedding(positions)
        seq_emb = seq_emb + pos_emb
        
        # Profile
        g_emb = self.gender_emb(profile_data.get('gender', torch.zeros(B, dtype=torch.long, device=device)))
        a_emb = self.age_emb(profile_data.get('age', torch.zeros(B, dtype=torch.long, device=device)))
        profile_feat = torch.cat([g_emb, a_emb], dim=1)
        user_token = self.profile_projector(profile_feat).unsqueeze(1)
        
        combined_seq = torch.cat([user_token, seq_emb], dim=1)
        
        key_padding_mask = (history_ids == 0)
        user_token_mask = torch.zeros((B, 1), dtype=torch.bool, device=device)
        combined_mask = torch.cat([user_token_mask, key_padding_mask], dim=1)
        
        output = self.transformer(combined_seq, src_key_padding_mask=combined_mask)
        user_vector = output[:, 0, :]
        
        user_rep = self.encoder_head(user_vector)
        user_final = self.projector(user_rep)
        
        # cos í•˜ë ¤ë©´ loadí•œ ì•„ì´í…œ ë²¡í„°(v=1)ì´ë‘ ë§ì¶°ì•¼í•˜ë‹ˆê¹Œ. ì´ê±°ê¸°ì¤€ìœ¼ë¡œ tower í•™ìŠµ?
        return F.normalize(user_final, p=2, dim=1)

class TwoTowerRecSys(nn.Module):
    """
    [User Tower + Item Tower]
    ì‹¤ì œ ì„œë¹„ìŠ¤(Retrieval)ë¥¼ ìœ„í•œ ì™„ì „ì²´ ëª¨ë¸
    """
    def __init__(self, 
                 item_tower: CoarseToFineItemTower, 
                 user_tower: SymmetricUserTower):
        super().__init__()
        self.item_tower = item_tower
        self.user_tower = user_tower
        
    def forward(self, 
                # Item Inputs
                std_input, re_input, 
                # User Inputs
                history_ids, profile_data):
        
        # 1. Item Vector ìƒì„± (Target Item)
        # (B, 128)
        target_item_vec = self.item_tower(std_input, re_input)
        
        # 2. User Vector ìƒì„±
        # (B, 128)
        user_vec = self.user_tower(history_ids, profile_data)
        
        # 3. Score Calculation (Dot Product)
        # (B, 128) * (B, 128) -> (B,) sum
        # í•™ìŠµ ì‹œì—ëŠ” ë³´í†µ In-batch Negative ë“±ì„ ì‚¬ìš©í•˜ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ë‘ ë²¡í„°ë¥¼ ë¦¬í„´í•˜ê±°ë‚˜, ìœ ì‚¬ë„ë¥¼ ë¦¬í„´
        return user_vec, target_item_vec