from typing import List, Union
from sqlalchemy import select
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Sampler
from pytorch_metric_learning import losses, miners, distances
from collections import defaultdict
import random
import os
import numpy as np
import math
import vocab
from database import ProductInput,ProductFeature, SessionLocal
from .APIController import serving_controller 
from sqlalchemy.orm import Session
import copy
import random
from tqdm import tqdm

# ItemTowerEmbedding(S1) * N -> save..DB -> stage2 (optimizer pass -> triplet)  


DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# --- Global Configuration (ì „ì²´ ì‹œìŠ¤í…œì´ ì°¸ì¡°í•˜ëŠ” ê³µí†µ ì°¨ì›) ---
EMBED_DIM_CAT = 64 # Featureì˜ ì„ë² ë”© ì°¨ì› (Transformer d_model)
OUTPUT_DIM_TRIPLET = 128 # Stage 2 ìµœì¢… ì••ì¶• ì°¨ì›
OUTPUT_DIM_ITEM_TOWER = 128 # Stage 1 ìµœì¢… ì¶œë ¥ ì°¨ì› (Triplet Tower Input)
RE_MAX_CAPACITY = 50000 # <<<<<<<<<<<< RE í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ í• ë‹¹
# ----------------------------------------------------------------------
# 1. Utility Modules (Shared for both Item Tower and Optimization Tower)
# ----------------------------------------------------------------------

# --- Residual Block (Corrected for Skip Connection) ---
class ResidualBlock(nn.Module):

    def __init__(self, dim, dropout=0.2):
        super().__init__()
        # ë¸”ë¡ ë‚´ì—ì„œ ì°¨ì›ì„ ìœ ì§€í•˜ëŠ” 2ê°œì˜ Linear Layer (Skip Connection ì „ ì²˜ë¦¬)
        self.block = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )
        self.relu = nn.ReLU()

    def forward(self, x):
        residual = x
        out = self.block(x)
        # x + block(x) -> ì”ì°¨ ì—°ê²° (í•µì‹¬!)
        return self.relu(residual + out)

# --- Deep Residual Head (Pyramid Funnel) ---
class DeepResidualHead(nn.Module):
    """
    Categorical Vector(64d) -> 256 -> 128
    """
    def __init__(self, input_dim, output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. ë‚´ë¶€ í™•ì¥ (Expansion): í‘œí˜„ë ¥ì„ ìœ„í•´ 4ë°° í™•ì¥ì€ ìœ ì§€ (64 -> 256)
        hidden_dim = input_dim * 4 
        
        self.expand = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        # 2. Deep Interaction (ResBlocks): 256ì°¨ì›ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        self.res_blocks = nn.Sequential(
            ResidualBlock(hidden_dim), # 256 ìœ ì§€
            ResidualBlock(hidden_dim)  # 256 ìœ ì§€
        )
        
        # 3. Projection (Compression): ë°”ë¡œ ëª©í‘œ ì°¨ì›(128)ìœ¼ë¡œ ì••ì¶•
        self.project = nn.Linear(hidden_dim, output_dim) 
        
    def forward(self, x):
        x = self.expand(x)      # 64 -> 256
        x = self.res_blocks(x)  # 256 -> 256 (Deep Feature Extraction)
        x = self.project(x)     # 256 -> 128 (Final Output)
        return x
 
# ----------------------------------------------------------------------
# 3. Main Model: CoarseToFineItemTower (Stage 1)
# ----------------------------------------------------------------------
class CoarseToFineItemTower(nn.Module):
    """
    [Item Tower]: Standard/Reinforced í”¼ì³ë¥¼ ìœµí•©í•˜ê³  512ì°¨ì› ë²¡í„° ìƒì„±.
    vocab.pyì˜ ì´ì¤‘ ì–´íœ˜ êµ¬ì¡°ì™€ í˜¸í™˜ë˜ë„ë¡ ìˆ˜ì •ë˜ì—ˆìŠµë‹ˆë‹¤.
    """
    def __init__(self, embed_dim=EMBED_DIM_CAT, nhead=4, output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. vocab.pyì—ì„œ STDì™€ REì˜ ë¶„ë¦¬ëœ ì–´íœ˜ í¬ê¸°ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
        std_vocab_size, re_vocab_size = vocab.get_vocab_sizes()
        
        # A. Dual Embedding (64d)
        # ë‹¨ì¼ ì„ë² ë”© ëŒ€ì‹ , ë¶„ë¦¬ëœ ì–´íœ˜ í¬ê¸°ë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.
        self.std_embedding = nn.Embedding(std_vocab_size, embed_dim, padding_idx=vocab.PAD_ID)
        self.re_embedding = nn.Embedding(RE_MAX_CAPACITY, embed_dim, padding_idx=vocab.PAD_ID)
        # B. Self-Attention Encoders (d_model=64)
        encoder_layer = nn.TransformerEncoderLayer(d_model=embed_dim, nhead=nhead, batch_first=True)
        self.std_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)
        self.re_encoder = nn.TransformerEncoder(encoder_layer, num_layers=1)
        
        # C. Cross-Attention (d_model=64, nhead=4)
        # ì´ ë ˆì´ì–´ëŠ” Q=STD, K/V=REë¡œ ì‚¬ìš©ë  ê²ƒì…ë‹ˆë‹¤.
        # (ìˆ˜ì •ë¨) Shape Vector (128d)ê°€ ì œê±°ë˜ì–´ ì…ë ¥ì€ 64dê°€ ë¨.
        self.cross_attn = nn.MultiheadAttention(embed_dim, nhead, batch_first=True)
        self.layer_norm = nn.LayerNorm(embed_dim)
        
        # D. Deep Residual Head (ì…ë ¥ ì°¨ì›: embed_dim = 64)
        head_input_dim = embed_dim
        self.head = DeepResidualHead(input_dim=head_input_dim, output_dim=output_dim)

    def forward(self, std_input: torch.Tensor, re_input: torch.Tensor) -> torch.Tensor:
        # 1. ì„ë² ë”© (STDì™€ RE ë¶„ë¦¬ ì²˜ë¦¬)
        std_embed = self.std_embedding(std_input)
        re_embed = self.re_embedding(re_input)
        
        # 2. Self-Attention Encoders
        std_output = self.std_encoder(std_embed) # Shape: (B, L_std, D)
        re_output = self.re_encoder(re_embed)   # Shape: (B, L_re, D)
        
        # 3. Cross-Attention (STD(Q)ê°€ RE(K/V)ë¥¼ ì°¸ì¡°)
        # Query: STD (ìš°ë¦¬ê°€ ë” ì¤‘ìš”í•˜ë‹¤ê³  ê°€ì •í•˜ëŠ” ê¸°ë³¸ì ì¸ ìƒí’ˆ ì •ë³´)
        # Key/Value: RE (ì„ íƒì ìœ¼ë¡œ ë³´ê°•í•  ì„¸ë¶€ ì •ë³´)
        
        # query, key, value ì¸ìë¥¼ ëª…ì‹œì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        attn_output, _ = self.cross_attn(
            query=std_output,  
            key=re_output,     
            value=re_output,   
            need_weights=False
        )
        
        # 4. ì”ì°¨ ì—°ê²°(Residual Connection) ë° Layer Normalization
        # STDì˜ ì›ë³¸ ì •ë³´ì— REë¡œë¶€í„° ì¶”ì¶œëœ ê°•í™” ì •ë³´(attn_output)ë¥¼ ë”í•©ë‹ˆë‹¤.
        fused_output = self.layer_norm(std_output + attn_output)
        
        # 5. í’€ë§ (Sequence -> Vector)
        # ìµœì¢…ì ìœ¼ë¡œ Item ì„ë² ë”©ì„ ì–»ê¸° ìœ„í•´ í‰ê·  í’€ë§ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.
        # Shape: (B, D)

        
        pooled_output = fused_output.mean(dim=1) 

        ## 5. Shape Fusion Logic (ì œê±°ë¨)
        # v_fused = torch.cat([v_final, shape_vecs], dim=1) # ì´ ì½”ë“œê°€ ì œê±°ë¨.
        
        # 6. Deep Residual Head
        # Deep Head Pass (I : 64 -> O : 128)
        final_vector = self.head(pooled_output)
        
        return final_vector
    

# ----------------------------------------------------------------------
# 4. OptimizedItemTower (Stage 2 Adapter - Triplet Training)
# ----------------------------------------------------------------------

class OptimizedItemTower(nn.Module):
    """
    [Optimization Tower]: Stage 1ì˜ vector non-liner
    """
    def __init__(self, input_dim=OUTPUT_DIM_ITEM_TOWER, output_dim=OUTPUT_DIM_TRIPLET):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.LayerNorm(input_dim),
            nn.ReLU(),
            nn.Linear(input_dim, output_dim),
        )
        
    def forward(self, x):
        # [Log 1] ì…ë ¥ ë°ì´í„° í™•ì¸
        if not self.training: # ì¶”ë¡ (eval) ëª¨ë“œì¼ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥ (í•™ìŠµ ë• ë„ˆë¬´ ë§ìŒ)
            print(f"\n  [Model Internal] Input Vector Shape: {x.shape}")
            print(f"  [Model Internal] Input Sample (First 5): {x[0, :5].detach().cpu().numpy()}")

        # ë ˆì´ì–´ í†µê³¼
        x = self.layer(x)
        
        # ì •ê·œí™” (L2 Normalization)
        x = F.normalize(x, p=2, dim=1)
        
        # [Log 3] ì •ê·œí™” í™•ì¸ (Normì´ 1.0ì— ê°€ê¹Œìš´ì§€)
        if not self.training:
            norm_check = torch.norm(x, p=2, dim=1).mean().item()
            print(f"  [Model Internal] Output Normalized Shape: {x.shape} | Avg Norm: {norm_check:.4f} (Expected ~1.0)")
            
        return x
    
    
# ----------------------------------------------------------------------
# 5. Dataset & Sampler & Training Function (Stage 2 Logic) / first INPUT from DB
# ----------------------------------------------------------------------


class SimCSEModelWrapper(nn.Module):
    def __init__(self, encoder, projector):
        super().__init__()
        self.encoder = encoder      # ì´ê²ƒì´ CoarseToFineItemTower
        self.projector = projector  # ì´ê²ƒì´ OptimizedItemTower


    def forward(self, t_std, t_re):
        # 1. ë°›ì€ 2ê°œ ì¸ìë¥¼ encoderì—ê²Œ ê·¸ëŒ€ë¡œ í† ìŠ¤
        enc_out = self.encoder(t_std, t_re) 
        
        # 2. ê·¸ ê²°ê³¼ë¥¼ projectorì—ê²Œ í† ìŠ¤
        return self.projector(enc_out)


class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[ProductInput], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def input_feature_dropout(self, product: ProductInput) -> ProductInput:
        """
        [Augmentation Logic]
        JSON êµ¬ì¡°("clothes", "reinforced_feature_value")ì— ë§ì¶°
        ëœë¤í•˜ê²Œ ì†ì„±(Key-Value)ì„ ì œê±°í•©ë‹ˆë‹¤.
        """
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ Deep Copy (ë§¤ìš° ì¤‘ìš”)
        aug_p = copy.deepcopy(product)
        
        # 1. Standard Features (clothes) Dropout
        # ì˜ˆ: "top.neck_color_design" í‚¤ë¥¼ ì‚­ì œí•˜ì—¬ ëª¨ë¸ì´ ë‹¤ë¥¸ ì†ì„±(ì†Œì¬, í•)ì„ ë³´ê²Œ í•¨
        if aug_p.clothes:
            keys = list(aug_p.clothes.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del aug_p.clothes[k]
        
        # 2. Reinforced Features Dropout
        # ì˜ˆ: "specification.metadata" ì‚­ì œ
        if aug_p.reinforced_feature_value:
            keys = list(aug_p.reinforced_feature_value.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del aug_p.reinforced_feature_value[k]
                
        return aug_p

    def __getitem__(self, idx):
        raw_product = self.products[idx]
        
        # SimCSE: ê°™ì€ ìƒí’ˆì„ ë‘ ë²ˆ ë³€í˜•í•´ì„œ (View1, View2) ìƒì„±
        view1 = self.input_feature_dropout(raw_product)
        view2 = self.input_feature_dropout(raw_product)
        
        return view1, view2

def collate_simcse(batch):
    """(View1, View2) ë¦¬ìŠ¤íŠ¸ -> Tensor ë³€í™˜"""
    view1_list = [item[0] for item in batch]
    view2_list = [item[1] for item in batch]
    
    t_std1, t_re1 = serving_controller.preprocess_batch_input(view1_list)
    t_std2, t_re2 = serving_controller.preprocess_batch_input(view2_list)
    
    return t_std1, t_re1, t_std2, t_re2


## ë©”ëª¨ë¦¬ ìµœì í™”: db_session.query(Model).all() ëŒ€ì‹  select(...).mappings().all()ì„ ì‚¬ìš©í•˜ì—¬ ë”•ì…”ë„ˆë¦¬ë¡œ ë°ì´í„°ë¥¼ ë¡œë“œí•˜ì„¸ìš”

def train_simcse_from_db(    
    encoder: nn.Module,       
    projector: nn.Module,
    batch_size: int = 128, 
    epochs: int = 5,
    lr: float = 1e-4
):
    print("ğŸš€ Fetching data from DB...")
    
    # í˜¹ì‹œ ëª¨ë¥¼ taskbackgroundë–„ë¬¸ì— ì¼ë‹¨.
    db_session = SessionLocal()
    
    
    stmt = select(ProductFeature.product_id, ProductFeature.feature_data)
    result = db_session.execute(stmt).mappings().all()
    
    if not result:
        print("âŒ No data found.")
        return

    # [ìˆ˜ì • 2] Dictionary -> Pydantic ë³€í™˜
    products_list = []
    for row in result:
        # row['feature_data'] ì ‘ê·¼
        f_data = row['feature_data']
        p_input = ProductInput(
            id=row['product_id'],
            clothes=f_data.get("clothes", {}),
            reinforced_feature_value=f_data.get("reinforced_feature_value", {})
        )
        products_list.append(p_input)
        
    print(f"âœ… Loaded {len(products_list)} items.")
    
    # 3. ëª¨ë¸ ì„¤ì •
    model = SimCSEModelWrapper(encoder, projector).to(DEVICE)
    model.train() # Dropout ON (í•„ìˆ˜)
    
    # OptimizerëŠ” ë‘ ëª¨ë¸ì˜ íŒŒë¼ë¯¸í„°ë¥¼ ëª¨ë‘ í•™ìŠµí•´ì•¼ í•¨
    optimizer = torch.optim.AdamW(model.parameters(), lr=lr)
    
    # Loss Function (Contrastive Learning)
    loss_func = losses.NTXentLoss(temperature=0.07)
    
    dataset = SimCSERecSysDataset(products_list, dropout_prob=0.2)
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=True, 
        collate_fn=collate_simcse,
        drop_last=True
    )
    
    print("ğŸ”¥ Starting Training Loop...")
    
    # 5. Training Loop
    for epoch in range(epochs):
        total_loss = 0
        step = 0
        
        progress = tqdm(dataloader, desc=f"Epoch {epoch+1}/{epochs}")
        for t_std1, t_re1, t_std2, t_re2 in progress:
            t_std1, t_re1 = t_std1.to(DEVICE), t_re1.to(DEVICE)
            t_std2, t_re2 = t_std2.to(DEVICE), t_re2.to(DEVICE)
            
            optimizer.zero_grad()
            
            # Forward (Cross-Attention)
            emb1 = model(t_std1, t_re1)
            emb2 = model(t_std2, t_re2)
            
            # Contrastive Loss Calculation
            embeddings = torch.cat([emb1, emb2], dim=0)
            
            # Label generation
            # ë°°ì¹˜ ì‚¬ì´ì¦ˆë§Œí¼ 0~N ë¼ë²¨ì„ ë§Œë“¤ê³  ë‘ ë²ˆ ë°˜ë³µ
            batch_curr = emb1.size(0)
            labels = torch.arange(batch_curr).to(DEVICE)
            labels = torch.cat([labels, labels], dim=0)
            
            loss = loss_func(embeddings, labels)
            
            loss.backward()
            optimizer.step()
            
            total_loss += loss.item()
            step += 1
            progress.set_postfix({"loss": f"{loss.item():.4f}"})
            
        print(f"Epoch {epoch+1} Avg Loss: {total_loss/step:.4f}")
        
    print("Training Finished.")
    
    print("ğŸ’¾ Saving models...")
    torch.save(encoder.state_dict(), "encoder_stage1.pth")
    torch.save(projector.state_dict(), "projector_stage2.pth")
    
    # torch.save(model.state_dict(), "final_simcse_model.pth")    










