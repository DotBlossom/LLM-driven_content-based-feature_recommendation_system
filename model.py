from typing import Any, Dict, List, Tuple, Union
from fastapi import APIRouter, Depends
from pydantic import BaseModel
from sqlalchemy import Column, select
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
from torch.utils.data import Dataset, DataLoader, Sampler
from pytorch_metric_learning import losses, miners, distances
from collections import defaultdict
import random
import numpy as np

import utils.vocab as vocab
from database import ProductInferenceVectors, SessionLocal

from sqlalchemy.orm import Session
import copy
import random
from tqdm import tqdm

# ItemTowerEmbedding(S1) * N -> save..DB -> stage2 (optimizer pass -> triplet)  

model_router = APIRouter()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")


# í•„ë“œ ìˆœì„œ ì •ì˜ (Field Embedding), ì„ì‹œ, data ë³´ê³  ê²°ì •
# key ìˆœì„œ == ì˜¤ëŠ” json ë°ì´íƒ€Load ìˆœì„œ
ALL_FIELD_KEYS = [
    "category", "season", "fiber_composition", "elasticity", "transparency", 
    "isfleece", "color", "gender", "category_specification", "top.length_type", "top.sleeve_length_type",
    "top.neck_color_design","top.sleeve_design","pant.silhouette", "skirt.design",
    "specification.metadata"
    # í•„ìš”í•œ ë§Œí¼ ì¶”ê°€...
]
FIELD_TO_IDX = {k: i for i, k in enumerate(ALL_FIELD_KEYS)}
NUM_TOTAL_FIELDS = len(ALL_FIELD_KEYS)


class TrainingItem(BaseModel):

    product_id: int
    feature_data: Dict[str, Any]

# --- Global Configuration (ì „ì²´ ì‹œìŠ¤í…œì´ ì°¸ì¡°í•˜ëŠ” ê³µí†µ ì°¨ì›) ---
EMBED_DIM_CAT = 64 # Featureì˜ ì„ë² ë”© ì°¨ì› (Transformer d_model)
OUTPUT_DIM_TRIPLET = 128 # Stage 2 ìµœì¢… ì••ì¶• ì°¨ì›
OUTPUT_DIM_ITEM_TOWER = 128 # Stage 1 ìµœì¢… ì¶œë ¥ ì°¨ì› (Triplet Tower Input)
RE_MAX_CAPACITY = 500 # <<<<<<<<<<<< RE í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ í• ë‹¹
# ----------------------------------------------------------------------
# 1. Utility Modules (Shared for both Item Tower and Optimization Tower)
# ----------------------------------------------------------------------

# --- Residual Block (Corrected for Skip Connection) ---
class ResidualBlock(nn.Module):

    def __init__(self, dim, dropout=0.2):
        super().__init__()
        # ë¸”ë¡ ë‚´ì—ì„œ ì°¨ì›ì„ ìœ ì§€í•˜ëŠ” 2ê°œì˜ Linear Layer (Skip Connection ì „ ì²˜ë¦¬)
        self.block = nn.Sequential(
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
            nn.ReLU(),
            nn.Dropout(dropout),
            nn.Linear(dim, dim),
            nn.BatchNorm1d(dim),
        )
        self.relu = nn.ReLU()

    def forward(self, x):
        residual = x
        out = self.block(x)
        # x + block(x) -> ì”ì°¨ ì—°ê²° (í•µì‹¬!)
        return self.relu(residual + out)

# --- Deep Residual Head (Pyramid Funnel) ---
class DeepResidualHead(nn.Module):
    """
    Categorical Vector(64d) -> 256 -> 128
    """
    def __init__(self, input_dim, output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. ë‚´ë¶€ í™•ì¥ (Expansion): í‘œí˜„ë ¥ì„ ìœ„í•´ 4ë°° í™•ì¥ì€ ìœ ì§€ (64 -> 256)
        hidden_dim = input_dim * 4 
        
        self.expand = nn.Sequential(
            nn.Linear(input_dim, hidden_dim),
            nn.BatchNorm1d(hidden_dim),
            nn.ReLU(),
            nn.Dropout(0.1)
        )
        
        # 2. Deep Interaction (ResBlocks): 256ì°¨ì›ì—ì„œ íŠ¹ì§• ì¶”ì¶œ
        self.res_blocks = nn.Sequential(
            ResidualBlock(hidden_dim), # 256 ìœ ì§€
            ResidualBlock(hidden_dim)  # 256 ìœ ì§€
        )
        
        # 3. Projection (Compression): ë°”ë¡œ ëª©í‘œ ì°¨ì›(128)ìœ¼ë¡œ ì••ì¶•
        self.project = nn.Linear(hidden_dim, output_dim) 
        
    def forward(self, x):
        x = self.expand(x)      # 64 -> 256
        x = self.res_blocks(x)  # 256 -> 256 (Deep Feature Extraction)
        x = self.project(x)     # 256 -> 128 (Final Output)
        if not self.training:
            # (B, 128)
            final_sample = x[0, :6].detach().cpu().numpy()
            print(f"[Head DEBUG] D. Final Output (B, {x.shape[1]}): {final_sample}")
        return x
 
# ----------------------------------------------------------------------
# 3. Main Model: CoarseToFineItemTower (Stage 1)
# ----------------------------------------------------------------------
class CoarseToFineItemTower(nn.Module):
    """
    [Item Tower - Residual Field Embedding Ver.]
    TabTransformerì˜ ì•„ì´ë””ì–´ë¥¼ ì‘ìš©í•˜ì—¬, STDì™€ REë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ í†µí•©í•˜ê³ 
    ê³„ì¸µì  ì”ì°¨ ì—°ê²°(Inheritance)ì„ í†µí•´ í•™ìŠµ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•œ êµ¬ì¡°.
    """
    def __init__(self, 
                 embed_dim=EMBED_DIM_CAT,     # 64
                 nhead=4, 
                 num_layers=2,                # TabTransformerëŠ” ì–•ì•„ë„ ì¶©ë¶„í•¨
                 max_fields=50,               # ì˜ˆìƒë˜ëŠ” ìµœëŒ€ í•„ë“œ(ì»¬ëŸ¼) ê°œìˆ˜
                 output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. Vocab Size ê°€ì ¸ì˜¤ê¸°
        std_vocab_size, _ = vocab.get_vocab_sizes()
        
        # 2. Embeddings
        # A. STD Value Embedding (Base) , RE Value Embedding (Delta / Child)
        self.std_embedding = nn.Embedding(std_vocab_size, embed_dim, padding_idx=vocab.PAD_ID)
        self.re_embedding = nn.Embedding(RE_MAX_CAPACITY, embed_dim, padding_idx=vocab.PAD_ID)
        
        # REëŠ” Delta(ì°¨ì´ì )ë§Œ í•™ìŠµí•˜ë¯€ë¡œ 0 ê·¼ì²˜ ì´ˆê¸°í™” (í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±)
        nn.init.normal_(self.re_embedding.weight, mean=0.0, std=0.01)

        # C. Field Embedding (Shared Key)
        # ê° ì»¬ëŸ¼(Color, Brand ë“±)ì˜ ì—­í• ì„ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”©
        self.field_embedding = nn.Parameter(torch.randn(1, max_fields, embed_dim))
        
        # 3. Unified Transformer Encoder
        # STDì™€ REê°€ í•œ ê³µê°„ì—ì„œ ìƒí˜¸ì‘ìš© (Cross-Attn ëŒ€ì‹  Self-Attn ì‚¬ìš©)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=nhead, 
            dim_feedforward=embed_dim * 4,
            batch_first=True,
            dropout=0.1,
            activation='gelu'
            #,norm_first=True # ìµœì‹  íŠ¸ë Œë“œ (ì•ˆì •ì  ìˆ˜ë ´)
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # 4. Projection Head
        # ì…ë ¥ ì°¨ì›: (STDí•„ë“œìˆ˜ + REí•„ë“œìˆ˜) * embed_dim -> Flatten í›„ ì••ì¶•
        self.head = DeepResidualHead(input_dim=embed_dim, output_dim=output_dim) 
        


    def forward(self, std_input: torch.Tensor, re_input: torch.Tensor) -> torch.Tensor:
        """
        std_input: (Batch, Num_Fields) - ì˜ˆ: [Color_ID, Category_ID, ...]
        re_input:  (Batch, Num_Fields) - ì˜ˆ: [MatteBlack_ID, 0, ...] (ìˆœì„œê°€ STDì™€ ëŒ€ì‘ë˜ì–´ì•¼ í•¨)
        """
        B, num_fields = std_input.shape
        
        # --- [Logic 1] Hierarchical Embedding Construction ---
        
        # (A) Field Embedding (Broadcasting)
        # í˜„ì¬ ë°°ì¹˜ì˜ í•„ë“œ ê°œìˆ˜ë§Œí¼ ìë¦„ (í˜¹ì‹œ ëª¨ë¥¼ ê°€ë³€ ê¸¸ì´ì— ëŒ€ë¹„)
        field_emb = self.field_embedding[:, :num_fields, :] # (1, F, D)
        
        # (B) STD (Parent)
        std_val = self.std_embedding(std_input) # (B, F, D)
        std_token = std_val + field_emb
        
        # (C) RE (Child = Delta + Parent + Field)
        re_delta = self.re_embedding(re_input) # (B, F, D)
        
        # * í•µì‹¬: REê°€ 0(PAD)ì´ì–´ë„ std_val + field_embê°€ ë‚¨ì•„ì„œ 'Parent' ì—­í• ì„ ìˆ˜í–‰í•¨
        # * detach(): REì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ STD ì„ë² ë”©ì„ ë§ê°€ëœ¨ë¦¬ì§€ ì•Šë„ë¡ ì°¨ë‹¨
        re_token = re_delta + std_val.detach() + field_emb
        
        # --- [Logic 2] Unified Sequence ---
        # [STD_1, STD_2, ..., RE_1, RE_2, ...]
        combined_seq = torch.cat([std_token, re_token], dim=1) # (B, 2*F, D)
        
        # --- [Logic 3] Transformer & Pooling ---
        # PAD Masking: ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ìƒëµ (SimCLR íŠ¹ì„±ìƒ Noiseë„ ì •ë³´ê°€ ë¨)
        # ì •êµí•˜ê²Œ í•˜ë ¤ë©´ src_key_padding_mask ì¶”ê°€ ê°€ëŠ¥
        
        context_out = self.transformer(combined_seq) # (B, 2*F, D)
        
        # Mean Pooling (Flatten ëŒ€ì‹  ì‚¬ìš© -> í•„ë“œ ìˆ˜ ë³€í™”ì— ê°•ì¸í•¨)
        pooled = context_out.mean(dim=1) # (B, D)
    
        if not self.training:
            # ì²« ë²ˆì§¸ ìƒ˜í”Œì˜ ì²˜ìŒ 6ê°œ ê°’ë§Œ ì¶œë ¥
            pooled_sample = pooled[0, :6].detach().cpu().numpy()
            print(f"DEBUG: Pooled Vector (h) Sample (1st 6 values): {pooled_sample}")
        
        return self.head(pooled) # (B, 128)
    
    
# ----------------------------------------------------------------------
# 4. OptimizedItemTower (Stage 2 Adapter - Triplet Training)
#    Projection Head --> Contrastive Loss(Opt.z) / Representation(Encoder)
# ----------------------------------------------------------------------

class OptimizedItemTower(nn.Module):
    """
    [Optimization Tower]: Stage 1ì˜ vector non-liner
    """
    def __init__(self, input_dim=OUTPUT_DIM_ITEM_TOWER, output_dim=OUTPUT_DIM_TRIPLET):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.LayerNorm(input_dim),
            nn.GELU(), #nn.ReLU(), 
            nn.Linear(input_dim, output_dim),
        )
        
    def forward(self, x):
        # [Log 1] ì…ë ¥ ë°ì´í„° í™•ì¸
        if not self.training: # ì¶”ë¡ (eval) ëª¨ë“œì¼ ë•Œë§Œ ë¡œê·¸ ì¶œë ¥ (í•™ìŠµ ë• ë„ˆë¬´ ë§ìŒ)
            print(f"\n  [Model Internal] Input Vector Shape: {x.shape}")
            print(f"  [Model Internal] Input Sample (First 5): {x[0, :5].detach().cpu().numpy()}")

        # ë ˆì´ì–´ í†µê³¼
        x = self.layer(x)
        
        # ì •ê·œí™” (L2 Normalization)
    
        return F.normalize(x, p=2, dim=1)




# x = F.normalize(x, p=2, dim=1) ì‹¤ì œ ì¶”ë¡ ë–„ëŠ” hìª½ model loadí•˜ì—¬ ì“°ì. (same d)

'''

êµ¬ì¡°: Encoder -> Embedding(h) -> MLP Layer(Projection Head) -> Output(z) -> Loss

ì›ë¦¬: z ê³µê°„ì—ì„œëŠ” Contrastive Lossì— ì˜í•´ ë°ì´í„°ê°€ êµ¬ì²´ í‘œë©´ìœ¼ë¡œ ì°Œê·¸ëŸ¬ì§€ë©° ì •ë³´ ì†ì‹¤
ë°˜ë©´ ê·¸ ì „ ë‹¨ê³„ì¸ hëŠ” ë°ì´í„°ì˜ ì›ë³¸ ì •ë³´ë¥¼ ìƒëŒ€ì  ë³´ì¡´

í•™ìŠµí•  ë•Œ: Projection Headë¥¼ ë¶™ì—¬ì„œ z ê°’ìœ¼ë¡œ Loss ê³„ì‚°.

ì„œë¹™í•  ë•Œ: Projection Headë¥¼ ë–¼ì–´ë²„ë¦¬ê³  h ê°’ì„ ì‚¬ìš©.

íš¨ê³¼: ì´ë ‡ê²Œ í•˜ë©´ Representation Qualityê°€ 10~15% í–¥ìƒ data

'''


    
# ----------------------------------------------------------------------
# 5. Dataset & Sampler & Training Function (Stage 2 Logic) / first INPUT from DB
# ----------------------------------------------------------------------


class SimCSEModelWrapper(nn.Module):
    def __init__(self, encoder, projector):
        super().__init__()
        self.encoder = encoder      # ì´ê²ƒì´ CoarseToFineItemTower
        self.projector = projector  # ì´ê²ƒì´ OptimizedItemTower


    def forward(self, t_std, t_re):
        # 1. ë°›ì€ 2ê°œ ì¸ìë¥¼ encoderì—ê²Œ ê·¸ëŒ€ë¡œ í† ìŠ¤
        enc_out = self.encoder(t_std, t_re) 
        
        # 2. ê·¸ ê²°ê³¼ë¥¼ projectorì—ê²Œ í† ìŠ¤
        return self.projector(enc_out)

class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def _apply_dropout_and_convert(self, product: TrainingItem):
        """
        1. Feature Dropout ìˆ˜í–‰
        2. Dictionary -> Fixed Size Tensor ë³€í™˜ (Hashing í¬í•¨)
        """
        # (1) Dropout Logic
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ (Shallow copy of dict structure is enough usually, but deep for safety)
        feat_data = copy.deepcopy(product.feature_data)
        
        clothes = feat_data.get("clothes", {})
        reinforced = feat_data.get("reinforced_feature_value", {})
        
        # Random Dropout (Key ì‚­ì œ)
        if self.dropout_prob > 0:
            for k in list(clothes.keys()):
                if random.random() < self.dropout_prob:
                    del clothes[k]
            for k in list(reinforced.keys()):
                if random.random() < self.dropout_prob:
                    del reinforced[k]

        # (2) Tensor Conversion Logic (Alignment)
        std_ids = []
        re_ids = []
        debug_output = {}
        # ë¯¸ë¦¬ ì •ì˜ëœ ALL_FIELD_KEYS ìˆœì„œëŒ€ë¡œ ìˆœíšŒí•˜ë©° ID ì¶”ì¶œ
        for idx, key in enumerate(ALL_FIELD_KEYS):
            # A. STD ID ì¶”ì¶œ
            std_val = clothes.get(key) # ì—†ìœ¼ë©´ None
            # Noneì´ë©´ MockVocab ë‚´ë¶€ì—ì„œ PAD_ID(0) ë°˜í™˜
            s_id = vocab.get_std_id(key, std_val) 
            std_ids.append(s_id)
            
            # B. RE ID ì¶”ì¶œ (Hashing)
            # RE ë°ì´í„°ëŠ” ë¦¬ìŠ¤íŠ¸ í˜•íƒœì¼ ìˆ˜ ìˆìŒ (["Matte Black"]) -> ì²«ë²ˆì§¸ ê°’ ì‚¬ìš©
            re_val_list = reinforced.get(key)
            re_val = None
            if re_val_list and isinstance(re_val_list, list) and len(re_val_list) > 0:
                re_val = re_val_list[0]
            elif isinstance(re_val_list, str):
                re_val = re_val_list
            
            # Hashing í•¨ìˆ˜ í˜¸ì¶œ (ì €ì¥ X)
            r_id = vocab.get_re_hash_id(re_val)
            re_ids.append(r_id)
            
            # --- ë””ë²„ê·¸ ë¡œê·¸ ê¸°ë¡ ---
            if idx < 3: # ì²˜ìŒ 3ê°œ í•„ë“œë§Œ ê¸°ë¡
                debug_output[key] = {
                    "STD_Val": std_val,
                    "STD_ID": s_id,
                    "RE_Val": re_val,
                    "RE_ID_Hash": r_id
                }

        # --- ë””ë²„ê·¸ ë¡œê·¸ ì¶œë ¥ (ë°°ì¹˜ì—ì„œ ì²« ë²ˆì§¸ ì•„ì´í…œë§Œ ê°€ì •í•˜ê³  ì¶œë ¥) ---
        if product.product_id == self.products[0].product_id: # ì²« ë²ˆì§¸ ìƒí’ˆì— ëŒ€í•´ì„œë§Œ ì¶œë ¥ (ì „ì²´ ìƒí’ˆ ì¶œë ¥í•˜ë©´ ë„ˆë¬´ ê¸¸ì–´ì§)
            print("\n[DATASET DEBUG] Feature Extraction & Hashing Check:")
            for k, v in debug_output.items():
                print(f"  > Key: {k.upper()} | STD Val: '{v['STD_Val']}' -> ID {v['STD_ID']} | RE Val: '{v['RE_Val']}' -> ID {v['RE_ID_Hash']}")
            print(f"  > Final Tensors Length: STD={len(std_ids)}, RE={len(re_ids)} (Should be {len(ALL_FIELD_KEYS)})")
        # -------------------------------------------------------------
            
        return torch.tensor(std_ids, dtype=torch.long), torch.tensor(re_ids, dtype=torch.long)

    def __getitem__(self, idx):
        item = self.products[idx]
        
        # Contrastive Learningì„ ìœ„í•œ 2ê°œì˜ View ìƒì„±
        # ê°ê° ì„œë¡œ ë‹¤ë¥¸ Dropoutì´ ì ìš©ë¨
        v1_std, v1_re = self._apply_dropout_and_convert(item)
        v2_std, v2_re = self._apply_dropout_and_convert(item)
        
        return (v1_std, v1_re), (v2_std, v2_re)






''' 
class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def input_feature_dropout(self, product: TrainingItem) -> TrainingItem:
        """
        [Augmentation Logic]
        JSON êµ¬ì¡°("clothes", "reinforced_feature_value")ì— ë§ì¶°
        ëœë¤í•˜ê²Œ ì†ì„±(Key-Value)ì„ ì œê±°í•©ë‹ˆë‹¤.
        """
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ Deep Copy (ë§¤ìš° ì¤‘ìš”)
        aug_p = copy.deepcopy(product)
        
        feature_dict = aug_p.feature_data
        
        # 1. Standard Features (clothes) Dropout
   
        clothes_data = feature_dict.get("clothes")
        if clothes_data:
            keys = list(clothes_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del clothes_data[k]
        
        # 2. Reinforced Features Dropout
  
        re_data = feature_dict.get("reinforced_feature_value")
        if re_data:
            keys = list(re_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del re_data[k]
                    
        return aug_p
    def __getitem__(self, idx):
        raw_product = self.products[idx]
        
        # SimCSE: ê°™ì€ ìƒí’ˆì„ ë‘ ë²ˆ ë³€í˜•í•´ì„œ (View1, View2) ìƒì„±
        view1 = self.input_feature_dropout(raw_product)
        view2 = self.input_feature_dropout(raw_product)
        
        return view1, view2
'''


    
# ----------------------------------------------------------------------
# 6. userTowerClass
#     
# ----------------------------------------------------------------------


def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [ê¸°ëŠ¥]
    1. DBì—ì„œ (product_id, vector) ìŒì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
    2. DB ID -> Model Index ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3. User Towerì˜ Embedding Layerì— ë„£ì„ Weight Matrixë¥¼ ë§Œë“­ë‹ˆë‹¤.
    
    [Return]
    - embedding_matrix: (Num_Products + 1, 128) - 0ë²ˆì€ Padding
    - id_map: {real_db_id: model_index}
    """
    print("â³ Fetching product vectors from DB...")
    
    # 1. DB Query (IDì™€ Serving Vectorë§Œ ê°€ì ¸ì˜´)
    # vector_servingì´ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìµœì¢… ì•„ì´í…œ ë²¡í„°ë¼ê³  ê°€ì •
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_serving
    ).filter(
        ProductInferenceVectors.vector_serving.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128 # ê³ ì • ì°¨ì›
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    id_map = {} # Real ID -> Model Index

    # 3. ë§¤í•‘ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listëŠ” DBì—ì„œ List[float] í˜•íƒœë¡œ ì˜¨ë‹¤ê³  ê°€ì •
        if vector_list is None: continue
            
        # ë§¤í•‘ ì €ì¥
        id_map[real_id] = idx 
        
        # í…ì„œì— ê°’ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print("âœ… Pretrained Embedding Matrix Created.")
    print(f"   Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map

class SymmetricUserTower(nn.Module):
    def __init__(self, 
                 num_total_products: int,    # DBì— ìˆëŠ” ì´ ìƒí’ˆ ê°œìˆ˜ (Padding ì œì™¸)
                 max_seq_len: int = 50,
                 input_dim: int = 128,       # Item Vector ì°¨ì›
                 d_model: int = 128,
                 nhead: int = 4,
                 num_layers: int = 2,
                 dropout: float = 0.1):
        super().__init__()
        
        self.max_seq_len = max_seq_len
        
        # --- 1. Embeddings ---
        
        # (A) Item Lookup Table (Pre-trained)
        # num_embeddings = ìƒí’ˆê°œìˆ˜ + 1 (for Padding Index 0)
        self.item_embedding = nn.Embedding(num_total_products + 1, input_dim, padding_idx=0)
        
        # (B) Positional Embedding
        self.position_embedding = nn.Embedding(max_seq_len + 1, d_model)
        
        # (C) User Profile (ì˜ˆì‹œ)
        self.gender_emb = nn.Embedding(3, 16, padding_idx=0)
        self.age_emb = nn.Embedding(10, 16, padding_idx=0)
        self.profile_projector = nn.Sequential(
            nn.Linear(16 + 16, d_model),
            nn.LayerNorm(d_model),
            nn.GELU()
        )

        # --- 2. Encoder ---
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=d_model, nhead=nhead, dim_feedforward=d_model*4,
            batch_first=True, dropout=dropout, activation='gelu'
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # --- 3. Head ---
        self.head = DeepResidualHead(input_dim=d_model, output_dim=d_model)

    def load_pretrained_weights(self, pretrained_matrix: torch.Tensor, freeze: bool = True):
        """
        [í•µì‹¬ ë¡œì§] DBì—ì„œ ê°€ì ¸ì˜¨ ë²¡í„°ë¥¼ ì„ë² ë”© ë ˆì´ì–´ì— ë®ì–´ì”Œì›ë‹ˆë‹¤.
        """
        # ì°¨ì› ê²€ì‚¬
        if self.item_embedding.weight.shape != pretrained_matrix.shape:
            raise ValueError(f"Shape Mismatch! Model: {self.item_embedding.weight.shape}, DB: {pretrained_matrix.shape}")
            
        # 1. ê°€ì¤‘ì¹˜ ë³µì‚¬ (Copy)
        self.item_embedding.weight.data.copy_(pretrained_matrix)
        print("âœ… Pretrained Item Vectors Loaded into User Tower.")
        
        # 2. ê°€ì¤‘ì¹˜ ë™ê²° (Freeze) - ì•„ì´í…œ ë²¡í„°ëŠ” ë” ì´ìƒ í•™ìŠµë˜ì§€ ì•ŠìŒ (ì¼ë°˜ì )
        if freeze:
            self.item_embedding.weight.requires_grad = False
            print("â„ï¸ Item Embeddings are FROZEN (Not trainable).")
        else:
            print("ğŸ”¥ Item Embeddings are TRAINABLE (Fine-tuning mode).")

    def forward(self, history_ids, profile_data):
        # ... (ì´ì „ ì½”ë“œì™€ ë™ì¼: history_idsëŠ” ë§¤í•‘ëœ Model Indexì—¬ì•¼ í•¨) ...
        B, L = history_ids.shape
        device = history_ids.device
        
        # (A) Lookup -> (B, L, 128) : ì—¬ê¸°ì„œ DB ë²¡í„°ê°€ íŠ€ì–´ë‚˜ì˜´
        seq_emb = self.item_embedding(history_ids)
        
        # ... (ì´í•˜ ë™ì¼: Positional ë”í•˜ê³  Transformer í†µê³¼) ...
        positions = torch.arange(L, device=device).unsqueeze(0).expand(B, L)
        pos_emb = self.position_embedding(positions)
        seq_emb = seq_emb + pos_emb
        
        # Profile
        g_emb = self.gender_emb(profile_data.get('gender', torch.zeros(B, dtype=torch.long, device=device)))
        a_emb = self.age_emb(profile_data.get('age', torch.zeros(B, dtype=torch.long, device=device)))
        profile_feat = torch.cat([g_emb, a_emb], dim=1)
        user_token = self.profile_projector(profile_feat).unsqueeze(1)
        
        combined_seq = torch.cat([user_token, seq_emb], dim=1)
        
        key_padding_mask = (history_ids == 0)
        user_token_mask = torch.zeros((B, 1), dtype=torch.bool, device=device)
        combined_mask = torch.cat([user_token_mask, key_padding_mask], dim=1)
        
        output = self.transformer(combined_seq, src_key_padding_mask=combined_mask)
        user_vector = output[:, 0, :]
        
        return self.head(user_vector)

class TwoTowerRecSys(nn.Module):
    """
    [User Tower + Item Tower]
    ì‹¤ì œ ì„œë¹„ìŠ¤(Retrieval)ë¥¼ ìœ„í•œ ì™„ì „ì²´ ëª¨ë¸
    """
    def __init__(self, 
                 item_tower: CoarseToFineItemTower, 
                 user_tower: SymmetricUserTower):
        super().__init__()
        self.item_tower = item_tower
        self.user_tower = user_tower
        
    def forward(self, 
                # Item Inputs
                std_input, re_input, 
                # User Inputs
                history_ids, profile_data):
        
        # 1. Item Vector ìƒì„± (Target Item)
        # (B, 128)
        target_item_vec = self.item_tower(std_input, re_input)
        
        # 2. User Vector ìƒì„±
        # (B, 128)
        user_vec = self.user_tower(history_ids, profile_data)
        
        # 3. Score Calculation (Dot Product)
        # (B, 128) * (B, 128) -> (B,) sum
        # í•™ìŠµ ì‹œì—ëŠ” ë³´í†µ In-batch Negative ë“±ì„ ì‚¬ìš©í•˜ë¯€ë¡œ
        # ì—¬ê¸°ì„œëŠ” ë‹¨ìˆœíˆ ë‘ ë²¡í„°ë¥¼ ë¦¬í„´í•˜ê±°ë‚˜, ìœ ì‚¬ë„ë¥¼ ë¦¬í„´
        return user_vec, target_item_vec