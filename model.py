from typing import Any, Dict, List, Tuple
from fastapi import APIRouter
from pydantic import BaseModel
import torch
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import Dataset
import random
import utils.vocab as vocab
from database import ProductInferenceVectors
from sqlalchemy.orm import Session
import copy
import random

#################### !!!!!!!! ì¹´í…Œê³ ë¦¬ ì œì™¸í•˜ê³  í•™ìŠµí•˜ê¸°

def prepare_training_data(raw_json):
    features = raw_json['feature_data']['clothes']
    
    # âœ‚ï¸ í•™ìŠµìš© í…ìŠ¤íŠ¸ ë§Œë“¤ ë•ŒëŠ” ì¹´í…Œê³ ë¦¬ ì‚­ì œ!
    if 'category' in features:
        del features['category'] 
        
    # ë‚¨ì€ ê±´: "color: black, material: wool..." (ìˆœìˆ˜ íŠ¹ì§•ë“¤)
    return str(features)


# ItemTowerEmbedding(S1) * N -> save..DB -> stage2 (optimizer pass -> triplet)  

model_router = APIRouter()
DEVICE = torch.device("cuda" if torch.cuda.is_available() else "cpu")



# í•„ë“œ ìˆœì„œ ì •ì˜ (Field Embedding), ì„ì‹œ, data ë³´ê³  ê²°ì •
# key ìˆœì„œ == ì˜¤ëŠ” json ë°ì´íƒ€Load ìˆœì„œ
ALL_FIELD_KEYS = vocab.ORDERED_FEATURE_KEYS 
FIELD_TO_IDX = {k: i for i, k in enumerate(ALL_FIELD_KEYS)}
NUM_TOTAL_FIELDS = len(ALL_FIELD_KEYS)



class TrainingItem(BaseModel):

    product_id: int
    feature_data: Dict[str, Any]

# --- Global Configuration (ì „ì²´ ì‹œìŠ¤í…œì´ ì°¸ì¡°í•˜ëŠ” ê³µí†µ ì°¨ì›) ---
EMBED_DIM_CAT = 64 # Featureì˜ ì„ë² ë”© ì°¨ì› (Transformer d_model)
OUTPUT_DIM_TRIPLET = 128 # Stage 2 ìµœì¢… ì••ì¶• ì°¨ì›
OUTPUT_DIM_ITEM_TOWER = 128 # Stage 1 ìµœì¢… ì¶œë ¥ ì°¨ì› (Triplet Tower Input)
RE_MAX_CAPACITY = 500 # <<<<<<<<<<<< RE í† í°ì˜ ìµœëŒ€ ê°œìˆ˜ë¥¼ ë¯¸ë¦¬ í• ë‹¹
# ----------------------------------------------------------------------
# 1. Utility Modules (Shared for both Item Tower and Optimization Tower)
# ----------------------------------------------------------------------

# --- Residual Block (Corrected for Skip Connection) ---
class SEResidualBlock(nn.Module):

    def __init__(self, dim, dropout=0.2, expansion_factor=4):
        super().__init__()
        
        # 1. Feature Transformation (ê¸°ì¡´ê³¼ ë™ì¼í•˜ë˜, SwiGLU ìŠ¤íƒ€ì¼ë¡œ í™•ì¥ ì œì•ˆ)
        # ì—¬ê¸°ì„œëŠ” ì•ˆì •ì ì¸ ê¸°ì¡´ Linear ë°©ì‹ì„ ìœ ì§€í•˜ë˜ SEë¥¼ ì¶”ê°€í•¨
        self.block = nn.Sequential(
            nn.Linear(dim, dim * expansion_factor), # ë‚´ë¶€ í™•ì¥
            nn.LayerNorm(dim * expansion_factor),
            nn.GELU(),
            nn.Dropout(dropout),
            nn.Linear(dim * expansion_factor, dim), # ë‹¤ì‹œ ì••ì¶•
            nn.LayerNorm(dim),
        )
        
        # 2. SE-Block (Channel Attention, SE-Net êµ¬ì¡° ë°˜ì˜, Gating=Relu íŒŒíŠ¸)
        # ì…ë ¥ ë²¡í„°ì˜ ê° ì°¨ì›(feature)ì— ëŒ€í•´ ì¤‘ìš”ë„(0~1)ë¥¼ ê³„ì‚°
        self.se_block = nn.Sequential(
            nn.Linear(dim, dim // 4),  # Squeeze (ì •ë³´ ì••ì¶•)
            nn.ReLU(),
            nn.Linear(dim // 4, dim),  # Excitation (ì¤‘ìš”ë„ ë³µì›)
            nn.Sigmoid()               # 0~1 ì‚¬ì´ì˜ ê°€ì¤‘ì¹˜ë¡œ ë³€í™˜
        )

        self.act = nn.GELU()
    
    def forward(self, x):
        residual = x
        
        # (A) Main Path
        out = self.block(x)
        
        # (B) SE-Attention Path
        # ë²¡í„°ì˜ ê¸€ë¡œë²Œ ì •ë³´ë¥¼ ë³´ê³ , ì–´ë–¤ ì°¨ì›ì„ ê°•ì¡°í• ì§€ ê²°ì •
        # MLP ì¶œë ¥ê°’(out)ì— ì¤‘ìš”ë„(weight)ë¥¼ ê³±í•¨
        weight = self.se_block(out)
        out = out * weight 
        
        # (C) Residual Connection
        return self.act(residual + out)




# --- Deep Residual Head (Pyramid Funnel) ---
class DeepResidualHead(nn.Module):
    """
    [Architecture]
    Input(64) -> [Expand 2x] -> 128 -> [Expand 2x] -> 256 
    -> [Deep Interaction (SE-ResBlock)] -> 256 
    -> [Compression] -> Output(128)
    + Global Skip Connection
    """
    def __init__(self, input_dim, output_dim=128):
        super().__init__()
        
        # ì°¨ì› ì •ì˜ (64 -> 128 -> 256)
        mid_dim = input_dim * 2      # 128
        hidden_dim = input_dim * 4   # 256
        
        # 1. Progressive Expansion 
        self.expand_layer1 = nn.Sequential(
            nn.Linear(input_dim, mid_dim),  # 64 -> 128
            nn.LayerNorm(mid_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        self.expand_layer2 = nn.Sequential(
            nn.Linear(mid_dim, hidden_dim), # 128 -> 256
            nn.LayerNorm(hidden_dim),
            nn.GELU(),
            nn.Dropout(0.1)
        )
        
        # 2. Deep Interaction (Peak Dimensionì—ì„œ ìˆ˜í–‰)
        # ê°€ì¥ ì°¨ì›ì´ ë†’ì€ 256 ìƒíƒœì—ì„œ SE-Blockìœ¼ë¡œ ì •ë°€í•œ íŠ¹ì§• ì¶”ì¶œ ìˆ˜í–‰
        self.res_blocks = nn.Sequential(
            SEResidualBlock(hidden_dim, dropout=0.2), # 256 ìœ ì§€
            SEResidualBlock(hidden_dim, dropout=0.2)  # 256 ìœ ì§€
        )
        
        # 3. Final Projection (Compression)
        # 256 -> 128 ë¡œ ì••ì¶•í•˜ì—¬ ìµœì¢… ì„ë² ë”© ìƒì„±
        self.final_proj = nn.Linear(hidden_dim, output_dim)
        
        # 4. Global Skip Connection (Input Shortcut) ResNet ì”ì°¨
        self.input_skip = nn.Linear(input_dim, output_dim)

    def forward(self, x):
        # --- [Step 1] Progressive Expansion ---
        m = self.expand_layer1(x)  # 64 -> 128
        h = self.expand_layer2(m)  # 128 -> 256
        
        # --- [Step 2] Feature Interaction (SE-Attention) ---
        h = self.res_blocks(h)     # 256 -> 256
        
        # --- [Step 3] Compression ---
        main_out = self.final_proj(h) # 256 -> 128
        
        # --- [Step 4] Global Shortcut ---
        skip_out = self.input_skip(x) # 64 -> 128
        
        return main_out + skip_out
    
    
# ----------------------------------------------------------------------
# 3. Main Model: CoarseToFineItemTower (Stage 1)
# ----------------------------------------------------------------------
class CoarseToFineItemTower(nn.Module):
    """
    [Item Tower - Residual Field Embedding Ver.]
    TabTransformerì˜ ì•„ì´ë””ì–´ë¥¼ ì‘ìš©í•˜ì—¬, STDì™€ REë¥¼ í•˜ë‚˜ì˜ ì‹œí€€ìŠ¤ë¡œ í†µí•©í•˜ê³ 
    ê³„ì¸µì  ì”ì°¨ ì—°ê²°(Inheritance)ì„ í†µí•´ í•™ìŠµ ì•ˆì •ì„±ì„ ê·¹ëŒ€í™”í•œ êµ¬ì¡°.
    """
    def __init__(self, 
                 embed_dim=EMBED_DIM_CAT,     # 64
                 nhead=4, 
                 num_layers=2,                # TabTransformerëŠ” ì–•ì•„ë„ ì¶©ë¶„í•¨
                 max_fields=50,               # ì˜ˆìƒë˜ëŠ” ìµœëŒ€ í•„ë“œ(ì»¬ëŸ¼) ê°œìˆ˜
                 output_dim=OUTPUT_DIM_ITEM_TOWER):
        super().__init__()
        
        # 1. Vocab Size ê°€ì ¸ì˜¤ê¸°
        std_vocab_size, _ = vocab.get_vocab_sizes()
        
        # 2. Embeddings
        # A. STD Value Embedding (Base) , RE Value Embedding (Delta / Child)
        self.std_embedding = nn.Embedding(std_vocab_size, embed_dim, padding_idx=vocab.PAD_ID)
        # self.re_embedding = nn.Embedding(RE_MAX_CAPACITY, embed_dim, padding_idx=vocab.PAD_ID)
        self.re_token_embedding = nn.Embedding(vocab.RE_VOCAB_SIZE, embed_dim, padding_idx=vocab.RE_TOKENIZER.pad_token_id)
        # REëŠ” Delta(ì°¨ì´ì )ë§Œ í•™ìŠµí•˜ë¯€ë¡œ 0 ê·¼ì²˜ ì´ˆê¸°í™” (í•™ìŠµ ì´ˆê¸° ì•ˆì •ì„±)
        nn.init.normal_(self.re_token_embedding.weight, mean=0.0, std=0.01)

        # C. Field Embedding (Shared Key)
        # ê° ì»¬ëŸ¼(Color, Brand ë“±)ì˜ ì—­í• ì„ ë‚˜íƒ€ë‚´ëŠ” ì„ë² ë”©
        self.field_embedding = nn.Parameter(torch.randn(1, max_fields, embed_dim))
        
        # 3. Unified Transformer Encoder
        # STDì™€ REê°€ í•œ ê³µê°„ì—ì„œ ìƒí˜¸ì‘ìš© (Self-Attn ì‚¬ìš©)
        encoder_layer = nn.TransformerEncoderLayer(
            d_model=embed_dim, 
            nhead=nhead, 
            dim_feedforward=embed_dim * 4,
            batch_first=True,
            dropout=0.1,
            activation='gelu'
            #,norm_first=True # ìµœì‹  íŠ¸ë Œë“œ (ì•ˆì •ì  ìˆ˜ë ´)
        )
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        # 4. Projection Head
        # ì…ë ¥ ì°¨ì›: (STDí•„ë“œìˆ˜ + REí•„ë“œìˆ˜) * embed_dim -> Flatten í›„ ì••ì¶•
        self.head = DeepResidualHead(input_dim=embed_dim, output_dim=output_dim) 
        
    # $$Input Sequence = [\underbrace{Token_A}_{STDìë¦¬}, \underbrace{Token_B}_{RE(ì”ì°¨)ìë¦¬}]$$

    def forward(self, std_input: torch.Tensor, re_input: torch.Tensor) -> torch.Tensor:
        """
        std_input: (Batch, Num_Fields) - ì˜ˆ: [Color_ID, Category_ID, ...]
        re_input:  (Batch, Num_Fields) - ì˜ˆ: [MatteBlack_ID, 0, ...] (ìˆœì„œê°€ STDì™€ ëŒ€ì‘ë˜ì–´ì•¼ í•¨)
        """
        B, num_fields = std_input.shape
        
        # --- [Logic 1] Hierarchical Embedding Construction ---
        
        # (A) Field Embedding (Broadcasting)
        # í˜„ì¬ ë°°ì¹˜ì˜ í•„ë“œ ê°œìˆ˜ë§Œí¼ ìë¦„ (í˜¹ì‹œ ëª¨ë¥¼ ê°€ë³€ ê¸¸ì´ì— ëŒ€ë¹„)
        field_emb = self.field_embedding[:, :num_fields, :] # (1, F, D)
        
        # (B) STD (Parent)
        std_val = self.std_embedding(std_input) # (B, F, D)
        std_token = std_val + field_emb
        
        re_tokens = self.re_token_embedding(re_input)
        re_mask = (re_input != vocab.RE_TOKENIZER.pad_token_id).float().unsqueeze(-1) # (B, F, S, 1)
        
        # 3. Sum / Count (ìœ íš¨ í† í° ê°œìˆ˜ë¡œ ë‚˜ëˆ„ê¸°)
        sum_re = torch.sum(re_tokens * re_mask, dim=2) # (B, F, D)
        count_re = torch.clamp(re_mask.sum(dim=2), min=1e-9) # (B, F, 1)
        
    
        # (C) RE (Child = Delta + Parent + Field)
        re_delta = sum_re / count_re # (B, F, D) -> í•˜ë‚˜ì˜ ë²¡í„°ë¡œ ì••ì¶•ë¨!
        
    
        # re_delta = self.re_embedding(re_input) # (B, F, D)
        
        # * í•µì‹¬: REê°€ 0(PAD)ì´ì–´ë„ std_val + field_embê°€ ë‚¨ì•„ì„œ 'Parent' ì—­í• ì„ ìˆ˜í–‰í•¨
        # * detach(): REì˜ ê·¸ë˜ë””ì–¸íŠ¸ê°€ STD ì„ë² ë”©ì„ ë§ê°€ëœ¨ë¦¬ì§€ ì•Šë„ë¡ ì°¨ë‹¨
        re_token = re_delta + std_val.detach() + field_emb
        
        # --- [Logic 2] Unified Sequence ---
        combined_seq = torch.cat([std_token, re_token], dim=1)
        
        # Mask ìƒì„±
        # 1. STD, REê°€ ìœ íš¨í•œê°€?
        std_valid = (std_input != vocab.PAD_ID)
        re_valid = (re_input != vocab.RE_TOKENIZER.pad_token_id).any(dim=2)

        mask_part_std = std_valid
        mask_part_re = re_valid | std_valid

        full_mask = torch.cat([mask_part_std, mask_part_re], dim=1) # (B, 2*F)

        # ì´í›„ Transformerì— ì „ë‹¬
        context_out = self.transformer(combined_seq, src_key_padding_mask=~full_mask)

        # [Smart Pooling] íŒ¨ë”© ì œì™¸ í‰ê· 
        mask_expanded = full_mask.unsqueeze(-1).float() # (B, 2*F, 1)
        sum_embeddings = torch.sum(context_out * mask_expanded, dim=1)
        sum_mask = torch.clamp(mask_expanded.sum(dim=1), min=1e-9) # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€
        
        pooled = sum_embeddings / sum_mask
        
        return self.head(pooled)
    
# ----------------------------------------------------------------------
# 4. OptimizedItemTower (Stage 2 Adapter - Triplet Training)
#    Projection Head --> Contrastive Loss(Opt.z) / Representation(Encoder)
# ----------------------------------------------------------------------

class OptimizedItemTower(nn.Module):
    """
    [Optimization Tower]: Projection Head, Distance/metric Learningìš©
    """
    def __init__(self, input_dim=OUTPUT_DIM_ITEM_TOWER, output_dim=OUTPUT_DIM_TRIPLET):
        super().__init__()
        self.layer = nn.Sequential(
            nn.Linear(input_dim, input_dim),
            nn.LayerNorm(input_dim),
            nn.GELU(), #nn.GELU(), 
            nn.Linear(input_dim, output_dim),
        )
        
    def forward(self, x):
        # [Log 1] ì…ë ¥ ë°ì´í„° í™•ì¸
        if not self.training: 
            print(f"\n  [Model Internal] Input Vector Shape: {x.shape}")
            print(f"  [Model Internal] Input Sample (First 5): {x[0, :5].detach().cpu().numpy()}")

        # ë ˆì´ì–´ í†µê³¼
        x = self.layer(x)
        
        # ì •ê·œí™” (L2 Normalization)
    
        return F.normalize(x, p=2, dim=1)




# x = F.normalize(x, p=2, dim=1) ì‹¤ì œ ì¶”ë¡ ë–„ëŠ” hìª½ model loadí•˜ì—¬ ì“°ì. (same d)

'''

êµ¬ì¡°: Encoder -> Embedding(h) -> MLP Layer(Projection Head) -> Output(z) -> Loss

ì›ë¦¬: z ê³µê°„ì—ì„œëŠ” Contrastive Lossì— ì˜í•´ ë°ì´í„°ê°€ êµ¬ì²´ í‘œë©´ìœ¼ë¡œ ì°Œê·¸ëŸ¬ì§€ë©° ì •ë³´ ì†ì‹¤
ë°˜ë©´ ê·¸ ì „ ë‹¨ê³„ì¸ hëŠ” ë°ì´í„°ì˜ ì›ë³¸ ì •ë³´ë¥¼ ìƒëŒ€ì  ë³´ì¡´

í•™ìŠµí•  ë•Œ: Projection Headë¥¼ ë¶™ì—¬ì„œ z ê°’ìœ¼ë¡œ Loss ê³„ì‚°.

ì„œë¹™í•  ë•Œ: Projection Headë¥¼ ë–¼ì–´ë²„ë¦¬ê³  h ê°’ì„ ì‚¬ìš©.

íš¨ê³¼: ì´ë ‡ê²Œ í•˜ë©´ Representation Qualityê°€ 10~15% í–¥ìƒ data

'''


    
# ----------------------------------------------------------------------
# 5. Dataset & Sampler & Training Function (Stage 2 Logic) / first INPUT from DB
# ----------------------------------------------------------------------


class SimCSEModelWrapper(nn.Module):
    def __init__(self, encoder, projector):
        super().__init__()
        self.encoder = encoder      # ì´ê²ƒì´ CoarseToFineItemTower
        self.projector = projector  # ì´ê²ƒì´ OptimizedItemTower


    def forward(self, t_std, t_re):
        # 1. ë°›ì€ 2ê°œ ì¸ìë¥¼ encoderì—ê²Œ ê·¸ëŒ€ë¡œ í† ìŠ¤
        enc_out = self.encoder(t_std, t_re) 
        
        # 2. ê·¸ ê²°ê³¼ë¥¼ projectorì—ê²Œ í† ìŠ¤
        return self.projector(enc_out)

class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def _apply_dropout_and_convert(self, product: TrainingItem):
        """
        1. Feature Dropout ìˆ˜í–‰
        """
        # 1. Deep Copy (ì›ë³¸ ë³´ì¡´)
        feat_data = copy.deepcopy(product.feature_data)
        
        clothes = feat_data.get("clothes", {})
        reinforced = feat_data.get("reinforced_feature_value", {})
        
        # 2. Random Dropout (Key ì‚­ì œ) - ì—¬ê¸°ê°€ ë°ì´í„° ì¦ê°•(Augmentation) í•µì‹¬
        if self.dropout_prob > 0:
            # list(...)ë¡œ ê°ì‹¸ì•¼ ì‚­ì œ ì¤‘ ë”•ì…”ë„ˆë¦¬ í¬ê¸° ë³€ê²½ ì—ëŸ¬ ë°©ì§€
            for k in list(clothes.keys()):
                if random.random() < self.dropout_prob:
                    del clothes[k]
            for k in list(reinforced.keys()):
                if random.random() < self.dropout_prob:
                    del reinforced[k]

        
        # 3.preprocess_batch_inputì´ 'feature_data' ì†ì„±ì„ ì°¸ì¡°í•˜ë¯€ë¡œ ê·¸ í˜•íƒœë¥¼ ë§ì¶°ì¤Œ.
        return TrainingItem(
            product_id=product.product_id,
            feature_data=feat_data # ë“œëì•„ì›ƒ ì ìš©ëœ ë°ì´í„°
        )

    def __getitem__(self, idx):
        item = self.products[idx]
        
        # ë·° 1 ìƒì„± (ë“œëì•„ì›ƒ A ì ìš©)
        view1_obj = self._apply_dropout_and_convert(item)
        
        # ë·° 2 ìƒì„± (ë“œëì•„ì›ƒ B ì ìš©)
        view2_obj = self._apply_dropout_and_convert(item)
        
        return view1_obj, view2_obj



''' 
class SimCSERecSysDataset(Dataset):
    def __init__(self, products: List[TrainingItem], dropout_prob: float = 0.2):
        self.products = products
        self.dropout_prob = dropout_prob

    def __len__(self):
        return len(self.products)

    def input_feature_dropout(self, product: TrainingItem) -> TrainingItem:
        """
        [Augmentation Logic]
        JSON êµ¬ì¡°("clothes", "reinforced_feature_value")ì— ë§ì¶°
        ëœë¤í•˜ê²Œ ì†ì„±(Key-Value)ì„ ì œê±°í•©ë‹ˆë‹¤.
        """
        # ì›ë³¸ ë°ì´í„° ë³´í˜¸ë¥¼ ìœ„í•´ Deep Copy (ë§¤ìš° ì¤‘ìš”)
        aug_p = copy.deepcopy(product)
        
        feature_dict = aug_p.feature_data
        
        # 1. Standard Features (clothes) Dropout
   
        clothes_data = feature_dict.get("clothes")
        if clothes_data:
            keys = list(clothes_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del clothes_data[k]
        
        # 2. Reinforced Features Dropout
  
        re_data = feature_dict.get("reinforced_feature_value")
        if re_data:
            keys = list(re_data.keys())
            for k in keys:
                if random.random() < self.dropout_prob:
                    del re_data[k]
                    
        return aug_p
    def __getitem__(self, idx):
        raw_product = self.products[idx]
        
        # SimCSE: ê°™ì€ ìƒí’ˆì„ ë‘ ë²ˆ ë³€í˜•í•´ì„œ (View1, View2) ìƒì„±
        view1 = self.input_feature_dropout(raw_product)
        view2 = self.input_feature_dropout(raw_product)
        
        return view1, view2
'''


    
# ----------------------------------------------------------------------
# 6. userTowerClass
#     
# ----------------------------------------------------------------------


def load_pretrained_vectors_from_db(db_session: Session) -> Tuple[torch.Tensor, Dict[int, int]]:
    """
    [ê¸°ëŠ¥]
    1. DBì—ì„œ (product_id, vector) ìŒì„ ëª¨ë‘ ê°€ì ¸ì˜µë‹ˆë‹¤.
    2. DB ID -> Model Index ë§¤í•‘ì„ ìƒì„±í•©ë‹ˆë‹¤.
    3. User Towerì˜ Embedding Layerì— ë„£ì„ Weight Matrixë¥¼ ë§Œë“­ë‹ˆë‹¤.
    
    [Return]
    - embedding_matrix: (Num_Products + 1, 128) - 0ë²ˆì€ Padding
    - id_map: {real_db_id: model_index}
    """
    print("â³ Fetching product vectors from DB...")
    
    # 1. DB Query (IDì™€ Serving Vectorë§Œ ê°€ì ¸ì˜´)
    # vector_servingì´ ìš°ë¦¬ê°€ ì‚¬ìš©í•  ìµœì¢… ì•„ì´í…œ ë²¡í„°ë¼ê³  ê°€ì •
    results = db_session.query(
        ProductInferenceVectors.id, 
        ProductInferenceVectors.vector_embedding
    ).filter(
        ProductInferenceVectors.vector_embedding.isnot(None)
    ).all()
    
    if not results:
        raise ValueError("DBì— ì €ì¥ëœ ì•„ì´í…œ ë²¡í„°ê°€ ì—†ìŠµë‹ˆë‹¤!")

    # 2. ë©”íƒ€ë°ì´í„° ì„¤ì •
    num_products = len(results)
    vector_dim = 128 # ê³ ì • ì°¨ì›
    
    # 0ë²ˆ ì¸ë±ìŠ¤ëŠ” Paddingì„ ìœ„í•´ ë¹„ì›Œë‘  (Index 1ë¶€í„° ì‹œì‘)
    embedding_matrix = torch.zeros((num_products + 1, vector_dim), dtype=torch.float32)
    id_map = {} # Real ID -> Model Index

    # 3. ë§¤í•‘ ë° ë§¤íŠ¸ë¦­ìŠ¤ ì±„ìš°ê¸°
    print(f"ğŸ“¦ Processing {num_products} items...")
    
    for idx, (real_id, vector_list) in enumerate(results, start=1):
        # vector_listëŠ” DBì—ì„œ List[float] í˜•íƒœë¡œ ì˜¨ë‹¤ê³  ê°€ì •
        if vector_list is None: continue
            
        # ë§¤í•‘ ì €ì¥
        id_map[real_id] = idx 
        
        # í…ì„œì— ê°’ í• ë‹¹
        embedding_matrix[idx] = torch.tensor(vector_list, dtype=torch.float32)
        
    print("âœ… Pretrained Embedding Matrix Created.")
    print(f"   Shape: {embedding_matrix.shape}")
    
    return embedding_matrix, id_map


class FinalUserTower(nn.Module):
    def __init__(self, 
                 num_total_products: int,
                 pretrained_item_matrix: torch.Tensor = None,
                 max_seq_len: int = 50,
                 d_model: int = 128,      # Transformer ë‚´ë¶€ ì°¨ì›
                 nhead: int = 4,
                 num_layers: int = 2,
                 output_dim: int = 128):  # ìµœì¢… ì¶œë ¥ ì°¨ì›
        super().__init__()
        
        # ==========================================
        # 1. Feature Extraction (Transformer Body)
        # ==========================================
        self.item_embedding = nn.Embedding(num_total_products + 1, d_model, padding_idx=0)
        if pretrained_item_matrix is not None:
            self.load_pretrained_weights(pretrained_item_matrix)
            
        self.position_embedding = nn.Embedding(max_seq_len, d_model)
        self.season_embedding = nn.Embedding(4, d_model)
        self.gender_embedding = nn.Embedding(3, d_model, padding_idx=0)
        
        encoder_layer = nn.TransformerEncoderLayer(d_model=d_model, nhead=nhead, dim_feedforward=d_model*4, batch_first=True, dropout=0.1)
        self.transformer = nn.TransformerEncoder(encoder_layer, num_layers=num_layers)
        
        self.user_query_token = nn.Parameter(torch.randn(1, 1, d_model)) 

        # ==========================================
        # 2. Deep Interaction & Mapping (Head) - [ì¶”ê°€ëœ ë¶€ë¶„]
        # ==========================================
        # Transformerì˜ ì¶œë ¥(d_model)ì„ ë°›ì•„ì„œ ì‹¬ì¸µ ê°€ê³µ
        # DeepResidualHead: Expand -> SE-ResBlock -> Compress
        self.deep_head = DeepResidualHead(input_dim=d_model, output_dim=output_dim)
        
        # ==========================================
        # 3. Final Projection (OptimizedItemTowerì™€ ë™ì¼ êµ¬ì¡°)
        # ==========================================
        # Metric Learningì„ ìœ„í•œ ìµœì¢… ì •ê·œí™” ë° íˆ¬ì˜
        self.final_projector = OptimizedItemTower(input_dim=output_dim, output_dim=output_dim)

    def load_pretrained_weights(self, matrix):
        self.item_embedding.weight.data.copy_(matrix)
        self.item_embedding.weight.requires_grad = False

    def forward(self, history_ids, season_idx, gender_idx):
        B, L = history_ids.shape
        device = history_ids.device
        
        # --- [Step 1] Transformer Context Encoding ---
        seq_emb = self.item_embedding(history_ids)
        pos_emb = self.position_embedding(torch.arange(L, device=device))
        season_emb = self.season_embedding(season_idx).unsqueeze(1)
        gender_emb = self.gender_embedding(gender_idx).unsqueeze(1)
        
        x = seq_emb + pos_emb + season_emb + gender_emb
        
        cls_token = self.user_query_token.expand(B, -1, -1)
        x = torch.cat([cls_token, x], dim=1)
        
        padding_mask = (history_ids == 0)
        cls_mask = torch.zeros((B, 1), dtype=torch.bool, device=device)
        full_mask = torch.cat([cls_mask, padding_mask], dim=1)
        
        out = self.transformer(x, src_key_padding_mask=full_mask)
        
        # ìœ ì € í† í° ì¶”ì¶œ (Transformerê°€ ìš”ì•½í•œ 1ì°¨ ì •ë³´)
        raw_user_vector = out[:, 0, :] # (B, d_model)
        
        # --- [Step 2] Deep Residual Interaction (SE-Block) ---
        # "ì‹œê°„ì¶•"ì´ ìš”ì•½ëœ ì •ë³´ì—ì„œ "íŠ¹ì„±ì¶•" ì¤‘ìš”ë„ë¥¼ ë‹¤ì‹œ ê³„ì‚°í•˜ê³  ë¹„ì„ í˜• ë³€í™˜
        deep_feat = self.deep_head(raw_user_vector) # (B, output_dim)
        
        # --- [Step 3] Final Projection & Normalize ---
        # Item Towerì™€ ë™ì¼í•œ ìœ„ìƒ ê³µê°„ìœ¼ë¡œ ë§¤í•‘
        final_vector = self.final_projector(deep_feat) # (B, output_dim)
        
        return final_vector